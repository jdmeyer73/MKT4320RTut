[["index.html", "R Tutorial for MKT 4320 About this tutorial", " R Tutorial for MKT 4320 Jeffrey Meyer 2025-01-14 About this tutorial This tutorial is a quick and basic R tutorial for MKT 4320. It is not designed to be comprehensive, but will provide you with the basics of R, RStudio, and how to complete the types of analyses covered in the course. At this time, the tutorial is not complete, but will be updated as we move through the topics in the course. Much of the content in this tutorial is adapted from a variety of sources. Where applicable, the source will be noted. "],["r-basics.html", "Chapter 1 R Basics 1.1 Introduction 1.2 R Language 1.3 Packages 1.4 Getting Help 1.5 Basic Object Types (and Other Important Stuff) 1.6 Data Frames 1.7 Data Transformations 1.8 R Projects 1.9 Loading and Saving Data 1.10 User Defined Functions 1.11 Package MKT4320BGSU 1.12 Package dplyr 1.13 Package lubridate 1.14 R Markdown and R Notebook 1.15 Working with R Notebook Lab Assignment Files", " Chapter 1 R Basics Sources for this chapter: R for Marketing Research ad Analytics, Second Edition (2019). Chris Chapman and Elea McDonnell Feit http://r-marketing.r-forge.r-project.org/index.html 1.1 Introduction 1.1.1 What is R? R is a programming language R is not a statistics program Much different than SPSS, MiniTab, Stata, etc. Does not use a point-and-click interface 1.1.2 Why R? Emerging techniques usually available in R quickly Default educational platform for statistics programs (and spreading to other disciplines) Large and diverse set of analytic tools Powerful plotting options Large community of helpful users R skills are in high demand And R is free 1.1.3 Why NOT R? Steep learning curve Requires programming 1.1.4 What is RStudio? RStudio IDE is an integrated development environment that makes working with R more user friendly Not required to use R, but provides a better interface and environment of writing code, editing code, and creating documents. Complete separate software And RStudio is free 1.1.5 Getting Started 1.1.5.1 Option 1: Install on your Machine Install “R base” from the Comprehensive R Archive Network (CRAN) https://cran.r-project.org/ Install RStudio https://posit.co/download/rstudio-desktop/#download 1.1.5.2 Option 2: Use BGSU’s Virtual Computing Lab pilot See course website for link 1.1.5.3 Option 3: Use a computer in an on-campus computer lab All computer in on-campus computer labs should have R and RStudio installed 1.1.6 Navigating RStudio As you can see in Figure 1.1, RStudio is typically divided in 4 quadrants. Figure 1.1: RStudio Layout 1.1.6.1 Quadrant 1 The upper-left corner is the source pane. This pane is where the majority of your programming or coding will take place. When working in this pane, the code does not run unless you tell it to run. In addition, the code can be saved to prevent work from being lost. 1.1.6.2 Quadrant 2 The lower-left corner is the console pane. While it contains several tabs, generally the Console tab is the only one used. The console is where R actually evaluates the code. If you run code from the a source pane window, the code will automatically be put into the console pane and evaluated. You can also type code directly into the console pane and receive immediate results. Depending on the code, the results will appear directly in the console or in a tab Quadrant 4. The “&gt;” symbol shows that the console is ready for input. 1.1.6.3 Quadrant 3 The upper-right corner also contains several tabs, but the Environment and History tabs are the ones used most often. The Environment tab lists all data objects that have been defined in the current session. The History tab is an archive of all commands run in the current session. 1.1.6.4 Quadrant 4 The bottom-right corner also contains several tabs, all of which are used at different times. The Files tab lists all files in the current directory. The Plots tab shows visualizations created during the current session. The Packages tab shows all packages installed as well as which packages are currently loaded. The Help tab contains the help menu. The Viewer tab contains output from code if the code directs it to be displayed there. 1.2 R Language 1.2.1 Basics of R Commands R is case sensitive When using the console, use the keyboard  ↑  and  ↓  arrow keys to easily cycle through previous commands typed. When using the text editor (i.e., a script file) in the source pane, use the Ctrl+Enter keyboard shortcut to submit a line of code directly to the console. The entire line does not need to be highlighted; the cursor needs to be anywhere on the line to be submitted. When using the text editor/script file, the “#” symbol signifies a comment Everything after is ignored It can be on the same line: x &lt;- 100 # Assign 100 to x It can be on separate lines: # Assign 100 to x x &lt;- 100 1.2.2 Operators Mathematical and logical operators are used frequently. Table 1.1: R Operators Description Operator Mathematical addition \\(+\\) subtraction \\(-\\) multiplication \\(*\\) division \\(/\\) exponentiation ^ or \\(**\\) Logical less than &lt; less than or equal to &lt;= greater than &gt; greater than or equal to &gt;= exactly equal to == not equal to != Not x !x x OR y x|y x AND y x&amp;y test if X is TRUE isTRUE(x) 1.3 Packages Packages are collections of functions that have been written to expand the functionality of R. Packages are not automatically included, and if a command is given that is not part of a package installed and loaded, R will give an error message. Therefore, the package must first be installed, and then loaded. 1.3.1 Installing Packages Installing packages is performed with the install.packages(\"\")function, where the name of the package is inside the quotation marks Two packages that used quite often in this course are ggplot2 and dplyr install.packages(&quot;ggplot2&quot;) install.packages(&quot;dplyr&quot;) NOTE 1: Packages only need to be installed on your machine once NOTE 2: If using BGSU’s Virtual Computing Lab, new packages cannot be installed, but the version in the virtual environment has most of the most common packages pre-installed 1.3.2 Loading Packages Once a package is installed, it has to be loaded with the library() function, where the name of the package is in the parentheses, in order to be used library(ggplot2) library(dplyr) NOTE 1: It is not uncommon to see a variety of messages when loading a package NOTE 2: Packages need to be loaded every time you start a new R session 1.4 Getting Help R has built in help to assist with understanding different functions To access the help, type ? FUNCTION in the console, and the help page for that function will show up in the lower-right pane under the help tab ? mean 1.5 Basic Object Types (and Other Important Stuff) Objects in R include variables, data sets, and functions The assignment operator &lt;- assigns a value to a named object x &lt;- 100 # Assign value 100 to object &#39;x&#39; x # Display object &#39;x&#39; [1] 100 NOTE: In RStudio console or script file, Alt+- will automatically paste the assignment operator As stated before, object names are case sensitive x &lt;- 100 # Assign value 100 to object &#39;x&#39; X # Display object &#39;X&#39; Error: object &#39;X&#39; not found The print command can also be used to print objects print(x) [1] 100 Video Tutorial: Assignment Operator 1.5.1 Vectors Vectors can be created many ways and take many data types One method is to using the c() function, which concatenates individual items x.Num &lt;- c(1, 3.14, 5.49, 10, 20) x.Num [1] 1.00 3.14 5.49 10.00 20.00 x.Log &lt;- c(TRUE, FALSE, TRUE, TRUE, FALSE) x.Log [1] TRUE FALSE TRUE TRUE FALSE x.Char &lt;- c(&quot;fr&quot;, &quot;fr&quot;, &quot;jr&quot;, &quot;so&quot;, &quot;sr&quot;) x.Char [1] &quot;fr&quot; &quot;fr&quot; &quot;jr&quot; &quot;so&quot; &quot;sr&quot; The class of the vector can be checked with the class() function # Concatenate class functions and print together print(c(class(x.Num), class(x.Log), class(x.Char))) [1] &quot;numeric&quot; &quot;logical&quot; &quot;character&quot; Video Tutorial: Vectors - Part 1 Vectors can only hold a single class/type of value When multiple classes are included, the values are coerced to the most general type x.Mix &lt;- c(1, FALSE, 3.5, &quot;Hello!&quot;) x.Mix [1] &quot;1&quot; &quot;FALSE&quot; &quot;3.5&quot; &quot;Hello!&quot; class(x.Mix) [1] &quot;character&quot; The c() function can be used to add to existing vectors, or combine vectors Type coercion will be applied as needed x2 &lt;- c(x.Num, 25, 50) x.Num [1] 1.00 3.14 5.49 10.00 20.00 x2 [1] 1.00 3.14 5.49 10.00 20.00 25.00 50.00 x3 &lt;- c(x2, &quot;Hello&quot;) x3 [1] &quot;1&quot; &quot;3.14&quot; &quot;5.49&quot; &quot;10&quot; &quot;20&quot; &quot;25&quot; &quot;50&quot; &quot;Hello&quot; Math can be applied directly to vectors x.Num [1] 1.00 3.14 5.49 10.00 20.00 x.Num + 100 [1] 101.00 103.14 105.49 110.00 120.00 x.Num * pi [1] 3.141593 9.864601 17.247344 31.415927 62.831853 The length() function provides the length of a vector length(x.Num) [1] 5 length(x.Char) [1] 5 The str() function provide the structure of an object Class, Length, and Value str(x.Num) num [1:5] 1 3.14 5.49 10 20 str(x.Char) chr [1:5] &quot;fr&quot; &quot;fr&quot; &quot;jr&quot; &quot;so&quot; &quot;sr&quot; Video Tutorial: Vectors - Part 2 1.5.2 Indexing Indexing is used to obtain particular elements of a data structure Vectors are indexed with square brackets, [] # Obtain the third element of the &#39;x.Num&#39; vector x.Num[3] [1] 5.49 Items can be excluded with negative indexing # Obtain all elements except the third element of the &#39;x.Num&#39; vector x.Num[-3] [1] 1.00 3.14 10.00 20.00 Indexing also works with logical operators # Obtain all elements in &#39;x.Num&#39; greater than 5 x.Num[x.Num &gt; 5] [1] 5.49 10.00 20.00 Video Tutorial: Indexing 1.5.3 Sequencing Vectors can also be created using sequencing Integer sequencing is done with #:# coding x.Seq &lt;- 1:10 x.Seq [1] 1 2 3 4 5 6 7 8 9 10 Sequences can also be used in indexing # Obtain the second through fourth element of the &#39;x.Num&#39; vector x.Num[2:4] [1] 3.14 5.49 10.00 Complex sequencing can be done using the seq() function x.Seq2 &lt;- seq(from=0, to=100, by=20) x.Seq2 [1] 0 20 40 60 80 100 Note: the from=, to= and by= can be excluded x.Seq3 &lt;- seq(0,100,20) x.Seq3 [1] 0 20 40 60 80 100 Video Tutorial: Sequencing 1.5.4 Missing (and Other Interesting) Values In R, missing values are assigned a special constant, NA NA is not a character value, but a type of its own Any math performed on a value of NA becomes NA x.Scores &lt;- c(85, 93, NA, NA) mean(x.Scores) [1] NA Many commands contain a option, na.rm=TRUE, to ignore NA data when performing the function mean(x.Scores, na.rm=TRUE) [1] 89 NA values can also be removed before performing the function using the na.omit() function mean(na.omit(x.Scores)) [1] 89 R also has special types for infinity, Inf, and undefined numbers (i.e., “not a number”), NaN To see this in action, take the natural log, log(), of certain numbers log(-1) [1] NaN log(0) [1] -Inf Notice that R provides a warning when the NaN is found 1.5.5 Factors Character data can be converted into nominal factors using the as.factors() function Each unique character value will be a level of the factor Behind the scenes, R stores the values as integers, with a separate list of labels When the data type is set as a factor, R knows how to handle it appropriately in the model The levels can be accessed with the levels() function x.Class &lt;- as.factor(x.Char) str(x.Class) Factor w/ 4 levels &quot;fr&quot;,&quot;jr&quot;,&quot;so&quot;,..: 1 1 2 3 4 levels(x.Class) [1] &quot;fr&quot; &quot;jr&quot; &quot;so&quot; &quot;sr&quot; 1.6 Data Frames Data frames are an object type that deserve special attention 1.6.1 Overview Most common way to handle data sets in R Provide data to statistical functions Think of it like a spreadsheet, or a rectangular object where: Columns are varying data types (i.e., variables) Rows are values in each column (i.e, observations) 1.6.2 Creating a data frame Can construct a data frame with the data.frame() function Takes as input a set of vectors of the same length x.df &lt;- data.frame(x.Num, x.Log, x.Char) x.df x.Num x.Log x.Char 1 1.00 TRUE fr 2 3.14 FALSE fr 3 5.49 TRUE jr 4 10.00 TRUE so 5 20.00 FALSE sr Note that the column names are inherited from the contributing vector Elements can be indexed using [ROW, COLUMN] notation # Obtain the first element of the third row of data frame &#39;x.df&#39; x.df[3,1] [1] 5.49 # Obtain the third element of the second row of data frame &#39;x.df&#39; x.df[2,3] [1] &quot;fr&quot; Video Tutorial: Data Frames (Part 1) 1.6.2.1 Using vectors in-line The vectors can be created in line (i.e., not already created) If the vectors are of different length, the shorter vector will be repeated IF the longest vector is divisible by the vector If a single value is provided instead of a vector, it is repeated for all rows x2.df &lt;- data.frame(var1=seq(10,100,10), var2=c(&quot;Yes&quot;,&quot;No&quot;), var3=1:5, var4=100) x2.df var1 var2 var3 var4 1 10 Yes 1 100 2 20 No 2 100 3 30 Yes 3 100 4 40 No 4 100 5 50 Yes 5 100 6 60 No 1 100 7 70 Yes 2 100 8 80 No 3 100 9 90 Yes 4 100 10 100 No 5 100 Video Tutorial: Data Frames (Part 2) 1.6.3 Viewing a Data Frame There are a few ways to view a data frame Type the data frame name in the console x.df x.Num x.Log x.Char 1 1.00 TRUE fr 2 3.14 FALSE fr 3 5.49 TRUE jr 4 10.00 TRUE so 5 20.00 FALSE sr With data frames that have many variables, this is cumbersome With data frames with many rows, a “max.print” setting will kick in and not all rows will be shown To view only a few rows of data, the head(DF, n) function can be used, where DF is the name of the data frame, and n (optional) is the number of rows to view, with 10 as the default NOTE: The “Salaries” data frame from the car package is being used as an example head(Salaries,5) rank discipline yrs.since.phd yrs.service sex salary 1 Prof B 19 18 Male 139750 2 Prof B 20 16 Male 173200 3 AsstProf B 4 3 Male 79750 4 Prof B 45 39 Male 115000 5 Prof B 40 41 Male 141500 Use the function View() or click on the data frame name in the environment tab to see the data farme in the Source pane See Figure 1.2 Figure 1.2: Viewing a Data Frame in the Source Window Video Tutorial: Data Frames (Viewing) 1.6.4 Indexing and Sequencing Indices can be left blank, which selects all of that dimension x.df[2, ] # Obtain all of row 2 x.Num x.Log x.Char 2 3.14 FALSE fr x.df[ ,3] # Obtain all of column 3 [1] &quot;fr&quot; &quot;fr&quot; &quot;jr&quot; &quot;so&quot; &quot;sr&quot; As with vectors, indexing can be done with sequencing and negative indices to omit rows x.df[2:3, ] # Obtain rows 2 and 3 x.Num x.Log x.Char 2 3.14 FALSE fr 3 5.49 TRUE jr x.df[ ,-2] # Exclude column 2 x.Num x.Char 1 1.00 fr 2 3.14 fr 3 5.49 jr 4 10.00 so 5 20.00 sr Indexing a data frame returns an object, but the object type depends on the indexing Choosing \\(n\\) rows and and a single column yields a vector of length \\(n\\) Choosing multiple columns returns a new data frame Use the str() function to verify the new objects structure str(x.df[1, 1]) # 1 row and 1 column = vector of length 1 num 1 str(x.df[1:3, 2]) # 3 rows and 1 column = vector of length 3 logi [1:3] TRUE FALSE TRUE str(x.df[1, 1:2]) # 1 row and 2 columns = 1 x 2 data frame &#39;data.frame&#39;: 1 obs. of 2 variables: $ x.Num: num 1 $ x.Log: logi TRUE str(x.df[1:4, c(1, 3)]) #4 rows and 2 columns = 4 x 2 data frame &#39;data.frame&#39;: 4 obs. of 2 variables: $ x.Num : num 1 3.14 5.49 10 $ x.Char: chr &quot;fr&quot; &quot;fr&quot; &quot;jr&quot; &quot;so&quot; Data frames can also be indexed using column names after the $ character x.df$x.Char [1] &quot;fr&quot; &quot;fr&quot; &quot;jr&quot; &quot;so&quot; &quot;sr&quot; Video Tutorial: Data Frames (Indexing &amp; Sequencing) 1.7 Data Transformations Analysts and researchers often need to create new variables from existing ones or transform existing variables Data transformations can usually be accomplished in more than one way Using base R will be shown first After the dplyr package is introduced, a second way will be shown For the transformations shown below, either a new variable will be added to the data frame, or an existing variable will be changed However, it is not always required that the data frame be changed Sometimes, a transformation will be done ‘on the fly’ and used only in an analysis, but the data frame remains the same 1.7.1 Creating New Variables Adding a new variable is done using code such as df$new &lt;- SOME FUNCTION, where: df is the name of the data frame new is the name for the new variable SOME FUNCTION is the data transformation to take place # Create new variable &#39;NumSq&#39; that is the square of current variable x.Num x.df$NumSq &lt;- x.df$x.Num^2 x.df x.Num x.Log x.Char NumSq 1 1.00 TRUE fr 1.0000 2 3.14 FALSE fr 9.8596 3 5.49 TRUE jr 30.1401 4 10.00 TRUE so 100.0000 5 20.00 FALSE sr 400.0000 Video Tutorial: Data Transformations (Introduction) 1.7.2 Recoding (Create New) In base R, recoding is usually a multi-step process using indexing # Recode &#39;x.Num&#39; into three factors x.df$Grp &lt;- &quot;low&quot; # Create new variable and set all rows to one level x.df$Grp[x.df$x.Num&gt;=3 &amp; x.df$x.Num&lt;10] &lt;- &quot;med&quot; # Create medium level x.df$Grp[x.df$x.Num&gt;10] &lt;- &quot;high&quot; # Create high level x.df$Grp &lt;- as.factor(x.df$Grp) # Set new variable as factor str(x.df) # See structure of data frame with new variable &#39;data.frame&#39;: 5 obs. of 5 variables: $ x.Num : num 1 3.14 5.49 10 20 $ x.Log : logi TRUE FALSE TRUE TRUE FALSE $ x.Char: chr &quot;fr&quot; &quot;fr&quot; &quot;jr&quot; &quot;so&quot; ... $ NumSq : num 1 9.86 30.14 100 400 $ Grp : Factor w/ 3 levels &quot;high&quot;,&quot;low&quot;,&quot;med&quot;: 2 3 3 2 1 Notice the &amp; in the code above. It stands for “and”, which tells R that both conditions must be true Video Tutorial: Data Transformations (Recoding New Variables) Video Tutorial: Data Transformations (Factor Variables) 1.7.3 Recoding (Change Existing) Recoding to change an existing variable is done in a similar manner NOTE: Sometimes we have to first change the variable type, such as when the existing variable is a factor # Recode &#39;Grp&#39; into only two factors # Change type to &#39;character&#39; x.df$Grp &lt;- as.character(x.df$Grp) # Recode &#39;low&#39; and &#39;med&#39; to &#39;very low&#39; x.df$Grp[x.df$Grp==&quot;low&quot; | x.df$Grp==&quot;med&quot;] &lt;- &quot;very low&quot; # Change back to factor x.df$Grp &lt;- as.factor(x.df$Grp) str(x.df) &#39;data.frame&#39;: 5 obs. of 5 variables: $ x.Num : num 1 3.14 5.49 10 20 $ x.Log : logi TRUE FALSE TRUE TRUE FALSE $ x.Char: chr &quot;fr&quot; &quot;fr&quot; &quot;jr&quot; &quot;so&quot; ... $ NumSq : num 1 9.86 30.14 100 400 $ Grp : Factor w/ 2 levels &quot;high&quot;,&quot;very low&quot;: 2 2 2 2 1 Notice the | in the code above. It stands for “or”, which tells R that either condition can be true. Video Tutorial: Data Transformations (Recoding Existing Variables) 1.8 R Projects The best way to manage all of the downloads and assignments for this course is to create an R Project. Follow the following steps to create a new R Project. From within RStudio, select File→New Project…See Figure 1.3If a Save Current Workspace window pops up, select Don’t Save Figure 1.3: Starting a New R Project To create the project in a new directory, select New Directory in the New Project Wizard window, then select New Project. Next, type in the name of the directory in the Directory Name: box (See 1 in Figure 1.4). Next, use the Browse button to select the location of the new directory (See 2 in Figure 1.4). Finally, click on Create Project to create the project (See 3 in Figure 1.4). Figure 1.4: Creating New R Project in New Directory To create the project in an existing directory, select Existing Directory in the New Project Wizard window. Next, use the Browse button to select the location of the existing directory (See 1 in Figure 1.5). Finally, click on Create Project to create the project (See 2 in Figure 1.5). Figure 1.5: Creating New R Project in Existing Directory To use the new project each time you work in RStudio for this class, you will need to open the project by using the drop down project menu (See 1 in Figure 1.6) and then selecting the appropriate project (See 2 in Figure 1.6). Figure 1.6: Opening an R Project Video Tutorial: R Projects using New Directory Option 1.9 Loading and Saving Data In this class, the data will be provided to you as an .Rdata file, which are specific to R and the best way to store (and load) objects. If desired, .Rdata files can contain multiple objects. For example, an .Rdata file could contain two different data frames. 1.9.1 Setting Working Directory To know where your files are saved to, and to make it easier to load files, it is best to use the R Project discussed above. However, you can also just place all of your files for the course in the same working directory. Use the getwd() function to see your current working directory getwd() [1] &quot;C:/Users/jdmeyer/Documents&quot; Set the working directory in one of three ways: Use the setwd() function: setwd(\"C:/Users/jdmeyer/Doc/RFiles/RTutorial\") NOTE: Forward slashes (as shown above) are used in place of backward slashes for directory paths Use the menus in RStudio Session→Set Working Directory→Choose Directory See Figure 1.7 Figure 1.7: Set Working Direcory using Menus Use the Files tab in the lower-right corner in RStudio See Figure 1.8 Figure 1.8: Set Working Direcory using Files Tab 1.9.2 Loading .Rdata Use the load(\"FILE LOCATION/NAME\") function to load and .Rdata file Suppose the data set used in Topic 1 (airlinesat.rdata) is in a subdirectory of the working directory called Data load(&quot;Data/airlinesat.rdata&quot;) See 1.9 for a visual example Figure 1.9: Loading Data 1.9.3 Saving .Rdata Use the save(OBJECT, file=\"SAVENAME\") function, where: OBJECT is one or more objects in the current environment separated by commas SAVENAME is the name of the file the objects will be saved to. save(x.df, file=&quot;xdf.rdata&quot;) 1.10 User Defined Functions Often, a series of commands is repeated over and over, or there is not an easy, built-in function in R to provide a needed result. In these case, R makes it relatively easy to create your own functions 1.10.1 Structure A function is constructed in the in the following manner: function.name &lt;- function(arglist) {body} where function.name is the name of the user defined function (arglist) contains the names of any inputs to the function, separated by commas {body} contains the code that operates on the inputs The function must be executed prior to using it in the current session; alternatively, the function can be saved as a “.R” script file and sourced using the source() function in R 1.10.2 Example Suppose a function is need to take the square root of a natural log transformation The new function will be named sqlog and will have one argument # Define the new function sqlog &lt;- function(x) { # Function has one argument, &#39;x&#39; sqrt(log(x)) # What is done with the argument, &#39;x&#39; } Now that the function is created and ran, it can be used. In this case, the output will be printed to the console. The function could have been written in a way that the result is stored as an object. sqlog(100) # Using the function on a single number [1] 2.145966 myvals &lt;- c(5, 10, 20, 40, 80, 160) # Creating a vector of values sqlog(myvals) # Using the function on a vector [1] 1.268636 1.517427 1.730818 1.920646 2.093329 2.252815 1.11 Package MKT4320BGSU The MKT4320BGSU package is a package I created that contains data sets and user-defined functions for this course. By installing this package when instructed, you will more easily be able to access the functions and data for the course, and you will have access to help files for the functions and data sets. The process for installing this package is a little different. You must first install the devtools package in order to use the install_github command. The steps are shown in the code below. # INSTALL &#39;devtools&#39; # NOTE: This step only has to be done the first time install.packages(&quot;devtools&quot;) # LOAD &#39;devtools&#39; package library(devtools) # INSTALL &#39;MKT4320BGSU&#39; package install_github(&quot;jdmeyer73/MKT4320BGSU&quot;) # LOAD &#39;MKT4320BGSU&#39; package library(MKT4320BGSU) 1.12 Package dplyr The dplyr package (pronounced DEE ply er) is a package that makes data manipulation much easier and more intuitive (for most). dplyr is built around the five main “verbs” shown below that make up a majority of data manipulation. However, there are other functions that dplyr uses to also help with data manipulation. select is used to subset columns filter is used to subset rows arrange is used to sort rows mutate is used to add new columns based on calculations (usually with other columns) summarise is use to perform summary calculations (e.g., mean, max, etc.) on data set In addition, dplyr uses the pipe, %&gt;%, to string together a series of functions. Think of functions strung together as upstream and downstream functions. The function to the left of %&gt;% is the upstream function, while the function to the right is the downstream function. By default, the downstream function assumes the value coming from the upstream function is the first argument in its function Therefore, the first argument can be omitted If the downstream function needs to use the value from from the upstream function assigned to a different argument, a . is simply put in the position of that argument 1.12.1 dplyr Examples First, be sure the dplyr package is loaded: library(dplyr) We’ll be using the airlinesat dataset from the airlinesat.rdata file for these examples. Video Tutorial: dplyr (Introduction) 1.12.1.1 select() function Usage: select(.data, ...), where ... is one or more unquoted expressions separated by commas airlinesat has 70 variables, but 46 of them are a series of expectation (e1 to e23) and satisfaction (s1 to s23)scales. First, we want to create a new data frame with those variables excluded. For simplicity, the num_range(\"prefix\", start:finish) selection can be used, and the ! takes the complement (i.e., all but these) airlinesat.small &lt;- # Create new data frame airlinesat %&gt;% # Use airlinesat as the starting data frame select(!num_range(&quot;e&quot;, 1:23)) %&gt;% # Select all but e1 to e23 select(!num_range(&quot;s&quot;, 1:23)) # Select all but s1 to s23 # NOTE: the two selects could have been concantendated as: # select(!c(num_range(&quot;e&quot;, 1:23), num_range(&quot;s&quot;, 1:23))) str(airlinesat.small) &#39;data.frame&#39;: 1065 obs. of 24 variables: $ age : num 30 55 56 43 44 40 39 41 33 51 ... $ country : Factor w/ 5 levels &quot;at&quot;,&quot;ch&quot;,&quot;de&quot;,..: 2 2 2 4 2 2 2 2 2 3 ... $ flight_class : Factor w/ 3 levels &quot;Business&quot;,&quot;Economy&quot;,..: 2 1 2 2 1 3 2 1 2 1 ... $ flight_latest : Factor w/ 6 levels &quot;within the last 12 months&quot;,..: 4 3 5 3 6 5 6 3 3 4 ... $ flight_purpose: Factor w/ 2 levels &quot;Business&quot;,&quot;Leisure&quot;: 2 1 1 2 1 2 1 1 2 1 ... $ flight_type : Factor w/ 2 levels &quot;Domestic&quot;,&quot;International&quot;: 1 2 1 1 2 2 1 2 1 2 ... $ gender : Factor w/ 2 levels &quot;female&quot;,&quot;male&quot;: 2 2 1 1 1 2 2 2 2 2 ... $ language : Factor w/ 3 levels &quot;English&quot;,&quot;French&quot;,..: 2 1 1 2 1 3 2 2 2 3 ... $ nflights : num 2 6 8 7 25 16 35 9 3 4 ... $ status : Factor w/ 3 levels &quot;Blue&quot;,&quot;Gold&quot;,..: 1 2 1 1 2 2 1 2 1 2 ... $ nps : num 6 10 8 8 6 7 8 7 8 8 ... $ sat1 : num 5 6 4 6 4 7 6 5 4 4 ... $ sat2 : num 2 6 2 6 3 2 3 3 4 4 ... $ sat3 : num 4 6 2 4 2 7 5 4 4 3 ... $ loy1 : num 3 6 3 6 3 2 2 4 4 3 ... $ loy2 : num 3 6 4 4 3 3 7 4 4 4 ... $ loy3 : num 3 6 7 5 2 2 7 4 2 3 ... $ loy4 : num 7 5 2 4 2 3 7 5 1 3 ... $ loy5 : num 3 6 4 5 2 2 6 5 2 4 ... $ com1 : num 1 6 7 6 3 7 7 4 3 1 ... $ com2 : num 1 6 7 6 3 6 7 4 3 7 ... $ com3 : num 7 6 7 6 2 3 7 5 3 7 ... $ overall_sat : num 2 6 2 4 2 4 4 4 4 3 ... $ reputation : num 3 6 4 6 5 3 3 4 2 4 ... Second, we want to create a new data frame with only demographic variables airlinesat.d &lt;- # Create new data frame airlinesat %&gt;% # Use airlinesat as the starting data frame select(age, country, gender) # Select only demographic variables str(airlinesat.d) &#39;data.frame&#39;: 1065 obs. of 3 variables: $ age : num 30 55 56 43 44 40 39 41 33 51 ... $ country: Factor w/ 5 levels &quot;at&quot;,&quot;ch&quot;,&quot;de&quot;,..: 2 2 2 4 2 2 2 2 2 3 ... $ gender : Factor w/ 2 levels &quot;female&quot;,&quot;male&quot;: 2 2 1 1 1 2 2 2 2 2 ... Video Tutorial: dplyr::select() 1.12.1.2 filter() function Usage: filter(.data, ...), where ... is an expression that returns a logical value First, we want to select only those rows where the person is from the United States (i.e., country == \"us\") using the newly created airlinesat.d data frame airlinesat.dus &lt;- airlinesat.d %&gt;% filter(country == &quot;us&quot;) head(airlinesat.dus) age country gender 1 52 us male 2 68 us male 3 64 us female 4 47 us male 5 57 us male 6 43 us male Second, we want to select only those rows where the person is older than the mean age using the newly created airlinesat.d data frame airlinesat.dold &lt;- airlinesat.d %&gt;% filter(age &gt; mean(age, na.rm=TRUE)) head(airlinesat.dold) age country gender 1 55 ch male 2 56 ch female 3 51 de male 4 58 de female 5 53 de male 6 53 de male Video Tutorial: dplyr::filter() 1.12.1.3 arrange() function Usage: arrange(.data, ..., .by_group = FALSE) where ... are variable(s) or functions of variables Use desc(...) to sort in a descending order .by_group = TRUE will sort first by a grouping variable, if one exists; default is FALSE First, we want to see the first 10 rows in ascending order of age using the airlinesat.d data frame # NOTE: A new data frame does not need to be created. # The result of the data manipulation can be sent directly # to another function, like &#39;head()&#39; airlinesat.d %&gt;% arrange(age) %&gt;% head(10) age country gender 1 19 de male 2 19 de male 3 21 de male 4 21 de male 5 22 de female 6 22 de male 7 22 de male 8 22 de female 9 22 de male 10 23 de male Second, we want to see the first 10 rows of three variables (age, country, nflights) from the original airlinesat data frame, sorted first ascending by age and second descending by nflights airlinesat %&gt;% select(age, country, nflights) %&gt;% arrange(age, desc(nflights)) %&gt;% head(10) age country nflights 1 19 de 15 2 19 de 3 3 21 de 11 4 21 de 2 5 22 de 20 6 22 de 8 7 22 de 3 8 22 de 3 9 22 de 2 10 23 de 15 Video Tutorial: dplyr::arrange() 1.12.1.4 mutate() function Usage: mutate(.data, ...) where ... are name-value pairs. The name gives the name of the new column/variable. The value is some function or formula. First, we want to create a standard normal variable for age using the airlinesat.d data frame airlinesat.d %&gt;% mutate(age_snrm=(age-mean(age, na.rm=TRUE))/sd(age,na.rm=TRUE)) %&gt;% head(10) age country gender age_snrm 1 30 ch male -1.66357002 2 55 ch male 0.37315007 3 56 ch female 0.45461887 4 43 fr female -0.60447557 5 44 ch female -0.52300677 6 40 ch male -0.84888198 7 39 ch male -0.93035079 8 41 ch male -0.76741318 9 33 ch male -1.41916361 10 51 de male 0.04727486 Second, we want to use mutate with recode to create a new variable, continent based on variable country recode(.x, ...) where .x is the variable to modify and ... are the things to recode in old = \"new\" format separated by commas Use recode_factor(.x, ...) to recode factor variables airlinesat.d %&gt;% mutate(continent=recode_factor(country, at=&quot;Europe&quot;, ch=&quot;Europe&quot;, de=&quot;Europe&quot;, fr=&quot;Europe&quot;, us=&quot;North America&quot;)) %&gt;% head(10) age country gender continent 1 30 ch male Europe 2 55 ch male Europe 3 56 ch female Europe 4 43 fr female Europe 5 44 ch female Europe 6 40 ch male Europe 7 39 ch male Europe 8 41 ch male Europe 9 33 ch male Europe 10 51 de male Europe Video Tutorial: dplyr::mutate() 1.12.1.5 summarise() function Usage: summarise(.data, ...) where ... are name-value pairs of summary functions (e.g., mean(), min(), sum(), n()) More than one summary function can be included First, we want to find the mean, standard deviation, and number of valid observations for the nflights variable airlinesat %&gt;% summarise(mean_flights=mean(nflights, na.rm=TRUE), sd_flights=mean(nflights, na.rm=TRUE), valid_n=sum(!is.na(nflights))) mean_flights sd_flights valid_n 1 13.41878 13.41878 1065 Second, we want to find the same information as above, but by continent group Use the group_by() function before summarise() # NOTE: The output will be of type &#39;tibble&#39; instead of &#39;data.frame&#39; # Tibbles are like data frames, but occasionally behave differently airlinesat %&gt;% mutate(continent=recode_factor(country, at=&quot;Europe&quot;, ch=&quot;Europe&quot;, de=&quot;Europe&quot;, fr=&quot;Europe&quot;, us=&quot;North America&quot;)) %&gt;% group_by(continent) %&gt;% summarise(mean_flights=mean(nflights, na.rm=TRUE), sd_flights=mean(nflights, na.rm=TRUE), valid_n=sum(!is.na(nflights))) # A tibble: 2 × 4 continent mean_flights sd_flights valid_n &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; 1 Europe 13.7 13.7 870 2 North America 12.2 12.2 195 Video Tutorial: dplyr::summarise() and dplyr::group_by() 1.13 Package lubridate The lubridate package was created to make working with dates and times a little bit easier. While the package has a great deal of funcationality, this tutorial will only focus on a some of the most common elements. Probably the most useful capability of lubridate is its ability to quickly parse out parts of a text date string, no matter the form of that string. Fast parsing is done through a series of functions that are based on the order of the parts of date/time in the text string. Use ymd() if the order is year, month, day, such as “20101215” or “16/7/1” Use mdy() if the order is month, day, year, such as “January 25, 2016” or “5/29/1993” Use dmy() if the order is day, month, year, such as “171210” or “5 January 1990” The results will be the in the format “YYYY-MM-DD” and have a ‘Date’ class library(lubridate) ymd(c(&quot;20101215&quot;, &quot;16/7/1&quot;)) [1] &quot;2010-12-15&quot; &quot;2016-07-01&quot; mdy(c(&quot;January 25, 2016&quot;, &quot;5/29/1993&quot;)) [1] &quot;2016-01-25&quot; &quot;1993-05-29&quot; dmy(c(&quot;171210&quot;, &quot;5 January 1990&quot;)) [1] &quot;2010-12-17&quot; &quot;1990-01-05&quot; If time is also included in the text string, that can also be parsed out, such as ymd_hms() where hms stands for hours, minutes, seconds Additionally, lubridate can easily pull out the specific components that are have class ‘Date’ year(x) returns the year number month(x) returns the number of the month month(x, label=TRUE) returns the month name (abbreviated) day(x) (or mday(x)) returns the number of the day of the month wday(x) returns the number of the day in week, where Sunday = 1 wday(x, label=TRUE) returns the day of the week name (abbreviated) yday(x) returns the number of the day of the year # Use lubridate to create a date class object for my birthday (not really) mybday &lt;- mdy(&quot;March 15, 1973&quot;) year(mybday) [1] 1973 month(mybday) [1] 3 month(mybday, label=TRUE) [1] Mar 12 Levels: Jan &lt; Feb &lt; Mar &lt; Apr &lt; May &lt; Jun &lt; Jul &lt; Aug &lt; Sep &lt; ... &lt; Dec day(mybday) [1] 15 wday(mybday) [1] 5 wday(mybday, label=TRUE) [1] Thu Levels: Sun &lt; Mon &lt; Tue &lt; Wed &lt; Thu &lt; Fri &lt; Sat yday(mybday) [1] 74 1.14 R Markdown and R Notebook R Markdown allows users to create documents that combine code and text. Ultimately, they are used for “reproducible research”. That is, the R Markdown files allow other people to see exactly what was done, and if the data is available to all, other people can reproduce the research. In this class, R Notebooks, which use R Markdown, will be used for the lab assignments. You will write your code in the R Notebook file, and answer the assignment questions with the code your have written. While R Markdown has a great deal of functionality, we will focus on a select few of those features. This cheatsheet may be beneficial. 1.14.1 YAML Header The top of every R Markdown is a section called the YAML header, which is enclosed at the top and bottom with ---. For this class, the only thing in the YAML header that you will need to change is the author: section. Figure 1.10: Change Author in YAML Header 1.14.2 Markdown Syntax When writing text in R Markdown, there isn’t a “point and click” menu to change fonts size or to add italics or bold text or to insert an equation. Instead, it requires the use of “markdown” syntax. The most commonly used are provided below: Plain text Plain text *Italic* Italic **Bold** Bold ***Bold and Italic*** Bold and Italic # Header 1 Header 1 ## Header 2 Header 2 ### Header 3 Header 3 #### Header 4 Header 4 * Unordered list item * Item 2 * Item 2a (indent 4 spaces) * Item 2b Unordered list item Item 2 Item 2a (indent 4 spaces) Item 2b 1. Ordered list item 2. Item 2 1. Item 2a (indent 4 spaces) 2. Item 2b Ordered list item Item 2 Item 2a (indent 4 spaces) Item 2b `verbatim code` vertabim code equation: $y=\\alpha+\\betax$ equation: \\(y=\\alpha+\\beta x\\) (See this file for symbols) 1.14.3 Code Chunks One of the greatest things about R Markdown and R Notebook files is the ability to include code, and run the code, within the file. Putting code in the file is done with code chunks. 1.14.3.1 Inserting a Code Chunk Code chunks can be inserted by clicking on the “Insert Chunk” button in the document toolbar (see Figure 1.11) or by manually typing in the code chunk (see Figure 1.12) Figure 1.11: Inserting a Code Chunk from the Toolbar Figure 1.12: Inserting a Code Chunk Manually 1.14.3.2 Using Code Chunks R Markdown and R Notebook don’t pay attention to anything else going on in your R/RStudio session Any objects, data, packages, or user defined scripts must be in a code chunk However, once they are loaded in a chunk, they do not need to be loaded again in subsequent chunks To run a code chunk, click on the green triangle ( If you run a chunk that does have the necessary object, data, etc., you will get an error message (see Figure 1.13) Figure 1.13: Chunk Error If you need to run previous chunks to load data or packages, click on the gray triangle with the green bar underneath () first, then click on the green triangle (see Figure 1.14) Figure 1.14: Run Previous Chunks, then Run Chunk Once the chunk runs correctly, the result will be shown under the chunk To clear the result, click on the ‘x’ in the upper right hand corner of the results 1.14.3.3 “Knitting” the Results At any time, you can “Knit” the R Notebook file to an HTML document or a PDF document. While working through the document, HTML is usually quicker. When the document is completed, a PDF is more professional looking. To “Knit” the file, click on the down arrow next to “Knit” in the document toolbar, and select how you would like to product the document (see Figure 1.15) By default, a document knitted to HTML will be viewable in the “Viewer” window in the lower right hand side of RStudio. For documents knitted to PDF, RStudio generally opens up a new window with the knitted PDF, from which the file can be saved to a local directory Figure 1.15: Knit a Document 1.15 Working with R Notebook Lab Assignment Files The best way to show how to use the R Notebook files for the Lab Assignments is through video demonstrations. The five video files below will show how to work the files. Video Tutorial: Downloading and Opening the File Video Tutorial: The YAML Header Video Tutorial: Code and Answers (Part 1) Video Tutorial: Code and Answers (Part 2) Video Tutorial: Saving Files and Recognizing Errors "],["examining-and-summarizing-data.html", "Chapter 2 Examining and Summarizing Data 2.1 Introduction 2.2 Visualizations 2.3 Tables and Statistics", " Chapter 2 Examining and Summarizing Data Sources for this chapter: ggplot2: https://ggplot2.tidyverse.org/ 2.1 Introduction Examining and summarizing data involves visualizations (e.g., graphs and charts) and tables. For visualization, the most popular package in R is th ggplot2 package. Data for this chapter: The airlinesat data is used from the MKT4320BGSU course package. Load the package and use the data() function to load the data. # Load course package library(MKT4320BGSU) # Load data data(airlinesat) 2.2 Visualizations 2.2.1 Package ggplot2 2.2.1.1 Introduction First, make sure the ggplot2 library is loaded: library(ggplot2) ggplot2 is based on the basic idea that for a graph, we need three things: Data: ggplot2 is designed to work with data frames Coordinate system: what are the x and y variables Geoms: how is the data being represented (e.g., points, lines, etc.) AND that the plot can be enhance by adding more layers, using + When ggplot is used in the console or from a script, the plot appears in the Viewer tab of the lower-right corner Video Tutorial: Data Visualizations using ggplot (Introduction) 2.2.1.2 Usage A plot starts with the ggplot() function, which requires two arguments: Source of the data, which can be piped in (i.e., %&gt;%) The mapping of the data components This argument is an aesthetic function, aes(), which maps the variable(s) to the coordinate system If the ggplot() function alone is used, the output is simply the coordinate system, but with nothing plotted Because a geom hasn’t been requested ggplot(airlinesat, # Use data frame &#39;airlinesat&#39; aes(x=country, y=nflights)) # Map &#39;country&#39; on x and &#39;nflights&#39; on y Figure 2.1: Call to ggplot() without a geom Other parts of the plot are adding in layers, using + A good analogy is building a house: The call to ggplot() is the foundation, but the structure is built one layer at a time Example: Request a column chart for a discrete x and a continuous y ggplot(airlinesat, # Use data frame &#39;airlinesat&#39; aes(x=country, y=nflights)) + # Map &#39;country&#39; on x and &#39;nflights&#39; on y geom_col() # Ask for column chart as the geom Figure 2.2: ggplot() + geom_col() NOTE: Each geom has a default statistic to plot In this case, it is summing the nflights variable by country We can use dplyr and ggplot2 together to get a different value, such as the mean # Use airlinesat data airlinesat %&gt;% # Group data by &#39;country&#39; group_by(country) %&gt;% # Create summary statistic summarise(mean_nflights=mean(nflights, na.rm=TRUE)) %&gt;% # Pass this results to ggplot and start the plot ggplot(aes(x=country, y=mean_nflights)) + # Note dataset was `piped` # Request column geom geom_col() Figure 2.3: Using dplyr before ggplot to get mean values Using ggplot() can get much more advanced. As the tutorial progresses, many examples of additional layers to a ggplot() will be shown. Video Tutorial: Data Visualizations using ggplot (Basic Usage) Video Tutorial: Data Visualizations using ggplot (Linking with dplyr) 2.2.2 Bar and Column Charts In ggplot, bar charts, geom_bar(), are used for plotting a single discrete variable, while column charts, geom_col(), are used for plotting a discrete variable on the x axis and a continuous variable on the y axis. 2.2.2.1 Bar Charts The standard bar chart provides a count of observations of each category of discrete variable x airlinesat %&gt;% ggplot(aes(x=gender)) + geom_bar() Figure 2.4: Standard bar chart Video Tutorial: Bar Charts with ggplot::geom_bar (Part 1) To get percentages of each category, we need to summarize the data and calculate the proportion for each category airlinesat %&gt;% group_by(gender) %&gt;% # Group data by gender summarise(n=n()) %&gt;% # Create variable with count of each gender mutate(prop=n/sum(n)) %&gt;% # Create variable with proportion by gender ggplot(aes(x=gender, # Variable for the x-axis y=prop)) + # Use &#39;prop&#39; instead of default counts for y-axis geom_bar(stat=&quot;identity&quot;) # Use the value of y as-is Figure 2.5: Bar chart with proportions Video Tutorial: Bar Charts with ggplot::geom_bar (Part 2) To make the chart “pretty”, we change the color of each bar we can add layers for axis labels, use the scales package to have the y-axis show percent, add labels for the bars etc. airlinesat %&gt;% group_by(gender) %&gt;% # Group data by gender summarise(n=n()) %&gt;% # Create variable with count of each gender mutate(prop=n/sum(n)) %&gt;% # Create variable with proportion by gender ggplot(aes(x=gender, # Variable for the x-axis y=prop, # Use &#39;prop&#39; instead of default counts for y-axis fill=gender)) + # Use different color for each bar geom_bar(show.legend=FALSE, # Hide legend stat=&quot;identity&quot;, ) + # Use the value of y as-is scale_y_continuous(labels=scales::label_percent()) + # y-axis labels % labs(x=&quot;Gender&quot;, y=&quot;Percent&quot;) + # Label x- and y-axes geom_text(aes(label=sprintf(&quot;%.1f%%&quot;, prop*100)), # Format label number vjust=.95, # Vertically adjust the labels fontface=&quot;bold&quot;, # Bold typeface color=&quot;white&quot;) # Text color Figure 2.6: Prettier bar chart Video Tutorial: Bar Charts with ggplot::geom_bar (Part 3) 2.2.2.1.1 Bar Chart Variations 2.2.2.1.1.1 Stacked Bar Chart Used to show one discrete variable by another discrete variable, such as data you would see in a cross-tab The x= variable specifies the axis, while the fill= variable stacks the bars by the other variable As with other bar charts, the default is to count observations, so some manipulation is needed to get “100% stacked bar charts” airlinesat %&gt;% group_by(gender, flight_type) %&gt;% # Group data by two discrete variables summarise(n=n()) %&gt;% # Count observations for each combination mutate(prop=n/sum(n)) %&gt;% # Calculate prop WITHIN first grouping variable ggplot(aes(x=gender, y=prop, fill=flight_type)) + geom_bar(position=&quot;fill&quot;, # Stack the bars stat=&quot;identity&quot;) + # Use the value of y as-is scale_y_continuous(labels=scales::label_percent()) + # y-axis labels % labs(x=&quot;Gender&quot;, y=&quot;Percent&quot;, # Label x- and y-axes fill=&quot;Flight Type&quot;) + # Label legend geom_text(aes(label=sprintf(&quot;%.1f%%&quot;, prop*100)), # Format data label position=position_stack(vjust=.95), # Adjust the labels fontface=&quot;bold&quot;, # Bold typeface color=&quot;white&quot;) # Text color Figure 2.7: Stacked bar chart 2.2.2.1.1.2 Side-by-Side Bar Chart Also used to shows one discrete variable by another discrete variable Again, default is to count observations, so some manipulation required to get percentages Percentages can be within a group (like in 100% stacked, see Figure 2.8) or percent of overall total (see Figure 2.9) # NOTE: The code for this chart is nearly identical to the previous figure # ONLY the changes have been commented on below airlinesat %&gt;% group_by(gender, flight_type) %&gt;% summarise(n=n()) %&gt;% mutate(prop=n/sum(n)) %&gt;% ggplot(aes(x=gender, y=prop, fill=flight_type)) + # NOTE: Use position=&quot;dodge&quot; to make bars side-by-side geom_bar(position=&quot;dodge&quot;, stat=&quot;identity&quot;) + scale_y_continuous(labels=scales::label_percent()) + labs(x=&quot;Gender&quot;, y=&quot;Percent&quot;, fill=&quot;Flight Type&quot;) + # NOTE: Use position=position_dodge(width=1) to position labels # in center of each bar horizontally; use vjust=.95 to # position labels at the top of each bar geom_text(aes(label=sprintf(&quot;%.1f%%&quot;, prop*100)), position=position_dodge(width=1), vjust=.95, fontface=&quot;bold&quot;, color=&quot;white&quot;) Figure 2.8: Side-by-side bar chart (% within group) # NOTE: The code for this chart is nearly identical to the previous figure # ONLY the changes have been commented on below airlinesat %&gt;% group_by(gender, flight_type) %&gt;% # NOTE: Use .groups=&quot;drop&quot; to remove the grouping structure after # summarising the data summarise(n=n(), .groups=&quot;drop&quot;) %&gt;% mutate(prop=n/sum(n)) %&gt;% ggplot(aes(x=gender, y=prop, fill=flight_type)) + geom_bar(position=&quot;dodge&quot;, stat=&quot;identity&quot;) + scale_y_continuous(labels=scales::label_percent()) + labs(x=&quot;Gender&quot;, y=&quot;Percent&quot;, fill=&quot;Flight Type&quot;) + geom_text(aes(label=sprintf(&quot;%.1f%%&quot;, prop*100)), position=position_dodge(width=1), vjust=.95, fontface=&quot;bold&quot;, color=&quot;white&quot;) Figure 2.9: Side-by-side bar chart (% of total) Video Tutorial: Bar Charts with ggplot::geom_bar (Part 4) 2.2.2.2 Column Charts The standard column chart provides a sum of continuous variable y of each category of disrete variable x airlinesat %&gt;% ggplot(aes(x=flight_type, y=nflights)) + geom_col() Figure 2.10: Standard column chart To get a different summary statistic, such as mean, we can summarize the data and calculate the summary statistic for each category (and make the graph prettier) airlinesat %&gt;% group_by(flight_type) %&gt;% summarise(mean=mean(nflights)) %&gt;% ggplot(aes(x=flight_type, y=mean, fill=flight_type)) + geom_col(show.legend=FALSE) + labs(x=&quot;Flight Type&quot;, y=&quot;Mean Number of Flights&quot;) + geom_text(aes(label=sprintf(&quot;%.2f&quot;, mean)), # Format label number vjust=.95, # Vertically adjust the labels fontface=&quot;bold&quot;, # Bold typeface color=&quot;white&quot;) # Text color Figure 2.11: Column chart showing means Video Tutorial: Column Charts with ggplot::geom_col (Part 1) 2.2.2.2.1 Side-by-Side Column Chart A side by side column chart can be used to show two discrete variables on the x-axis airlinesat %&gt;% group_by(flight_type, flight_purpose) %&gt;% summarise(mean=mean(nflights), .groups=&quot;drop&quot;) %&gt;% ggplot(aes(x=flight_type, y=mean, fill=flight_purpose)) + geom_col(position=&quot;dodge&quot;) + labs(x=&quot;Flight Type&quot;, y=&quot;Mean Number of Flights&quot;, fill=&quot;Flight Purpose&quot;) + geom_text(aes(label=sprintf(&quot;%.2f&quot;, mean)), position=position_dodge(width=1), vjust=.95, fontface=&quot;bold&quot;, color=&quot;white&quot;) Figure 2.12: Side-by-side column chart Video Tutorial: Column Charts with ggplot::geom_col (Part 2) 2.2.3 Histogram In ggplot, histograms are produced with the geom_histogram() geom, which produces a histogram of a single continuous variable. By default, the y-axis is a count of observations in each “bin” of the x variable A bin is a range of values of the continuous x variable By default, ggplot will produce a histogram with 30 bins, and a message is produced to that effect unless the bins are changed manually airlinesat %&gt;% ggplot(aes(x=age)) + geom_histogram() Figure 2.13: Standard histogram 2.2.3.1 Changing Bins Histograms can look quite different based on the bins used. Bins can be changed in two ways: (1) number of bins; and (2) bin width Changing the number of bins is done with the bins= option For example: geom_histogram(bins=20) Changing the bin width is done with the binwidth= option For example; geom_histogram(binwidth=5) Use the interactive histograms (Figure 2.14 and Figure 2.15 to see how the histograms change Video Tutorial: Histograms with ggplot::geom_histogram (Part 1) Figure 2.14: Interactive histogram for number of bins Figure 2.15: Interactive histogram for bin width 2.2.3.2 Improving the Look You may find the default histogram a little “blah” or tough to read. Just as the look of bar and column charts could be changed, so can the look of histograms airlinesat %&gt;% ggplot(aes(x=age)) + geom_histogram(color=&quot;black&quot;, # Adds red border around each bar fill=&quot;tan&quot;) + # Makes each bar blue labs(x=&quot;Age&quot;, y=&quot;Frequency&quot;) Figure 2.16: Prettier histogram Video Tutorial: Histograms with ggplot::geom_histogram (Part 2) 2.2.3.3 Other Options Instead of the default count of observations, a density histogram can be created, where the sum of the area of the bars adds up to 1 Often, a normal curve is added look of bar and column charts could be changed, so can the look of histograms airlinesat %&gt;% ggplot(aes(x=age)) + geom_histogram(aes(y=..density..), # Request density instead of count color=&quot;black&quot;, # Adds red border around each bar fill=&quot;tan&quot;) + # Makes each bar blue stat_function(fun=function(x) # Adds normal curve ovarlay dnorm(x, mean=mean(airlinesat$age, na.rm=TRUE), # Mean of normal dist sd=sd(airlinesat$age, na.rm=TRUE))) + # StdDev of normal dist labs(x=&quot;Age&quot;, y=&quot;Density&quot;) Figure 2.17: Density histogram with normal curve Video Tutorial: Histograms with ggplot::geom_histogram (Part 3) 2.2.4 Box Plot Box Plots are drawn with the geom_boxplot() geom, which by default creates a box plot for a continuous y variable, but for each level of a discrete x variable. In addition, the standard box plot does not contain “whiskers”. To get a box plot for only the continuous y variable, use x=\"\" as the discrete x variable To add whiskers, include a staplewidth=1 within the geom_boxplot. airlinesat %&gt;% ggplot(aes(x=&quot;&quot;, y=age)) + geom_boxplot(staplewidth = 1) + labs(x=&quot;&quot;, # Remove x axis label y=&quot;Age&quot;) # Make y axis label nicer Figure 2.18: Single box plot with whiskers To make comparisons across a discrete x variable, replaces the x=\"\" from before with x=VARIABLE airlinesat %&gt;% ggplot(aes(x=flight_purpose, y=age)) + geom_boxplot(staplewidth = 1) + labs(x=&quot;Flight Purpose&quot;, y=&quot;Age&quot;) Figure 2.19: Multiple box plot Video Tutorial: Box Plots with ggplot::geom_boxplot 2.2.5 Scatterplot Scatterplots are drawn with the geom_point() geom and are used to show the relationship between two continuous variables Notice the warning given due to missing values (these warnings will be suppressed in other scatterplots below) airlinesat %&gt;% ggplot(aes(x=age, y=s10)) + # s10 is satisfaction with condition of airplane geom_point() Figure 2.20: Standard scatterplot 2.2.5.1 Trendline Scatterplots become more helpful when we add a trend line. The most common trend line is a simple regression line, although others can be used. Use geom_smooth(method=\"lm\", se=FALSE) to add a linear trend line airlinesat %&gt;% ggplot(aes(x=age, y=s10)) + # s10 is satisfaction with condition of airplane geom_point() + geom_smooth(method=&quot;lm&quot;, se=FALSE) + # Add trendline labs(x=&quot;Age&quot;, y=&quot;Satisfaction with Aircraft Condition&quot;) Figure 2.21: Scatterplot with trendline Video Tutorial: Scatterplots with ggplot::geom_point (Part 1) 2.2.5.2 Other Options The color, shape, and size of the points can be changed In addition, they can vary by levels of a discrete variable If a trend line is requested, separate trend lines will be provided for each level of the discrete variable airlinesat %&gt;% ggplot(aes(x=age, y=s10, color=flight_type)) + geom_point(shape=17) + geom_smooth(method=&quot;lm&quot;, se=FALSE) + # Add trendline labs(x=&quot;Age&quot;, y=&quot;Satisfaction with Aircraft Condition&quot;, color=&quot;Flight Type&quot;) Figure 2.22: Scatterplot with different colors for discrete variable Video Tutorial: Scatterplots with ggplot::geom_point (Part 2) 2.3 Tables and Statistics 2.3.1 Frequency Table 2.3.1.1 Base R The table(data$variable) function can produce a one-way frequency table Wrapping the call to table with proportions will create the table with proportions (i.e., percent in each category) table(airlinesat$language) # One way frequency table (counts) English French German 233 10 822 proportions(table(airlinesat$language)) # One way table of proportions English French German 0.218779343 0.009389671 0.771830986 Table 2.1: One-way frequency table using Base R Video Tutorial: Frequency Tables with Base R 2.3.1.2 Package questionr The freq() command from the package questionr produces nice one-way frequency tables (i.e., a frequency table for a single discrete variable) library(questionr) freq(airlinesat$language, # Provide discrete variable cum=TRUE, # Add cumulative percent column total=TRUE) # Add total row at bottom n % val% %cum val%cum English 233 21.9 21.9 21.9 21.9 French 10 0.9 0.9 22.8 22.8 German 822 77.2 77.2 100.0 100.0 Total 1065 100.0 100.0 100.0 100.0 Table 2.2: One-way frequency table using questionr Video Tutorial: Frequency Tables with questionr 2.3.2 Crosstabs 2.3.2.1 Base R Base R does not do a great job of easily creating cross-tabs and testing for independent of the two variables Using base R, a multistep process is required Create the two-way frequency table using the table(rowvar, colvar) function and assign it to a separate object Display the two-way freq table by just using the table name Use the function proportions(tablename, margin) on the newly created object to get column, row, or total percentages proportions(tablename) gives total percentages proportions(tablename, 1) gives row percentages proportions(tablename, 2) gives column percentages Use the function chisq.test(tablename) on the newly created object to run the test of independence # Create two way table crosstab &lt;- table(airlinesat$flight_purpose, # row Variable airlinesat$gender) # Column variable crosstab # Display 2-way freq table female male Business 76 449 Leisure 204 336 proportions(crosstab, 2) # Display column percentages female male Business 0.2714286 0.5719745 Leisure 0.7285714 0.4280255 chisq.test(crosstab) # Run test of independence Pearson&#39;s Chi-squared test with Yates&#39; continuity correction data: crosstab X-squared = 73.386, df = 1, p-value &lt; 2.2e-16 Table 2.3: Cross-tabs using Base R Video Tutorial: Cross-Tabs with Base R 2.3.2.2 Alternative Packages The following packages are not availabe through the BGSU Virtual Computing lab, but can be installed if using R/RStudio on your own machine. These packages produce nicely formatted crosstabs. 2.3.2.2.1 Package sjPlot Use the function tab_xtab(var.row=, var.col=, show.col.prc=TRUE) to get a standard crosstab with column percentages library(sjPlot) tab_xtab(var.row=airlinesat$flight_purpose, var.col=airlinesat$gender, show.col.prc=TRUE) flight_purpose gender Total female male Business 7627.1 % 44957.2 % 52549.3 % Leisure 20472.9 % 33642.8 % 54050.7 % Total 280100 % 785100 % 1065100 % χ2=73.386 · df=1 · φ=0.265 · p=0.000 Table 2.4: Cross-tab using sjPlot Video Tutorial: Cross-Tabs with sjPlot 2.3.2.2.2 Package gmodels FunctionCrossTable(rowvar, colvar, OPTIONS) has many options similar to SPSS library(gmodels) CrossTable(airlinesat$flight_purpose, airlinesat$gender, prop.r=FALSE, # Exclude row percentages prop.t=FALSE, # Exclude total percentages, prop.chisq=FALSE, # Exclude cell contribution to chi-sq digits=2, # 2 digits after decimal point chisq=TRUE, # Request test of independence format=&quot;SPSS&quot;) # Request SPSS formatting Cell Contents |-------------------------| | Count | | Column Percent | |-------------------------| Total Observations in Table: 1065 | airlinesat$gender airlinesat$flight_purpose | female | male | Row Total | --------------------------|-----------|-----------|-----------| Business | 76 | 449 | 525 | | 27.14% | 57.20% | | --------------------------|-----------|-----------|-----------| Leisure | 204 | 336 | 540 | | 72.86% | 42.80% | | --------------------------|-----------|-----------|-----------| Column Total | 280 | 785 | 1065 | | 26.29% | 73.71% | | --------------------------|-----------|-----------|-----------| Statistics for All Table Factors Pearson&#39;s Chi-squared test ------------------------------------------------------------ Chi^2 = 74.58406 d.f. = 1 p = 5.811064e-18 Pearson&#39;s Chi-squared test with Yates&#39; continuity correction ------------------------------------------------------------ Chi^2 = 73.38648 d.f. = 1 p = 1.065938e-17 Minimum expected frequency: 138.0282 Table 2.5: Cross-tab using gmodels Video Tutorial: Cross-Tabs with gmodels 2.3.3 Measures of Centrality and Dispersion 2.3.3.1 Base R Any individual summary statistic can be easily calculated using Base R with functions such as: mean(x) for mean sd(x) for standard deviation quantile(x, .percentile) for percentiles (e.g., ‘.50’ would be median) For summary statistics except for standard deviation, the summary(object) function can be used, where object can be a single variable or an entire data frame # Summary for a single variable summary(airlinesat$nflights) Min. 1st Qu. Median Mean 3rd Qu. Max. 1.00 4.00 8.00 13.42 16.00 457.00 Table 2.6: Summary statistics in R Base, one variable # Subset of airlinesat summary(airlinesat[,c(&quot;age&quot;, &quot;nflights&quot;, &quot;s10&quot;)]) age nflights s10 Min. : 19.00 Min. : 1.00 Min. : 1.00 1st Qu.: 42.00 1st Qu.: 4.00 1st Qu.: 50.00 Median : 50.00 Median : 8.00 Median : 61.00 Mean : 50.42 Mean : 13.42 Mean : 64.54 3rd Qu.: 58.00 3rd Qu.: 16.00 3rd Qu.: 83.00 Max. :101.00 Max. :457.00 Max. :100.00 NA&#39;s :40 Table 2.7: Summary statistics in R Base, multiple variables Summary statistics for a continuous variable by different levels of a discrete variable can also be done in Base R using the tapply(continuous variable, discrete variable, function) function tapply(airlinesat$nflights, # Continous variable to apply the function to airlinesat$flight_purpose, # Discrete, grouping variable summary) # R function to apply by group $Business Min. 1st Qu. Median Mean 3rd Qu. Max. 1.00 6.00 12.00 18.65 25.00 120.00 $Leisure Min. 1st Qu. Median Mean 3rd Qu. Max. 1.000 3.000 4.000 8.337 8.000 457.000 Table 2.8: Summary statistics in R Base, one variable, grouped Video Tutorial: Summary Measures with Base R 2.3.3.2 Package dplyr The dplyr package can also be used to manually create tables of summary statistics One continuous variable airlinesat %&gt;% summarise(mean=mean(age), sd=sd(age), q1=quantile(age, .25), median=quantile(age,.50), q3=quantile(age, .75)) mean sd q1 median q3 1 50.41972 12.27464 42 50 58 Table 2.9: Summary statistics using dplyr, one variable Multiple continuous variables airlinesat %&gt;% select(age, nflights, s10) %&gt;% summary() age nflights s10 Min. : 19.00 Min. : 1.00 Min. : 1.00 1st Qu.: 42.00 1st Qu.: 4.00 1st Qu.: 50.00 Median : 50.00 Median : 8.00 Median : 61.00 Mean : 50.42 Mean : 13.42 Mean : 64.54 3rd Qu.: 58.00 3rd Qu.: 16.00 3rd Qu.: 83.00 Max. :101.00 Max. :457.00 Max. :100.00 NA&#39;s :40 Table 2.10: Summary statistics using dplyr, multiple variables One continuous variable by a discrete/grouping variable airlinesat %&gt;% group_by(flight_purpose) %&gt;% summarise(mean=mean(age), sd=sd(age), q1=quantile(age, .25), median=quantile(age,.50), q3=quantile(age, .75)) # A tibble: 2 × 6 flight_purpose mean sd q1 median q3 &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 Business 48.5 9.91 41 49 55 2 Leisure 52.3 14.0 43 53 63 Table 2.11: Summary statistics using dplyr, one variable, grouped Video Tutorial: Summary Measures with dplyr 2.3.3.3 Package vtable Package vtable produces very nice looking tables of summary statistics, but it isn’t available in BGSU’s Virtual Computer Lab. Use function sumtable(data, vars=\"varname\") to produce the table One continuous variable library(vtable) sumtable(airlinesat, vars=&quot;nflights&quot;) Variable N Mean Std. Dev. Min Pctl. 25 Pctl. 75 Max nflights 1065 13 20 1 4 16 457 Table 2.12: Summary statistics using vtable, one variable Multiple continuous variables sumtable(airlinesat, vars=c(&quot;nflights&quot;,&quot;age&quot;,&quot;s10&quot;), # Use `c()` for multiple variables add.median=TRUE) # Request median Variable N Mean Std. Dev. Min Pctl. 25 Pctl. 50 Pctl. 75 Max nflights 1065 13 20 1 4 8 16 457 age 1065 50 12 19 42 50 58 101 s10 1025 65 21 1 50 61 83 100 Table 2.13: Summary statistics using vtable, multiple variable One or more continuous variables by a discrete/grouping variable sumtable(airlinesat, vars=c(&quot;nflights&quot;,&quot;age&quot;,&quot;s10&quot;), add.median=TRUE, group=&quot;flight_purpose&quot;) Variable N Mean SD Median N Mean SD Median flight_purpose Business Leisure nflights 525 19 18 12 540 8.3 21 4 age 525 48 9.9 49 540 52 14 53 s10 511 62 21 60 514 67 21 65 Table 2.14: Summary statistics using vtable, multiple variables, grouped Video Tutorial: Summary Measures with vtable 2.3.4 Correlation Correlation provides a measure of the strength of association between two continuous variables. 2.3.4.1 Base R Base R can easily provide the correlation and a test of the correlation using the cor.test(variable1, variable2) function By default, it includes only observations that are non-missing in both variables cor.test(airlinesat$age, airlinesat$nflights) Pearson&#39;s product-moment correlation data: airlinesat$age and airlinesat$nflights t = -3.7998, df = 1063, p-value = 0.000153 alternative hypothesis: true correlation is not equal to 0 95 percent confidence interval: -0.17461941 -0.05608231 sample estimates: cor -0.115763 Table 2.15: Correlation with test in Base R Base R can also easily provide a correlation matrix of variables using the cor(data) function By default, correlation will only be calculated for those pairs of variables that have no missing values Use option use=\"pairwise.complete.obs\" to exclude observations that are non-missing in both variables However, Base R cannot produce a correlation matrix with p-values # First create data frame with only variables wanted mycorr &lt;- airlinesat[,c(&quot;age&quot;, &quot;nflights&quot;, &quot;s10&quot;)] # Use function `round` to limit to 3 digits after decimal point round(cor(mycorr, use=&quot;pairwise.complete.obs&quot;), 3) age nflights s10 age 1.000 -0.116 0.167 nflights -0.116 1.000 -0.121 s10 0.167 -0.121 1.000 Table 2.16: Correlation matrix in Base R Video Tutorial: Correlation with Base R 2.3.4.2 Package Hmisc The function rcorr() from the package Hmisc, which is available in the BGSU Virtual Computing Lab, can be used to create correlation matrices also The rcorr() function requires a matrix, so the data frame of variables must be coerced into a matrix first By default, rcorr() produces three separate matrices: correlation, number of observations, and p-values Separate tables can be requested rcorr(as.matrix(dataframe))]]\"r\"]] provides the correlation matrix rcorr(as.matrix(dataframe))]]\"P\"]] provides the matrix of p-values library(Hmisc) rcorr(as.matrix(mycorr)) # NOTE: &#39;mycorr&#39; created in previous code age nflights s10 age 1.00 -0.12 0.17 nflights -0.12 1.00 -0.12 s10 0.17 -0.12 1.00 n age nflights s10 age 1065 1065 1025 nflights 1065 1065 1025 s10 1025 1025 1025 P age nflights s10 age 2e-04 0e+00 nflights 2e-04 1e-04 s10 0e+00 1e-04 Table 2.17: Correlation matrix using Hmisc # Use &#39;round()&#39; function to limit digits in output round(rcorr(as.matrix(mycorr))[[&quot;r&quot;]],4) round(rcorr(as.matrix(mycorr))[[&quot;P&quot;]],5) age nflights s10 age 1.0000 -0.1158 0.1671 nflights -0.1158 1.0000 -0.1206 s10 0.1671 -0.1206 1.0000 age nflights s10 age NA 0.00015 0.00000 nflights 0.00015 NA 0.00011 s10 0.00000 0.00011 NA Table 2.18: Separate correlation matrix output using Hmisc Video Tutorial: Correlation with Hmisc 2.3.4.3 Package sjPlot The function tab_corr() from the sjPlot package produces very nice correlation matrices sjPlot is not available in BGSU’s Virtual Computing Lab library(sjPlot) tab_corr(mycorr, # Data frame of variables to use; created earlier na.deletion = &quot;pairwise&quot;, # Delete obs if either variable is missing corr.method = &quot;pearson&quot;, # Choose Pearson correlation coefficient show.p = TRUE, # Show asterisks for significant correlations digits = 3, # Show three decimal points triangle = &quot;lower&quot;, # Show only lower triangle fade.ns=FALSE) # Do not fade insignficant correlations)   age nflights s10 age       nflights -0.116***     s10 0.167*** -0.121***   Computed correlation used pearson-method with pairwise-deletion. Table 2.19: Correlation matrix output using sjPlot Video Tutorial: Correlation with sjPlot 2.3.4.4 Package GGally The ggpairs() function from package GGally can produce a combination scatterplot and correlation matrix library(GGally) ggpairs(mycorr, # Data frame created earlier lower=list(continuous=wrap(&quot;smooth&quot;, # Adds fit lines... method=&quot;lm&quot;, # Using linear regression... se=FALSE, # Without CI bands color=&quot;blue&quot;)), # Color dots diag=list(continuous=&quot;blankDiag&quot;)) # Sets diagonals to be blank Figure 2.23: Combination scatterplot/correlation matrix using GGally Video Tutorial: Correlation with GGally "],["linear-regression.html", "Chapter 3 Linear Regression 3.1 Introduction 3.2 The lm() Function 3.3 Prediction 3.4 Margin Plots (Manual Process) 3.5 Margin Plots (User-Defined Function)", " Chapter 3 Linear Regression Sources for this chapter: R for Marketing Research ad Analytics, Second Edition (2019). Chris Chapman and Elea McDonnell Feit http://r-marketing.r-forge.r-project.org/index.html ggplot2: https://ggplot2.tidyverse.org/ Data for this chapter: Once again, the airlinesat data is used from the MKT4320BGSU course package. Load the package and use the data() function to load the data. # Load course package library(MKT4320BGSU) # Load data data(airlinesat) 3.1 Introduction Base R is typically sufficient for performing most regression tasks. Some additional packages may be used for “prettier” tables or extracting results to make useful plots. 3.2 The lm() Function Basic linear regression is performed using the lm() function. Usage: lm(formula, data) In R, a formula is represented by dependent variables on the left side separated from the independent variables on the right side by a tilde(~), such as: dv ~ iv1 + iv2 For interactions between independent variables, use either * or : * will include the interaction term AND each main effect : will include ONLY the iteraction term Examples: y ~ x1 + x2*x3 is the same as: \\(y=x_1+x_2+x_3+(x_2\\times x_3)\\) y ~ x1 + x2:x3 is the same as: \\(y=x_1+(x_2\\times x_3)\\) y ~ x1 + x2 + x2:x3 is the same as: \\(y=x_1+x_2+(x_2\\times x_3)\\) Video Tutorial: lm() - Basic Usage If lm() is run by itself, R only outputs the coefficients lm(nps ~ age + nflights, airlinesat) Call: lm(formula = nps ~ age + nflights, data = airlinesat) Coefficients: (Intercept) age nflights 6.786100 0.016985 -0.009112 Table 3.1: Coefficients from lm() call However, if the results of the lm() call are assigned to an object, the summary() function can be used to get much more detailed output model1 &lt;- lm(nps ~ age + nflights, airlinesat) summary(model1) Call: lm(formula = nps ~ age + nflights, data = airlinesat) Residuals: Min 1Q Median 3Q Max -6.988 -1.316 0.440 1.725 7.682 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 6.786100 0.310554 21.852 &lt; 2e-16 *** age 0.016985 0.005815 2.921 0.00357 ** nflights -0.009112 0.003529 -2.582 0.00995 ** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 2.313 on 1062 degrees of freedom Multiple R-squared: 0.01591, Adjusted R-squared: 0.01406 F-statistic: 8.587 on 2 and 1062 DF, p-value: 0.0001997 Table 3.2: Summary results from lm() call Video Tutorial: lm() - Output To get standardized beta coefficients, use the lm_beta() function from the MKT4320BGSU course package. lm_beta(model1, # Saved object with results digits=4) # Number of digits to diplsy Std.Beta (Intercept) 0.0000 age 0.0895 nflights -0.0791 Table 3.3: Standardized Beta Coefficients Video Tutorial: lm() - Standardized Beta Coefficients For “nicer” looking results, the tab_model function from the sjPlot package can be used library(sjPlot) tab_model(model1, # Saved object from before show.stat=TRUE) # Display t-statistic   nps Predictors Estimates CI Statistic p (Intercept) 6.79 6.18 – 7.40 21.85 &lt;0.001 age 0.02 0.01 – 0.03 2.92 0.004 nflights -0.01 -0.02 – -0.00 -2.58 0.010 Observations 1065 R2 / R2 adjusted 0.016 / 0.014 Table 3.4: Summary results from lm() using sjPlot package Standardized beta coefficients can also be obtained library(sjPlot) tab_model(model1, # Saved object from before show.stat=TRUE, # Display t-statistic show.std=TRUE, # Display standardized beta coefficients show.ci=FALSE) # Remove confidence intervals for cleaner table   nps Predictors Estimates std. Beta Statistic p (Intercept) 6.79 0.00 21.85 &lt;0.001 age 0.02 0.09 2.92 0.004 nflights -0.01 -0.08 -2.58 0.010 Observations 1065 R2 / R2 adjusted 0.016 / 0.014 Table 3.5: Summary results from lm() using sjPlot package Video Tutorial: lm() - Results using the sjPlot Package For “nicer” looking results, the summ function from the jtools package can be used NOTE: jtools is not available in BGSU’s Virtual Computing Lab library(jtools) summ(model1, # Saved object from before digits=4) # How many digits to display in each column Observations 1065 Dependent variable nps Type OLS linear regression F(2,1062) 8.5875 R² 0.0159 Adj. R² 0.0141 Est. S.E. t val. p (Intercept) 6.7861 0.3106 21.8516 0.0000 age 0.0170 0.0058 2.9208 0.0036 nflights -0.0091 0.0035 -2.5822 0.0100 Standard errors: OLS Table 3.6: Summary results from lm() using jtools package Standardized beta coefficients can also be obtained library(jtools) summ(model1, # Saved object from before digits=4, # How many digits to display in each column scale=TRUE, # Standardize the IVs transform.response=TRUE) # Standarize the DV Observations 1065 Dependent variable nps Type OLS linear regression F(2,1062) 8.5875 R² 0.0159 Adj. R² 0.0141 Est. S.E. t val. p (Intercept) 0.0000 0.0304 0.0000 1.0000 age 0.0895 0.0306 2.9208 0.0036 nflights -0.0791 0.0306 -2.5822 0.0100 Standard errors: OLS; Continuous variables are mean-centered and scaled by 1 s.d. Table 3.7: Standardized Beta Coefficients from lm() using jtools package Video Tutorial: lm() - Results using the jtools Package 3.3 Prediction The function predict.lm() can be used to predict the DV based on values of the IVs. This function is used in the margin plots covered in the next two sections. To use this function, we must pass a data frame of values to the function, where the data frame contains ALL of the IVs and the value for each IV that we want. Suppose we wanted to predict, with a confidence interval, the nps of someone that is 45 years old and had 25 flights on the airline, and also someone that is 25 years old and had 45 flights on the airline. First, we create the data frame of values (see 1.6.2.1): values &lt;- data.frame(age=c(45, 25), nflights=c(25, 45)) # Create data frame values # Verify values age nflights 1 45 25 2 25 45 Second, the data frame is passed to the predict.lm() function with confidence intervals requested: predict.lm(model1, # The model we are using to predict values, # The data frame of values to predict with interval=&quot;confidence&quot;) # Request confidence interval fit lwr upr 1 7.322601 7.153951 7.491252 2 6.800657 6.431058 7.170255 Video Tutorial: lm() - Prediction 3.4 Margin Plots (Manual Process) In R, margin plots are a multistep process: Use the predictorEffect function from the effects package to create a data frame of predicted values for different values of the focal variable. For continuous focal variables, predictions will be made for 50 evenly-spaced values of the focal variable at mean values of the other variables. If the model has an interaction between a continuous focal variable and a factor variable, predictions will be made for each level of the factor variable. If the model has an interaction between a continuous focal variable and another continuous variable, predictions will be made for 5 evenly-spaced values of the other continuous variable. For factor focal variables, predictions will be made for each level of the factor variable at mean values of the other variables. If the model has an interaction between a factor focal variable and a continuous variable, predictions will be made for 5 evenly-spaced values of the the continuous variable. If the model has an interaction between a factor focal variable and another factor variable, predictions will be made for every combination of the two factor variables. By default, the dataframe will contain the predicted value (fit) and values for a \\(95\\%\\) confidence interval (lower and upper) Use ggplot to create the margin plot Video Tutorial: lm() - Introduction to Margin Plots 3.4.1 Continuous IV (No Interaction) library(effects) # Load package &#39;effects&#39; # Want to predict &#39;nps&#39; for different levels of &#39;age&#39; age.pred &lt;- data.frame(predictorEffect(&quot;age&quot;, # Focal variable model1)) # Use &#39;age.pred&#39; for margin plot age.pred %&gt;% ggplot(aes(x=age, # Age on x-axis y=fit)) + # &#39;nps&#39; prediction on y-axis geom_line(size=1) + # Draw predicted line geom_ribbon(aes(ymin=lower, # Draws the confidence interval bands ymax=upper), alpha=0.2) + # Sets transparency level labs(x=&quot;Age&quot;, y=&quot;Linear Prediciton&quot;) Figure 3.1: Margin plot (continuous IV) Video Tutorial: lm() - Margin Plots for Continuous IV with no Interaction 3.4.2 Separate Margin Plots (No Interaction) If creating separate plots for each continuous IV, it is best to have the prediction (y) variable have the same scale Doing so might take some trial and error after looking at graphs once Use the function plot_grid() from the cowplot package to make the plots appear in the same figure Save each plot as an object, then pass the objects to plot_grid() library(cowplot) # Using dataframe from previous chunk, ask for min/max of the 95% CI adjust axis min(age.pred$lower) [1] 6.601996 max(age.pred$upper) [1] 8.944869 # Save previous plot (for &#39;age&#39;) as plot 1 plot1 &lt;- age.pred %&gt;% ggplot(aes(x=age,y=fit)) + geom_line(size=1) + geom_ribbon(aes(ymin=lower, ymax=upper), alpha=0.2) + labs(x=&quot;Age&quot;, y=&quot;Linear Prediciton&quot;) + scale_y_continuous(limits=c(5.25,9.25)) # Set scale limits for y-axis # Create second plot for &#39;nflights&#39; using procedure above # Because of outliers in &#39;nflights&#39;, use the &#39;focal.levels=&#39; option for more # realistic predictions nflights.pred &lt;- data.frame(predictorEffect(&quot;nflights&quot;, # Focal variable model1, focal.levels=seq(0,150,3))) min(nflights.pred$lower) [1] 5.319659 max(nflights.pred$upper) [1] 7.809707 plot2 &lt;- nflights.pred %&gt;% ggplot(aes(x=nflights, y=fit)) + geom_line(size=1) + geom_ribbon(aes(ymin=lower,ymax=upper),alpha=0.2) + labs(x=&quot;Number of Flights&quot;, y=&quot;Linear Prediciton&quot;) + scale_y_continuous(limits=c(5.25,9.25)) # Set scale limits for y-axis # Use &#39;cowplot&#39; function &#39;plot_grid&#39; to combine plots cowplot::plot_grid(plot1,plot2) Figure 3.2: Separate margin plots (continuous factor IVs) Video Tutorial: lm() - Side-by-Side Margin Plots using cowplot Package 3.4.3 Factor IV (No Interaction) Margin plots for a factor IV without an interaction consist of a point and \\(95\\%\\) confidence interval error bars # Run new model with flight_purpose included model2 &lt;- lm(nps ~ age + nflights + flight_purpose, airlinesat) summary(model2) Call: lm(formula = nps ~ age + nflights + flight_purpose, data = airlinesat) Residuals: Min 1Q Median 3Q Max -7.130 -1.160 0.521 1.808 6.306 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 6.644742 0.313158 21.218 &lt; 2e-16 *** age 0.014749 0.005844 2.524 0.01175 * nflights -0.006540 0.003624 -1.805 0.07140 . flight_purposeLeisure 0.433007 0.147317 2.939 0.00336 ** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 2.304 on 1061 degrees of freedom Multiple R-squared: 0.02386, Adjusted R-squared: 0.0211 F-statistic: 8.646 on 3 and 1061 DF, p-value: 1.136e-05 Table 3.8: Summary results of model with factor variable # Create data frame with values to be plotted fp.pred &lt;- data.frame(predictorEffect(&quot;flight_purpose&quot;, model2)) # Create plot fp.pred %&gt;% ggplot(aes(x=flight_purpose, y=fit, group=1)) + # Need to draw line between points geom_point(size=4) + geom_line(color=&quot;orange&quot;) + geom_errorbar(aes(ymin=lower, ymax=upper), width=.5) + labs(x=&quot;Flight Purpose&quot;, y=&quot;Linear Prediction&quot;) Figure 3.3: Margin plot (factor IV) Video Tutorial: lm() - Margin Plots for Factor IV with No Interaction 3.4.4 Continuous IV (Interaction with Factor IV) Margin plots when for a continuous IV interaction with a factor IV are done in much the same way, but require an aes(color=factor, fill=factor) to produce different colored lines for each level of the factor # Run new model with &#39;age&#39; and &#39;flight_purpose&#39; interaction model3 &lt;- lm(nps ~ age*flight_purpose + nflights, airlinesat) summary(model3) Call: lm(formula = nps ~ age * flight_purpose + nflights, data = airlinesat) Residuals: Min 1Q Median 3Q Max -6.9177 -1.0298 0.3193 1.8402 6.1721 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 5.675998 0.510101 11.127 &lt; 2e-16 *** age 0.034704 0.010148 3.420 0.000651 *** flight_purposeLeisure 1.912145 0.632942 3.021 0.002579 ** nflights -0.006487 0.003616 -1.794 0.073088 . age:flight_purposeLeisure -0.029724 0.012372 -2.403 0.016450 * --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 2.299 on 1060 degrees of freedom Multiple R-squared: 0.02915, Adjusted R-squared: 0.02549 F-statistic: 7.957 on 4 and 1060 DF, p-value: 2.551e-06 Table 3.9: Summary results of model with continuous IV and factor IV interaction # Create data frame with values to be plotted age.pred &lt;- data.frame(predictorEffect(&quot;age&quot;, model3)) # Create plot age.pred %&gt;% ggplot(aes(x=age, y=fit, color=flight_purpose, fill=flight_purpose)) + # color based on factor geom_line(size=1) + # Draw predicted line geom_ribbon(aes(ymin=lower, # Draws the confidence interval bands ymax=upper), alpha=0.2) + # Sets transparency level labs(x=&quot;Age&quot;, y=&quot;Linear Prediciton&quot;, color=&quot;Flight Purpose&quot;, fill=&quot;Flight Purpose&quot;) + theme(legend.position=&quot;bottom&quot;) Figure 3.4: Margin plot (continuous IV with factor IV interaction) Video Tutorial: lm() - Margin Plots for Continuous IV with Factor IV Interaction 3.4.5 Factor IV (Interaction with Continuous IV) Margin plots for a factor IV interaction with a continuous IV are done in much the same way, but require an facet_wrap(~continuousIV) to produce different different plots for evenly-spaced values of the continuous IV # Create data frame with values to be plotted # By default, 5 evenly-spaced values for &#39;age&#39; will be created, but for use # with &#39;facet_wrap&#39;, set &#39;xlevels=4&#39; fp.pred &lt;- data.frame(predictorEffect(&quot;flight_purpose&quot;, model3, xlevels=4)) # Create plot fp.pred %&gt;% ggplot(aes(x=flight_purpose, y=fit, group=1)) + geom_point(size=4) + geom_line(color=&quot;orange&quot;) + geom_errorbar(aes(ymin=lower, ymax=upper), width=.5) + facet_wrap(~age) + labs(x=&quot;Flight Purpose&quot;, y=&quot;Linear Prediction&quot;) Figure 3.5: Margin plot (factor IV with continuous IV interaction) Video Tutorial: lm() - Margin Plots for Factor IV with Continuous IV Interaction 3.4.6 Continuous IV (Interaction with Continuous IV) # Run new model with &#39;age&#39; and &#39;overall_sat&#39; interaction model4 &lt;- lm(nps ~ age*overall_sat + nflights, airlinesat) summary(model4) Call: lm(formula = nps ~ age * overall_sat + nflights, data = airlinesat) Residuals: Min 1Q Median 3Q Max -7.9218 -0.9129 0.4645 1.4897 5.7636 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 7.181885 0.748391 9.596 &lt; 2e-16 *** age -0.023019 0.014642 -1.572 0.11623 overall_sat -0.051154 0.177249 -0.289 0.77294 nflights -0.007328 0.003370 -2.175 0.02986 * age:overall_sat 0.009427 0.003448 2.734 0.00636 ** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 2.205 on 1060 degrees of freedom Multiple R-squared: 0.1068, Adjusted R-squared: 0.1035 F-statistic: 31.7 on 4 and 1060 DF, p-value: &lt; 2.2e-16 Table 3.10: Summary results of model with continuous IV and continuous IV interaction # Create data frame with values to be plotted # By default, 5 evenly-spaced values for &#39;overall_sat&#39; will be created, but for # easier interpretation, set &#39;xlevels=4&#39; age.pred &lt;- data.frame(predictorEffect(&quot;age&quot;, model4, xlevels=4)) # Create plot age.pred %&gt;% ggplot(aes(x=age, y=fit, color=factor(overall_sat), fill=factor(overall_sat))) + # color based on factor geom_line(size=1) + # Draw predicted line geom_ribbon(aes(ymin=lower, # Draws the confidence interval bands ymax=upper), alpha=0.2) + # Sets transparency level labs(x=&quot;Age&quot;, y=&quot;Linear Prediciton&quot;, color=&quot;Overall Satisfaction&quot;, fill=&quot;Overall Satisfaction&quot;) + theme(legend.position=&quot;bottom&quot;) Figure 3.6: Margin plot (continuous IV with continuous IV interaction) Video Tutorial: lm() - Margin Plots for Continuous IV with Continuous IV Interaction 3.5 Margin Plots (User-Defined Function) 3.5.1 Overview The mymp user-defined function can produce a margin plot (and margin table) for a single variable or for a variable that has an interaction with another variable. Requires the following packages: ggplot2 dplyr ggeffects insight Usage: mymp(model, focal, int=NULL) where: model is a saved linear regression (lm) model or binary logistic regression (glm, family=\"binomial\") model. focal is the name of the focal predictor variable. Must be in quotations. int is the name of the interaction predictor variable. Must be in quotations. Can be excluded if focal variable only wanted (or no interaction exists). Objects returned: $ptable is the margin table used to produce the plot $plot is the margin plot Notes: The function will automatically determine the variable type (i.e., continuous or factor) and create the plot accordingly. 3.5.2 Examples Using model3 from above, which was the following model: \\(nps=\\alpha+\\beta_0age+\\beta_1flight\\_purpuse+\\beta_3age\\times{flight\\_purpose}+\\beta_4nflights+\\varepsilon\\) In this model, age and nflights are continuous, and flight_purpose is a factor. # Focal variable only ## Output will be both &quot;$ptable&quot; and &quot;$plot&quot; mymp(model=model3, focal=&quot;nflights&quot;) $plot $ptable # Predicted values of nps nflights | Predicted | 95% CI --------------------------------- 1 | 7.63 | 7.46, 7.79 60 | 7.25 | 6.89, 7.61 115 | 6.89 | 6.16, 7.62 170 | 6.53 | 5.41, 7.65 229 | 6.15 | 4.61, 7.69 288 | 5.77 | 3.81, 7.72 343 | 5.41 | 3.07, 7.75 457 | 4.67 | 1.52, 7.82 # Focal variable and interaction ## Output will be &quot;$plot&quot; only mymp(model3, &quot;age&quot;, &quot;flight_purpose&quot;)$plot "],["logistic-regression-binary.html", "Chapter 4 Logistic Regression (Binary) 4.1 Introduction 4.2 The glm() Function 4.3 Logistic Regression using glm() 4.4 Estimate with Training Sample Only 4.5 Classification Matrix 4.6 ROC Curve 4.7 Gain/Lift Charts and Tables 4.8 Sensitivity/Specificity Plot 4.9 Margin Plots", " Chapter 4 Logistic Regression (Binary) Sources for this chapter: R for Marketing Research ad Analytics, Second Edition (2019). Chris Chapman and Elea McDonnell Feit http://r-marketing.r-forge.r-project.org/index.html ggplot2: https://ggplot2.tidyverse.org/ Data for this chapter: The directmktg data is used from the MKT4320BGSU course package. Load the package and use the data() function to load the data. # Load the course package library(MKT4320BGSU) # Load the data data(directmktg) 4.1 Introduction Base R is typically sufficient for performing the basics of logisitic regression, but to get some of the outputs required, I have created some user defined functions that are available in the course package. or_table.R() produces Odds Ratio Coefficients logreg_cm() produces the Classification Matrix logreg_roc() produces the ROC Curves gainlift() produces Gain/Lift tables and charts logreg_cut() produces the Sensitivity/Specificity Plot Video Tutorial: Logistic Regression - Introduction 4.2 The glm() Function glm stands for Generalized Linear Model, and this function can be used with a variety of dependent variables by specifying different family=\"FAMILY\" options *lm(dv ~ iv1 + iv2, data) is the same as `glm(dv ~ iv1 + iv2, data, family=“gaussian”) Usage: glm(formula, data, family) 4.3 Logistic Regression using glm() Binary logistic regression is performed using the glm() function when the family=\"binomial\" is specified. Usage: glm(formula, data, family=\"binonmial\") family=\"binomial\" tells R to use logistic regression on a binary dependent variable If glm(formula, data, family=\"binomial\") is run by itself, R only outputs the **Logit formulation* coefficients (and some other measures) glm(buy ~ age + gender, directmktg, family=&quot;binomial&quot;) Call: glm(formula = buy ~ age + gender, family = &quot;binomial&quot;, data = directmktg) Coefficients: (Intercept) age genderFemale -8.02069 0.18954 -0.09468 Degrees of Freedom: 399 Total (i.e. Null); 397 Residual Null Deviance: 521.6 Residual Deviance: 336.1 AIC: 342.1 Table 4.1: Logit Coefficients from glm() call Video Tutorial: glm() Basic Usage However, if the results of the glm() call are assigned to an object, the Base R summary() function can be used to get much more detailed output, but requires manual calculation of McFadden’s Pseudo-\\(R^2\\) prelim &lt;- glm(buy ~ age + gender, directmktg, family=&quot;binomial&quot;) summary(prelim) Call: glm(formula = buy ~ age + gender, family = &quot;binomial&quot;, data = directmktg) Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -8.02069 0.78700 -10.191 &lt;2e-16 *** age 0.18954 0.01926 9.842 &lt;2e-16 *** genderFemale -0.09468 0.27354 -0.346 0.729 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 521.57 on 399 degrees of freedom Residual deviance: 336.14 on 397 degrees of freedom AIC: 342.14 Number of Fisher Scoring iterations: 5 # Manually calculate McFadden&#39;s Pseudo R-sq Mrsq &lt;- 1-prelim$deviance/prelim$null.deviance cat(&quot;McFadden&#39;s Pseudo-Rsquared = &quot;, Mrsq) McFadden&#39;s Pseudo-Rsquared = 0.3555239 Table 4.2: Summary results from glm() call Video Tutorial: glm() Output For “nicer” looking results, the package jtools can be used library(jtools) summ(prelim, # Saved object from before digits=4, # How many digits to display in each column model.info = FALSE) # Suppress extraneous information χ²(2) 185.4317 Pseudo-R² (Cragg-Uhler) 0.5092 Pseudo-R² (McFadden) 0.3555 AIC 342.1413 BIC 354.1157 Est. S.E. z val. p (Intercept) -8.0207 0.7870 -10.1915 0.0000 age 0.1895 0.0193 9.8422 0.0000 genderFemale -0.0947 0.2735 -0.3461 0.7293 Standard errors: MLE Table 4.3: Summary results from glm() using jtools package Video Tutorial: glm() Output Using the jtools Package 4.3.1 Odds Ratio Coefficients To get the Odds Ratio coefficients, use the or_table() function from the MKT4320BGSU course package. Usage: or_table(MODEL, DIGITS, CONF) MODEL is the name of the object with results of the glm() call DIGITS is the number of digits to round the values to in the table CONF is the confidence interval level (e.g., 95 = 95%) or_table(prelim, # Saved logistic regression model from above 4, # Number of digits to round output to 95) # Level of confidence Parameter OR Est p 2.5% 97.5% (Intercept) (Intercept) 0.0003 0.0000 0.0001 0.0015 age age 1.2087 0.0000 1.1639 1.2552 genderFemale genderFemale 0.9097 0.7293 0.5322 1.5550 Table 4.4: Odds Ratio Coefficients Odds Ratio coefficients can also be obtained from the summ function of the jtools package summ(prelim, # Saved object from before digits=4, # How many digits to display in each column exp = TRUE, # Obtain exponentiated coefficients (i.e., Odds Ratio) model.info = FALSE) # Suppress extraneous information χ²(2) 185.4317 Pseudo-R² (Cragg-Uhler) 0.5092 Pseudo-R² (McFadden) 0.3555 AIC 342.1413 BIC 354.1157 exp(Est.) 2.5% 97.5% z val. p (Intercept) 0.0003 0.0001 0.0015 -10.1915 0.0000 age 1.2087 1.1639 1.2552 9.8422 0.0000 genderFemale 0.9097 0.5322 1.5550 -0.3461 0.7293 Standard errors: MLE Table 4.5: Odds Ratio Coefficients using jtools package Video Tutorial: glm() Odds Ratio Coefficients 4.4 Estimate with Training Sample Only Generally, it is good practice to use a training sample and a testing/holdout sample to see how well the model performs “out of sample”. To do this, the data must be split into two groups: train and test 4.4.1 Creating train and test Samples While this can be done in a number of ways, the package caret has a very useful function that attempts to balance the percent of “positive” cases in both samples, while still creating random samples After running this procedure, two new data frames will be created One containing the training data, train One containing the testing/holdout data, test Two methods are available: using the splitsample function from the MKT4320BGSU package or manually using caret To use the splitsample function Usage: splitsample(data, outcome, p=0.75, seed=4320) data is the name of the dataframe to be used to estimate the model outcome is the name of the outcome variable (i.e., dependent variable) for the model to be estimated p is the percent of the data to be assigned to the training sample; defaults to 0.75 seed is an integer to be used for random number generation; defaults to 4320 Requires the caret package Will create two new dataframes in your environment: train and test splitsample(directmktg, buy) To use the caret package manually, follow the code below # Use &#39;caret&#39; package to create training and test/holdout samples # This will create two separate dataframes: train and test library(caret) # Load the &#39;caret package&#39; # Start by setting a random number seed so that the same samples # will be created each time set.seed(4320) # Create a dataframe of row numbers that should be in the &#39;train&#39; sample inTrain &lt;- createDataPartition(y=directmktg$buy, # Outcome variable p=.75, # Percent of sample to be in &#39;train&#39; list=FALSE) # Put result in matrix # Select only rows from data that are in &#39;inTrain&#39;; assign to &#39;train&#39; train &lt;- directmktg[inTrain,] # Select only rows from data that not in &#39;inTrain&#39;; assign to &#39;test&#39; test &lt;- directmktg[-inTrain,] Video Tutorial: Creating Training and Test Samples 4.4.2 Run Model with only Training Sample Once completed, run the model on the training sample only Goodness-of-Fit measures can be obtained from the results model &lt;- glm(buy ~ age + gender, train, family=&quot;binomial&quot;) summ(model, # &#39;jtools&#39; results; use &#39;summary&#39; for Base R 4, model.info=FALSE) χ²(2) 130.57 p 0.00 Pseudo-R² (Cragg-Uhler) 0.48 Pseudo-R² (McFadden) 0.33 AIC 268.37 BIC 279.49 Est. S.E. z val. p (Intercept) -7.71 0.87 -8.81 0.00 age 0.18 0.02 8.52 0.00 genderFemale -0.01 0.31 -0.04 0.97 Standard errors: MLE; Continuous predictors are mean-centered and scaled by 1 s.d. The outcome variable remains in its original units. or_table(model) Parameter OR Est p 2.5% 97.5% (Intercept) (Intercept) 0.0004 0.000 0.0001 0.0025 age age 1.1996 0.000 1.1505 1.2509 genderFemale genderFemale 0.9873 0.967 0.5399 1.8056 Table 4.6: Logistic Regression Results for Training Sample Video Tutorial: Model Fit - Goodness-of-Fit Measures 4.5 Classification Matrix To get the Classification Matrix, use the logreg_cm() function from the MKT4320BGSU course package. Usage: logreg_cm(MOD, DATA, \"POS\", CUTOFF=) MOD is the name of the object with results of the glm() call DATA is the data set for which the Classification Matrix should be produced (i.e., original, training, or testing) \"POS\" is the level of the factor variable that is the SUCCESS level CUTOFF= is the cutoff threshold; default is 0.5 This function requires the package caret, which should already be loaded from the splitting of the data # Classification Matrix for training sample logreg_cm(model, # Name of the results object train, # Use training sample &quot;Yes&quot;) # Level of &#39;buy&#39; that represents success/true Confusion Matrix and Statistics Reference Prediction No Yes No 179 37 Yes 14 71 Accuracy : 0.8306 95% CI : (0.7833, 0.8712) No Information Rate : 0.6412 P-Value [Acc &gt; NIR] : 3.179e-13 Kappa : 0.6136 Mcnemar&#39;s Test P-Value : 0.002066 Sensitivity : 0.6574 Specificity : 0.9275 Pos Pred Value : 0.8353 Neg Pred Value : 0.8287 Prevalence : 0.3588 Detection Rate : 0.2359 Detection Prevalence : 0.2824 Balanced Accuracy : 0.7924 &#39;Positive&#39; Class : Yes PCC = 53.99% Table 4.7: Classification Matrix for Training Sample Video Tutorial: Model Fit - Classification Matrix 4.6 ROC Curve To get the ROC curve, use the user defined function ``logreg_roc() function from the MKT4320BGSU course package. Usage: logreg_roc(MOD, DATA) MOD is the name of the object with results of the glm() call DATA is the data set for which the ROC should be produced (i.e., original, training, or testing) This function requires the package pROC, which needs to be loaded # Load &#39;pROC&#39; package library(pROC) # ROC Curve for the training sample logreg_roc(model, # Name of the results object train) # Use training sample Figure 4.1: ROC Curve for Training Sample Video Tutorial: Model Fit - ROC Curve 4.7 Gain/Lift Charts and Tables To get the Gain/Lift charts and tables , use the gainlift() function from the MKT4320BGSU course package. Usage: OBJ.NAME &lt;- gainlift(MOD, TRAIN, TEST, \"POS\") OBJ.NAME is the name of the object to assign the results to MOD is the name of the object with results of the glm() call TRAIN is the name of the data frame containing the training sample TEST is the name of the data frame containing the test/holdout sample \"POS\" is the level of the factor variable that is the SUCCESS level This function requires the ggplot2, dplyr, and tidyr packages, which need to be loaded first This user defined function returns a list of four objects To use, assign the result to an object name, and then call one of the four objects returned from the function # Load necessary packages (if not already loaded) library(ggplot2) library(dplyr) library(tidyr) # Call the function and assign to object named &#39;glresults&#39; glresults &lt;- gainlift(model, # Name of the glm results object train, # Name of the training data frame test, # Name of the testing data frame &quot;Yes&quot;) # Level that represents success/true OBJ.NAME$gaintable returns the Gain table glresults$gaintable # A tibble: 20 × 3 `% Sample` Holdout Training &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 0.05 0.114 0.130 2 0.1 0.229 0.269 3 0.15 0.371 0.370 4 0.2 0.457 0.5 5 0.25 0.6 0.602 6 0.3 0.714 0.667 7 0.35 0.8 0.704 8 0.4 0.8 0.731 9 0.45 0.829 0.769 10 0.5 0.886 0.815 11 0.55 0.914 0.861 12 0.6 0.943 0.870 13 0.65 0.971 0.889 14 0.7 1 0.944 15 0.75 1 0.954 16 0.8 1 0.972 17 0.85 1 0.991 18 0.9 1 1 19 0.95 1 1 20 1 1 1 Table 4.8: Gain Table OBJ.NAME$gainplot returns the Gain plot glresults$gainplot Figure 4.2: Gain Plot OBJ.NAME$lifttable returns the Lift table glresults$lifttable # A tibble: 20 × 3 `% Sample` Holdout Training &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 0.05 2.83 2.60 2 0.1 2.51 2.69 3 0.15 2.63 2.48 4 0.2 2.38 2.51 5 0.25 2.48 2.42 6 0.3 2.44 2.23 7 0.35 2.33 2.02 8 0.4 2.03 1.83 9 0.45 1.86 1.71 10 0.5 1.79 1.64 11 0.55 1.68 1.57 12 0.6 1.58 1.46 13 0.65 1.50 1.37 14 0.7 1.43 1.35 15 0.75 1.34 1.28 16 0.8 1.25 1.22 17 0.85 1.18 1.17 18 0.9 1.11 1.11 19 0.95 1.05 1.06 20 1 1 1 Table 4.9: Lift Table OBJ.NAME$liftplot returns the Lift plot glresults$liftplot Figure 4.3: Lift Plot Video Tutorial: Model Performance - Gain and Lift 4.8 Sensitivity/Specificity Plot To get the Sensitivity/Specificity plot, use the logreg_cut() function from the MKT4320BGSU course package. Usage: logreg_cut(MOD, DATA, \"POS\") MOD is the name of the object with results of the glm() call DATA is the data set for which the plot should be produced (i.e., original, training, or testing) \"POS\" is the level of the factor variable that is the SUCCESS level This function requires the ggplot2 package, which needs to be loaded first # Load necessary packages library(ggplot2) # Sensitivity/Specificity Plot for Training Sample logreg_cut(model, # Name of the results object train, # Use training sample &quot;Yes&quot;) # Level of &#39;buy&#39; that represents success/true Figure 4.4: Sensitivity/Specificity Plot for Training Sample Video Tutorial: Logistic Regression - Sensitivity/Specificity Plots 4.9 Margin Plots Margin plots are done in much the same way as with linear regression margin plots # Create plot for &#39;age&#39; and assign to &#39;p1&#39; p1 &lt;- mymp(model, &quot;age&quot;)$plot # Create plot for &#39;gender&#39; and assign to &#39;p2&#39; p2 &lt;- mymp(model, &quot;gender&quot;)$plot #Use &#39;cowplot&#39; to put into single plot cowplot::plot_grid(p1,p2) Figure 4.5: Margin plots for variables in model Video Tutorial: Logistic Regression - Margin Plots "],["cluster-analysis.html", "Chapter 5 Cluster Analysis 5.1 Introduction 5.2 Preparation 5.3 Hierarchical Agglomerative Clustering 5.4 k-Means Clustering 5.5 Describing clusters", " Chapter 5 Cluster Analysis Sources for this chapter: R for Marketing Research ad Analytics, Second Edition (2019). Chris Chapman and Elea McDonnell Feit http://r-marketing.r-forge.r-project.org/index.html Data for this chapter: The ffseg data is used from the MKT4320BGSU course package. Load the package and use the data() function to load the data. # Load the course package library(MKT4320BGSU) # Load the data data(ffseg) 5.1 Introduction Base R is typically sufficient for performing the basics of both hierarchical and k-means cluster analysis, but to get some of the outputs required more easily and more efficiently, I have created some user defined functions. You should download these functions and save them in your working directory. clustop provides Duda-Hart and psuedo-\\(T^2\\) indices for hierarchical agglomerative clustering cldescr describes variables based on cluster membership myhc produces a dendrogram and cluster sizes and percents for hierarchical agglomerative clustering wssplot produces a scree plot for \\(k\\)-means ksize produces cluster size and proportion tables for \\(k\\)-means kcenters produces cluster center table and plot from \\(k\\)-means 5.2 Preparation For both hierarchical agglomerative and k-means clustering, we usually prepare our data for clustering In other words, choose which variable to use for clustering Package dplyr is usually the best tool for this library(dplyr) # Store variables selected using dplyr to &#39;segvar&#39; clvar &lt;- ffseg %&gt;% select(quality, price, healthy, variety, speed) * To standardize the clustering variables, use the `scale` function * Usage: `scale(data)` * To store as a data frame, wrap the command in `data.frame()` # Standardize &#39;clvar&#39; df and store as &#39;sc.clvar&#39; sc.clvar &lt;- data.frame(scale(clvar)) Video Tutorial: Cluster Analysis Introduction and Preparation 5.3 Hierarchical Agglomerative Clustering 5.3.1 Base R In Base R, hierarchical cluster analysis is done in multiple steps, Use the dist() function to create a similarity/dissimilarity matrix Use the hclust() function to perform hierarchical cluster analysis on the matrix from (1) Determine how many clusters are desired using a dendrogram and/or the stopping indices from package NbClust 5.3.1.1 Creating the similarity/dissimilarity matrix Usage: dist(data, method=\"\") where: data is the (scaled) cluster variable data method=\"\" indicates the distance measure: method=\"euclidean\" provides Euclidean distance method=\"maximum\" provides Maximum distance method=\"manhattan\" provides Absolute distance method=\"binary\" provides a distance measure for a set of binary-only variables NOTE: other choices exist, but for MKT 4320, our focus is on these four # Create the similarity/dissimilarity matrix and save as object &#39;dist&#39; dist &lt;- dist(sc.clvar, # Scaled data from earlier method=&quot;euclidean&quot;) # Euclidean distance measure Video Tutorial: HCA in Base R - Creating Similarity Matrix 5.3.1.2 Perform hierarchical clustering Usage: hclust(d, method=\"\") where: d is the similarity/dissimilarity matrix method=\"\" indicates the linkage method: method=\"single\" provides Single linkage method=\"complete\" provides Complete linkage method=\"average\" provides Average linkage method=\"ward.D\" provides Ward’s linkage NOTE: other choices exist, but for MKT 4320, our focus is on these four # Preform hierarchical clustering and save as object &#39;hc&#39; hc &lt;- hclust(dist, # similarity/dissimilarity matrix from earlier method=&quot;ward.D&quot;) # Ward&#39;s linkage method # NOTE: The similarity/dissimilarity matrix can be done within the call # to &#39;hclust&#39; hc1 &lt;- hclust(dist(sc.clvar, method=&quot;euclidean&quot;), method=&quot;ward.D&quot;) 5.3.1.3 Create a dendrogram Usage: plot(x) where: x is a hierarchical clustering object # Create dendrogram of object hc plot(hc) Video Tutorial: HCA in Base R - Running the Analysis 5.3.1.4 Stopping indices To get the Duda-Hart index, and the pseudo-\\(T^2\\), the NbClust package is used This package is not available in BGSU’s Virtual Computing Lab Usage: NbClust(data, distance=\"\", method=\"\", min.nc=, max.nc=, index=\"\")$All.index where: data is the (scaled) cluster variable data distance=\"\" indicates the distance measure using the same options from the dist function above method=\"\" indicates the linkage method using the same options from the hclust option above min.nc= and max.nc= indicate the minimum and maximum number of clusters to examine index=\"\" indicates what measure is wanted: index=\"duda\" uses the Duda-Hart index index=\"pseudot2 uses the pseudo-\\(T^2\\) index $All.index requests only the index values be returned # After installing package for the first time, load the &#39;NbClust&#39; package library(NbClust) # Get Duda-Hart Index NbClust(sc.clvar, # Scaled cluster variable data from earlier distance=&quot;euclidean&quot;, # Euclidean distance measure method=&quot;ward.D&quot;, # Ward&#39;s linkage min.nc=1, # Show between 1 and... max.nc=10, # ... 10 clusters index=&quot;duda&quot;)$All.index # Request Duda-Hart index 1 2 3 4 5 6 7 8 9 10 0.7974 0.8367 0.8435 0.8490 0.7448 0.8628 0.8222 0.8206 0.6950 0.6470 # Get pseudo-T2 NbClust(sc.clvar, distance=&quot;euclidean&quot;, method=&quot;ward.D&quot;, min.nc=1, max.nc=10, index=&quot;pseudot2&quot;)$All.index 1 2 3 4 5 6 7 8 190.5756 88.3818 54.7376 50.5151 58.5770 41.3604 36.1142 40.0002 9 10 46.9583 40.9146 Video Tutorial: HCA in Base R - Stopping Indices using NbClust 5.3.2 User Defined Functions The myhc.R user defined function can produce the results with one or two passes of the function Requires the following packages: dendextend dplyr NbClust The results should be saved to an object Usage: myhc(data, dist=\"\", method=\"\", cuts, clustop=\"\") where: data is the (scaled) cluster variable data dist=\"\" indicates the distance measure: dist=\"euc\" provides Euclidean distance dist=\"euc2\" provides Euclidean Squared distance dist=\"max\" provides Maximum distance dist=\"abs\" provides Absolute distance dist=\"bin\" provides a distance measure for a set of binary-only variables method=\"\" indicates the linkage method: method=\"single\" provides Single linkage method=\"complete\" provides Complete linkage method=\"average\" provides Average linkage method=\"ward\" provides Ward’s linkage cuts indicates how many clusters (optional): Examples: cuts=3; cuts=c(2,4,5) clustop=\"\" indicates if stopping indices are wanted clustop=\"Y\" if indices are wanted clustop=\"N\" if indices are not wanted Objects returned: If cuts are provided: Dendrogram of the top \\(n\\) branches, where \\(n\\) is the highest number of clusters provided by cuts Table of cluster sizes ($kcount) Table of cluster size percentages ($kperc) hclust object ($hc) Stopping indices for 1 to 10 clusters, if requested ($stop) If cuts are not provided: Dendrogram with all branches Stopping indices for 1 to 10 clusters, if requested ($stop) Video Tutorial: HCA Using myhc.R (Part 1) Examples: No cuts with stopping indices # Both myhc.R and clustop.R need to be &quot;sourced&quot; eg1 &lt;- myhc(sc.clvar, &quot;euc&quot;, &quot;ward&quot;, clustop=&quot;Y&quot;) # Dendrogram will get produced automatically # Call eg1$stop to get table of stopping indices eg1$stop Num.Clusters Duda.Hart pseudo.t.2 1 1 0.7974 190.5756 2 2 0.8367 88.3818 3 3 0.8435 54.7376 4 4 0.8490 50.5151 5 5 0.7448 58.5770 6 6 0.8628 41.3604 7 7 0.8222 36.1142 8 8 0.8206 40.0002 9 9 0.6950 46.9583 10 10 0.6470 40.9146 One cut without stopping indices eg2 &lt;- myhc(sc.clvar, &quot;max&quot;, &quot;ward&quot;, cuts=5, clustop=&quot;N&quot;) # Dendrogram will get produced automatically # call eg2$kcount and eg2$kperc to get cluster sizes eg2$kcount Cluster k_5_Count 1 1 244 2 2 229 3 3 127 4 4 91 5 5 61 eg2$kperc Cluster k_5_Percent 1 1 32.45 2 2 30.45 3 3 16.89 4 4 12.10 5 5 8.11 Multiple cuts without stopping indices eg3 &lt;- myhc(sc.clvar, &quot;abs&quot;, &quot;ward&quot;, cuts=c(2,3,4,6), clustop=&quot;N&quot;) # Dendrogram will get produced automatically # call eg3$kcount and eg3$kperc to get cluster sizes eg3$kcount Cluster k_2_Count k_3_Count k_4_Count k_6_Count 1 1 537 344 215 205 2 2 215 215 205 153 3 3 NA 193 193 139 4 4 NA NA 139 120 5 5 NA NA NA 73 6 6 NA NA NA 62 eg3$kperc Cluster k_2_Percent k_3_Percent k_4_Percent k_6_Percent 1 1 71.41 45.74 28.59 27.26 2 2 28.59 28.59 27.26 20.35 3 3 NA 25.66 25.66 18.48 4 4 NA NA 18.48 15.96 5 5 NA NA NA 9.71 6 6 NA NA NA 8.24 Video Tutorial: HCA with myhc.R (Part 2) Video Tutorial: HCA with myhc.R (Part 3) 5.3.3 Cluster membership Use the cutree() function to get cluster membership for the specified number of clusters Usage: cutree(tree, k=) where: tree is an hclust object from Base R methods or from myhc function k= is the number of clusters to retrieve Assign cluster membership to original data, cluster variables, or both # Create new variables in original data based on cluster membership # Need to use &#39;as.factor()&#39; to classify variable as factor ffseg$K3 &lt;- as.factor(cutree(hc, # &#39;hclust&#39; object from Base R earlier k=3)) # Number of clusters to retrieve ffseg$K4 &lt;- as.factor(cutree(eg3$hc, # &#39;hclust&#39; object from call to &#39;myhc&#39; earlier k=4)) # Number of clusters to retrieve # Create new data frame of scaled clustering variables # with cluster membership appended # &#39;cbind&#39; stands for column bind sc.cldesc &lt;- cbind(sc.clvar, # Scaled cluster variables K3=as.factor(cutree(hc, k=3))) # Cluster membership variable Video Tutorial: Assigning Cluster Membership after HCA with cutree(https://youtu.be/86uktpw0jSQ) 5.4 k-Means Clustering 5.4.1 Base R \\(k\\)-Means clustering is done mostly in Base R, but there is a couple user defined functions to help Process: Run wssplot.R user defined function to get a scree plot Based on scree plot, use ksize() user defined function to examine the cluster sizes for several solutions Run kmeans() for desired solution Assign cluster membership for desired number of clusters to original data, cluster variables, or both 5.4.1.1 Scree plot The wssplot.R user defined function produces a scree plot for 1 to \\(n\\) clusters Requires the ggplot2 package Usage: wssplot(data, nc=, seed=) where: data is the (scaled) cluster variable data nc= takes an integer value and is the maximum number of clusters to plot; default is 15 seed= is a random number seed for reproducible results; default is 4320 wssplot(sc.clvar) # Produces scree plot with default 15 clusters and 4320 seed 5.4.1.2 Cluster sizes The ksize.R user defined function produces a count and proportion tables for the selected \\(k\\) solutions The results should be saved to an object Usage: ksize(data, centers=, nstart=, seed=) where: data is the (scaled) cluster variable data centers= takes one or more integers for the \\(k\\) cluster solutions to be examined nstart= takes an integer value for the number of random starting points to try; default is 25 seed= is a random number seed for reproducible results; default is 4320 Objects returned: Table of cluster sizes ($kcount) Table of cluster size percentages ($kperc) ks &lt;- ksize(sc.clvar, # Scaled cluster variables from earlier centers=c(3,4,5), # Request for 3, 4, and 5 cluster solutions nstart=25, # Request 25 random starting sets seed=4320) # Set seed to 4320 for reproducible results ks$kcount # Cluster sizes Num_Clusters k_3_Count k_4_Count k_5_Count 1 1 308 211 205 2 2 238 191 167 3 3 206 187 150 4 4 NA 163 124 5 5 NA NA 106 ks$kperc # Cluster percentages Num_Clusters k_3_Percent k_4_Percent k_5_Percent 1 1 40.96 28.06 27.26 2 2 31.65 25.40 22.21 3 3 27.39 24.87 19.95 4 4 NA 21.68 16.49 5 5 NA NA 14.10 Video Tutorial: k-Means Cluster Analysis - How Many Clusters? 5.4.1.3 kmeans function Usage: kmeans(data, centers=, nstart=) where: data is the (scaled) cluster variable data centers= takes an integer value for the number of clusters desired nstart= takes an integer value for the number of random starting points to try Results should be assigned to an object NOTE 1: For reproducible results, set.seed() should be run immediately before running kmeans() NOTE 2: nstart= should be same value as above Use the saved $cluster object to assign cluster membership set.seed(4320) # Set random number seed # Run kmeans() for 4 clusters and assign to object k3 k4 &lt;- kmeans(sc.clvar, # Scaled cluster variables from earlier centers=4, # Request 3-cluster solution nstart=25) # Request 25 random starting sets ffseg$KM4 &lt;- as.factor(k4$cluster) Video Tutorial: Using the kmeans() Function 5.5 Describing clusters 5.5.1 cldescr.R The cldescr.R user defined function can be used to describe the clusters on both cluster variables and other variables that may be in the dataset The results should be assigned to an object Usage: cldescr(data, var=\"\", vtype=c(\"F\", \"C\"), cvar=\"\" where: data is the original data or (scaled) cluster variable data with cluster membership attached var=\"\" contains the name of the variable to examine by cluster membership vtype=\"\" takes “F” if var is a factor variable or “C” if var is a continuous variable cvar=\"\" contains the name of the cluster membership variable If vtype=\"F\" with more than two levels, the factor variable is split into dummy variables (1=True, 0=False) for each level of the factor If vtype=\"F\" with only two levels, the only the first level of the factor variable is shown as a dummy variable (1=True, 0=False) If vtype=\"C\" a list (using c()) of variables can be provided Objects returned Table of means ($means) If vtype=\"F\", one column per level of factor Table of ANOVA p-values ($aovp) Table(s) of Tukey HSD multiple comparisons for any variables where the ANOVA p-value\\(&lt;0.1\\) (tukey) Video Tutorial: Describing clusers using cldescr.R (Part 1) 5.5.1.1 Examples Describing hierarchical clustering using clustering variables hc.cv &lt;- cldescr(sc.cldesc, # Scaled cluster variables w/ cluster membership var=c(&quot;quality&quot;, &quot;price&quot;, &quot;healthy&quot;, # List of cluster variables &quot;variety&quot;, &quot;speed&quot;), vtype=&quot;C&quot;, # All variables are continuous cvar=&quot;K3&quot;) # Cluster membership variable hc.cv$means Cluster quality price healthy variety speed 1 1 0.7033 0.0515 0.7903 0.5729 0.3159 2 2 -0.5419 0.5722 -0.5865 -0.3641 0.0258 3 3 -0.3189 -1.0589 -0.3964 -0.3907 -0.5989 hc.cv$aovp Variable p.value 1 quality 0 2 price 0 3 healthy 0 4 variety 0 5 speed 0 # hc.cv$tukey # NOT SHOWN BECAUSE USUALLY ALL SIGNIFICANTLY DIFFERENT Describing hierarchical clustering or \\(k\\)-means using non-clustering continuous variables done the same as previous example Describing hierarchical clustering or \\(k\\)-means using non-clustering factor variables # Factor variable &#39;live&#39; on k-means solution km.fv &lt;- cldescr(ffseg, var=&quot;live&quot;, vtype=&quot;F&quot;, cvar=&quot;KM4&quot;) km.fv$means Cluster Commuter Off.Campus On.Campus 1 1 0.1123 0.4545 0.4332 2 2 0.0613 0.4417 0.4969 3 3 0.1623 0.3665 0.4712 4 4 0.0758 0.4929 0.4313 km.fv$aovp Variable p.value 1 Commuter 0.0069 2 Off.Campus 0.0805 3 On.Campus 0.5349 km.fv$tukey $Commuter diff p adj 2-1 -0.0509 0.3977 3-1 0.0500 0.3776 4-1 -0.0365 0.6286 3-2 0.1010 0.0101 4-2 0.0145 0.9681 4-3 -0.0865 0.0229 $Off.Campus diff p adj 2-1 -0.0128 0.9950 3-1 -0.0881 0.3101 4-1 0.0383 0.8677 3-2 -0.0752 0.4848 4-2 0.0512 0.7550 4-3 0.1264 0.0528 # Factor variable &#39;gender&#39; on hierarchcial clustering solution hc.fv &lt;- cldescr(ffseg, var=&quot;gender&quot;, vtype=&quot;F&quot;, cvar=&quot;K3&quot;) hc.fv$means Cluster Female 1 1 0.8182 2 2 0.6783 3 3 0.5917 hc.fv$aovp Variable p.value 1 Female 0 hc.fv$tukey diff p adj 2-1 -0.1399 0.0004 3-1 -0.2265 0.0000 3-2 -0.0866 0.1100 Video Tutorial: Describing clusers using cldescr.R (Part 2) Video Tutorial: Describing clusers using cldescr.R (Part 3) 5.5.2 kcenters.R For \\(k\\)-Means, the kcenters.R user defined function can be used to describe the cluster centers Requires ggplot2 package The results should be assigned to an object Usage: kcenters(kobject) where: kobject is the name of a saved \\(k\\)-means object Objects returned Table of means ($table) ggplot object ($plot) Describing \\(k\\)-means clustering using cluster centers km.cent &lt;- kcenters(k4) km.cent$table quality price healthy variety speed Cluster 1 0.86830982 0.5282993 0.8952494 0.93322588 0.5295407 1 2 -1.15981355 -0.1062743 -0.9446355 -0.91358591 -0.4716217 2 3 0.22194885 -0.9606064 0.3494969 -0.16288116 -0.5958141 3 4 -0.07448606 0.4834435 -0.3800472 0.02612117 0.4343635 4 km.cent$plot Video Tutorial: Describing clusers using kcenters.R "],["principal-components-analysis.html", "Chapter 6 Principal Components Analysis 6.1 Introduction 6.2 Base R 6.3 User Defined Function", " Chapter 6 Principal Components Analysis Sources for this chapter: R for Marketing Research and Analytics, Second Edition (2019). Chris Chapman and Elea McDonnell Feit http://r-marketing.r-forge.r-project.org/index.html Data for this chapter: The greekbrands data is used from the MKT4320BGSU course package. Load the package and use the data() function to load the data. # Load the course package library(MKT4320BGSU) # Load the data data(greekbrands) 6.1 Introduction Base R is typically sufficient for performing the basics of principal components analysis, but to get some of the outputs required more easily and more efficiently, I have created a user defined function, which is part of the MKT4320BGSU package. pcaex provides an eigenvalue table, scree plot, unrotated and rotated factor loading tables, and the principal components R object 6.2 Base R 6.2.1 prcomp() function The prcomp() function performs PCA Usage: prcomp(formula, data=, scale=TRUE, rank=) where: formula is a formula with no response variables, but rather only the numeric variables to be included if not all variables in data are to be included No response variable means the formula is written as: ~var1 + var2 + var3 + ... + var4 data= is the name of the dataframe scale=TRUE standardizes the variables before running the PCA rank= is the number of components to retain; default is all When saved to an object, the following components are saved: $sdev is the standard deviations of the principal components (i.e., the square roots of the eigenvalues) $rotation is the unroated factor loadings $x is the factor scores Example: perform PCA on \\(serious\\), \\(fun\\), \\(bargain\\), \\(trendy\\), and \\(value\\) with only two components retained pcaout &lt;- prcomp(~serious+fun+bargain+trendy+value, # Variables to include data=greekbrands, # Data frame to use scale=TRUE, # Standardize the variables rank=2) # Retain only first two components 6.2.2 Eigenvalue table To get the eigenvalue table, we must square the $sdev component of the PCA object eigtable &lt;- data.frame(components=seq(1:5), # column with component #&#39;s pcaout$sdev^2) # Eigenvalues eigtable components pcaout.sdev.2 1 1 2.0722697 2 2 1.2747721 3 3 0.8111322 4 4 0.5913799 5 5 0.2504461 6.2.3 Unrotated loadings Unrotated factor loadings are in the $rotation component of the PCA object pcaout$rotation PC1 PC2 serious 0.006484917 -0.73514845 fun -0.179503188 0.65827780 bargain 0.596338877 0.07600771 trendy -0.469318304 -0.14191980 value 0.625984684 0.01756980 Rotated loadings Rotated loadings are not automatically created. Instead, we must use the varimax(pcaobject$rotation)$loadings command to obtain them. By default, only rotated loadings greater than 0.4 are shown. varimax(pcaout$rotation)$loadings Loadings: PC1 PC2 serious -0.101 -0.728 fun 0.677 bargain 0.601 trendy -0.485 value 0.622 PC1 PC2 SS loadings 1.0 1.0 Proportion Var 0.2 0.2 Cumulative Var 0.2 0.4 6.3 User Defined Function The pcaex user defined function can produce the results with one or two passes of the function Requires the following packages: ggplot2 dplyr The results should be saved to an object Usage: pcaex(data, group=\"\", pref=\"\", comp=) where: data is the PCA variable data group=\"\" is the name of the grouping variable Can be excluded if no grouping variable pref=\"\" is the name of the preference variable Can be excluded if no preference variable comp= is the number of components to retain Default is NULL if all components are wanted Objects returned: If comp is NOT provided: Scree plot ($plot) Table of eigenvalues ($table) If comp is provided: Table of eigenvalues ($table) Unrotated factor loading table ($unrotated) Rotated factor loading table ($rotated) PCA object ($pcaobj) When a group= variable is provided, the PCA will be performed on an aggregated data frame (i.e., mean values by group) 6.3.1 Preparation We need to pass a data frame to the user defined function containing the variables to be used (and maybe a preference and group/brand variable, see below) In our class, the data set will often be used for creating a perceptual map, so we may also have a grouping variable (e.g., brand or product name) and a preference variable Package dplyr is usually the best tool for this For this tutorial, we will perform a PCA using the greekbrands dataframe We will use only the following attributes: \\(perform\\), \\(leader\\), \\(fun\\), \\(serious\\), \\(bargain\\), \\(value\\) The data also has a preference variable, \\(pref\\) and a group variable, \\(brand\\), but we do not always want to use them. library(dplyr) # Store variables selected to &#39;pcadata1&#39; (WITHOUT group and pref variables) pcadata1 &lt;- greekbrands %&gt;% select(perform, leader, fun, serious, bargain, value) # Store variables selected to &#39;pcadata2&#39; (INCLUDES group and pref variables) pcadata2 &lt;- greekbrands %&gt;% select(perform, leader, fun, serious, bargain, value, pref, brand) 6.3.2 Examples 6.3.2.1 WITHOUT group= or pref= options All components gb1.all &lt;- pcaex(pcadata1) # PCA data created earlier # Do not include &#39;comp&#39; to get all components # Call gb1.all$table to get eigenvalue table gb1.all$table Component Eigenvalue Difference Proporation Cumulative 1 1 2.2293 0.5454 0.3716 0.3716 2 2 1.6839 0.8876 0.2806 0.6522 3 3 0.7963 0.1545 0.1327 0.7849 4 4 0.6418 0.2433 0.1070 0.8919 5 5 0.3985 0.1484 0.0664 0.9583 6 6 0.2501 NA 0.0417 1.0000 # Call gb1.all$plot to get scree plot gb1.all$plot Two components gb1.2comp &lt;- pcaex(pcadata1, # PCA data created earlier comp=2) # Request 2 components # Call gb1.2comp$unrotated to get unrotated factor loadings gb1.2comp$unrotated PC1 PC2 Unexplained perform 0.4683 0.1568 0.4697 leader 0.5336 0.2093 0.2914 fun -0.3774 -0.0522 0.6778 serious 0.4760 0.2589 0.3821 bargain 0.2228 -0.6689 0.1359 value 0.2780 -0.6438 0.1298 # Call gb1.2comp$rotated to get rotated factor loadings gb1.2comp$rotated PC1 PC2 Unexplained perform 0.4933 -0.0233 0.4697 leader 0.5732 0.0021 0.2914 fun -0.3708 0.0879 0.6778 serious 0.5374 0.0691 0.3821 bargain -0.0343 -0.7042 0.1359 value 0.0263 -0.7007 0.1298 6.3.2.2 WITH group= or pref= options All components gb2.all &lt;- pcaex(pcadata2, # PCA data created earlier group=&quot;brand&quot;, # Grouping variable pref=&quot;pref&quot;) # Preference variable # Do not include &#39;comp&#39; to get all components # Call gb2.all$table to get eigenvalue table gb2.all$table Component Eigenvalue Difference Proporation Cumulative 1 1 3.4180 1.5468 0.5697 0.5697 2 2 1.8712 1.4213 0.3119 0.8815 3 3 0.4500 0.2527 0.0750 0.9565 4 4 0.1973 0.1567 0.0329 0.9894 5 5 0.0405 0.0175 0.0068 0.9962 6 6 0.0231 NA 0.0038 1.0000 # Call gb2.all$plot to get scree plot gb2.all$plot Two components gb2.2comp &lt;- pcaex(pcadata2, # PCA data created earlier group=&quot;brand&quot;, # Grouping variable pref=&quot;pref&quot;, # Preference variable comp=2) # Request 2 components # Call gb2.2comp$unrotated to get unrotated factor loadings gb2.2comp$unrotated PC1 PC2 Unexplained perform 0.4455 0.0934 0.3054 leader 0.4970 0.1817 0.0941 fun -0.5005 -0.0351 0.1416 serious 0.4712 0.2503 0.1239 bargain 0.1718 -0.6815 0.0299 value 0.2293 -0.6557 0.0159 # Call gb2.2comp$rotated to get rotated factor loadings gb2.2comp$rotated PC1 PC2 Unexplained perform 0.4533 -0.0409 0.3054 leader 0.5284 0.0284 0.0941 fun -0.4889 0.1127 0.1416 serious 0.5238 0.1016 0.1239 bargain -0.0350 -0.7020 0.0299 value 0.0275 -0.6941 0.0159 "],["pca-perceptual-maps.html", "Chapter 7 PCA Perceptual Maps 7.1 Introduction 7.2 User Defined Function", " Chapter 7 PCA Perceptual Maps Sources for this chapter: R for Marketing Research and Analytics, Second Edition (2019). Chris Chapman and Elea McDonnell Feit http://r-marketing.r-forge.r-project.org/index.html Data for this chapter: The greekbrands data is used from the MKT4320BGSU course package. Load the package and use the data() function to load the data. # Load the course package library(MKT4320BGSU) # Load the data data(greekbrands) 7.1 Introduction Base R can produce basic perceptual maps from a PCA object, but cannot create a joint-space map easily. For joint-space maps, better looking perceptual maps, and to make the process easier, I have created a user defined function, which is part of the MKT4320BGSU package. percmap returns a ggplot created perceptual (or joint-space) map. 7.2 User Defined Function 7.2.1 Preparation For the user defined function, we must pass the function a data frame with the variables to be used in creating the principal components, the grouping variable (i.e., brand/product name), and if applicable, the preference variable The data frame does not need to be aggregated, but must contain ONLY those variables library(dplyr) # For a perceptual map, store variables selected using dplyr to &#39;pmdata&#39; pmdata &lt;- greekbrands %&gt;% select(perform, leader, fun, serious, bargain, value, brand) # For a joint space map, store variable selected using dplyr to &#39;jsmdata&#39; jsmdata &lt;- greekbrands %&gt;% select(perform, leader, fun, serious, bargain, value, pref, brand) 7.2.2 Using the function The percmap user defined function can easily product a perceptual map or joint-space map based on the first two principal components Requires the following packages: ggplot2 dplyr Usage: percmap(data, group=\"\", pref=\"\") where: data is the PCA variable data group=\"\" is the name of the grouping variable pref=\"\" is the name of the preference variable Can be excluded if no preference variable Returns: A perceptual map if pref is not included A joint space map if pref is included Examples: Perceptual Map percmap(pmdata, group=&quot;brand&quot;) Joint Space Map percmap(jsmdata, group=&quot;brand&quot;, pref=&quot;pref&quot;) "],["ab-testing-and-uplift-modeling.html", "Chapter 8 A/B Testing and Uplift Modeling 8.1 Introduction 8.2 Randomization check 8.3 Average Treatment Effect 8.4 Uplift Modling using Regression 8.5 LIFT Plots", " Chapter 8 A/B Testing and Uplift Modeling Data for this chapter: The email.camp.w data is used from the MKT4320BGSU course package. Load the package and use the data() function to load the data. # Load the course package library(MKT4320BGSU) # Load the data data(emailcampw) # Note: the dataframe is called email.camp.w 8.1 Introduction While A/B testing and Uplift modeling can be preformed with mostly base R functions, several user-defined functions that are part of the MKT4320BGSUpackage have been created to make the process more streamlined and consistent. Data for this chapter 8.2 Randomization check To perform a randomization check for the treatment and control groups for an A/B test, use the rcheck function. This function checks if the characteristics/covariates used for uplift modeling from an A/B test were randomly assigned to the test and control groups. To use the function, we must pass it a dataframe containing the covariates we want to use to check randomization. We must also provide it with the name of the treatment variable, and the name(s) of the outcome variabe(s) if they are included in the dataframe. 8.2.1 Using the rcheck function Requires the following packages: fastDummies htmlTable (if option nice=\"ht\" is used) flextable (if option nice=\"ft\" is used) Usage: rcheck(data, treatment, outcome=NULL, nice=c(\"no\",\"ft\", \"ht\")) where: data is the name of the dataframe containing the treatment variable and the covariates. treatment is the variable name identifying the treatment variable. Must be in quotations. outcome is the name or names of the variables that identifies the outcome variables. Default value is NULL. Must be in quotations. nice is the format for the output; can be: \"no\" for standard output \"ft\" for output using the flextable package \"ht\" for output using the htmlTable package Returns: A table containing the results of the randomization check 8.2.1.1 Examples Example 1: Standard output rcheck(email.camp.w, &quot;promotion&quot;, c(&quot;visit&quot;, &quot;spend&quot;), nice=&quot;no&quot;) variable treatment_mean control_mean sd recency recency 5.810 5.725 3.504 history history 245.995 242.539 253.384 womens womens 0.545 0.539 0.498 newbie newbie 0.497 0.493 0.500 zip_Rural zip_Rural 0.143 0.148 0.353 zip_Surburban zip_Surburban 0.459 0.445 0.498 zip_Urban zip_Urban 0.398 0.406 0.490 channel_Multichannel channel_Multichannel 0.122 0.120 0.326 channel_Phone channel_Phone 0.436 0.439 0.496 channel_Web channel_Web 0.442 0.441 0.497 scale_mean_diff p_val recency 0.024 0.227 history 0.014 0.495 womens 0.011 0.574 newbie 0.007 0.719 zip_Rural -0.014 0.497 zip_Surburban 0.027 0.185 zip_Urban -0.017 0.403 channel_Multichannel 0.006 0.782 channel_Phone -0.005 0.809 channel_Web 0.001 0.968 Example 2: flextable output rcheck(email.camp.w, &quot;promotion&quot;, c(&quot;visit&quot;, &quot;spend&quot;), nice=&quot;ft&quot;) .cl-0d3e9688{}.cl-0d3681d2{font-family:'Arial';font-size:11pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-0d3681e6{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-0d3982ce{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-0d3982d8{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:1pt;padding-top:1pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-0d3982d9{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:1pt;padding-top:1pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-0d399c8c{width:0.75in;background-color:transparent;vertical-align: bottom;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0d399c8d{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0d399c96{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0d399c97{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0d399ca0{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}VariableMeanSDScaled Mean Differencep-valueTreatmentControlrecency5.8105.7253.5040.0240.227history245.995242.539253.3840.0140.495womens0.5450.5390.4980.0110.574newbie0.4970.4930.5000.0070.719zip_Rural0.1430.1480.353-0.0140.497zip_Surburban0.4590.4450.4980.0270.185zip_Urban0.3980.4060.490-0.0170.403channel_Multichannel0.1220.1200.3260.0060.782channel_Phone0.4360.4390.496-0.0050.809channel_Web0.4420.4410.4970.0010.968 8.3 Average Treatment Effect To examine the average treatment effect both without control variables with control variables to account for observed heterogeneity, use the abate function. This function uses linear regression to calculate the average treatment effects both without controls and with controls. The function returns a flextable object. 8.3.1 Using the abate function Requires the following packages: dplyr gtsummary flextable Usage: abate(model, treatement) where: model is an existing linear regression (lm) object containing all control variables and the treatment variable. Treatment variable should appear as the first independent variable. treatment is the variable name identifying the treatment variable. Must be in quotations. Returns: A flextable object containing the results. 8.3.1.1 Examples Example: # Create the &#39;lm&#39; models ate.visit &lt;- lm(visit ~ promotion + recency + history + zip + womens, data=email.camp.w) ate.spend &lt;- lm(spend ~ promotion + recency + history + zip + womens, data=email.camp.w) # Use the function abate(ate.visit, &quot;promotion&quot;) .cl-0e476b0e{}.cl-0e4008a0{font-family:'Arial';font-size:14pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-0e4008b4{font-family:'Arial';font-size:11pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-0e4008be{font-family:'Arial';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-0e42af4c{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2pt;padding-top:2pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-0e42af56{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2pt;padding-top:2pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-0e42af60{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:1pt;padding-top:1pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-0e42af61{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:1pt;padding-top:1pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-0e42af6a{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:1pt;padding-top:1pt;padding-left:15pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-0e42c798{width:1.304in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0e42c799{width:0.757in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0e42c7a2{width:0.82in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0e42c7a3{width:1.304in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0e42c7ac{width:0.757in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0e42c7ad{width:0.82in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0e42c7b6{width:1.304in;height:0.157in;background-color:transparent;vertical-align: top;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0e42c7b7{width:0.757in;height:0.157in;background-color:transparent;vertical-align: top;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0e42c7c0{width:0.82in;height:0.157in;background-color:transparent;vertical-align: top;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0e42c7c1{width:1.304in;height:0.157in;background-color:transparent;vertical-align: top;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0e42c7ca{width:0.757in;height:0.157in;background-color:transparent;vertical-align: top;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0e42c7cb{width:0.82in;height:0.157in;background-color:transparent;vertical-align: top;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0e42c7d4{width:1.304in;height:0.157in;background-color:transparent;vertical-align: top;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0e42c7d5{width:0.757in;height:0.157in;background-color:transparent;vertical-align: top;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0e42c7d6{width:0.82in;height:0.157in;background-color:transparent;vertical-align: top;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} WithoutControlsWithControlsCharacteristicBetap-valueBetap-value(Intercept)0.106&lt;0.0010.151&lt;0.001promotion0.049&lt;0.0010.050&lt;0.001recency-0.006&lt;0.001history0.000&lt;0.001zipRural—Surburban-0.053&lt;0.001Urban-0.065&lt;0.001womens0.046&lt;0.001p-value&lt;0.001&lt;0.001R²0.0050.024 abate(ate.spend, &quot;promotion&quot;) .cl-0f325b14{}.cl-0f2ac016{font-family:'Arial';font-size:14pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-0f2ac020{font-family:'Arial';font-size:11pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-0f2ac02a{font-family:'Arial';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-0f2d73c4{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2pt;padding-top:2pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-0f2d73ce{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2pt;padding-top:2pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-0f2d73d8{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:1pt;padding-top:1pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-0f2d73e2{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:1pt;padding-top:1pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-0f2d73e3{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:1pt;padding-top:1pt;padding-left:15pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-0f2d8ad0{width:1.304in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0f2d8ae4{width:0.668in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0f2d8aee{width:0.82in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0f2d8aef{width:0.718in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0f2d8af8{width:1.304in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0f2d8af9{width:0.668in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0f2d8b02{width:0.82in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0f2d8b03{width:0.718in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0f2d8b0c{width:1.304in;height:0.157in;background-color:transparent;vertical-align: top;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0f2d8b0d{width:0.668in;height:0.157in;background-color:transparent;vertical-align: top;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0f2d8b16{width:0.82in;height:0.157in;background-color:transparent;vertical-align: top;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0f2d8b17{width:0.718in;height:0.157in;background-color:transparent;vertical-align: top;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0f2d8b20{width:1.304in;height:0.157in;background-color:transparent;vertical-align: top;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0f2d8b21{width:0.668in;height:0.157in;background-color:transparent;vertical-align: top;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0f2d8b2a{width:0.82in;height:0.157in;background-color:transparent;vertical-align: top;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0f2d8b2b{width:0.718in;height:0.157in;background-color:transparent;vertical-align: top;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0f2d8b34{width:1.304in;height:0.157in;background-color:transparent;vertical-align: top;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0f2d8b3e{width:0.668in;height:0.157in;background-color:transparent;vertical-align: top;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0f2d8b3f{width:0.82in;height:0.157in;background-color:transparent;vertical-align: top;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0f2d8b48{width:0.718in;height:0.157in;background-color:transparent;vertical-align: top;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} WithoutControlsWithControlsCharacteristicBetap-valueBetap-value(Intercept)0.651&lt;0.0011.2650.011promotion0.4360.1080.4500.097recency-0.0810.042history0.0000.703zipRural—Surburban-0.5960.144Urban0.0980.814womens0.0490.858p-value0.110.032R²0.0000.001 8.4 Uplift Modling using Regression To perform a uplift modeling using regression, we will use the reguplift function. This function performs uplift modeling based on either logistic regression (for binary outcomes) or linear regression (for continuous outcomes). The function uses the two-model, indirect modeling approach. In order to use the function, we must first create our base model. The base model is usually a model with no interactions included, along with the treatment variable. If known interactions are to be used, the base model can include the interactions also. The base model must contain the treatment variable as the first independent variable. Base model examples: # Base model for binary outcome variable email.visit &lt;- glm(visit ~ promotion + recency + history + zip + womens, data=email.camp.w, family=&quot;binomial&quot;) # Base model for continuous outcome variable email.spend &lt;- lm(visit ~ promotion + recency + history + zip + womens, data=email.camp.w) 8.4.1 Using the reguplift function Requires the following packages: ggplot2 gtsummary (if option ct=\"Y\" is used) flextable (if option ct=\"Y\" is used or if option int=\"Y\" is used) Usage: reguplift(model, treatment, pdata=NULL,ng=10, ar=NULL, int=\"N\", ct=\"N\") where: model is a logistic or linear regression model saved results. The model must have been run where the treatment variable was the first term in the right-hand side of the model formula, followed by all independent variables. For option int=\"Y\", no interaction terms should have been included in the original model. treatment is the variable name identifying the treatment variable. Must be in quotations. pdata is the data upon which to calculate the lift. Default is NULL, in which case the lift will be calculated using the original model data. ng is the number of groups to split the data for the group output table and the plots. Must be an integer between 5 and 20. Default is 10. ar is the aspect ratio for the plots. Default is NULL. int is an indicator if an interaction check between independent variables is desired (int=\"Y\") or not (int=\"N\"). Default is “N”. ct is an indicator if comparison tables between treatment levels is desired (ct=\"Y\") or not (ct=\"N\"). Default is “N”. Rarely used. Returns: A list containing the following objects. $group is a table of lift results by ordered group based on ng $all is the original model data or pdata (if provided) with lift values appended. $plots is a list containing three plots: $qini is a Qini plot containing a Qini coefficient $uplift is a mean uplift plot by ordered group $c.gain is a cumulative gain plot by ordered group $int is an interaction table showing significant potential interactions. $ct is a comparison table between treatment levels. 8.4.1.1 Examples Using all default options # Save results as an object visit.uplift &lt;- reguplift(email.visit, &quot;promotion&quot;) spend.uplift &lt;- reguplift(email.spend, &quot;promotion&quot;) # Examine results visit.uplift$plots $qini $uplift $c.gain spend.uplift$plots $qini $uplift $c.gain Using options # Save results as an object spend.uplift.5 &lt;- reguplift(email.spend, &quot;promotion&quot;, ng=5, int=&quot;Y&quot;) # Examine results spend.uplift.5$plots $qini $uplift $c.gain spend.uplift.5$int .cl-1076a002{}.cl-106f4ece{font-family:'Arial';font-size:14pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-106f4ed8{font-family:'Arial';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-106f4ee2{font-family:'Arial';font-size:6.6pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;position: relative;bottom:3.3pt;}.cl-106f4ee3{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-1072494e{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-10724958{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-10724959{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:1pt;padding-top:1pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-10724962{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:1pt;padding-top:1pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-10725f4c{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-10725f56{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-10725f60{width:0.75in;height:0.157in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-10725f61{width:0.75in;height:0.157in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-10725f6a{width:0.75in;height:0.157in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-10725f6b{width:0.75in;height:0.157in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-10725f74{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(255, 255, 255, 0.00);border-top: 0 solid rgba(255, 255, 255, 0.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}InteractionControlwomens:zipSurburban0.057womens:zipUrban0.0061 Values are p-values for interaction2 Outcome = visit3 Control: promotion = 04 Treat: promotion = 1 8.5 LIFT Plots To get LIFT plots based on an uplift modeling object, use the liftplot function. This function creates a lift plot following uplift modeling. It can create a histogram (if var is null) or an error-bar plot. For continuous variables, it will create an error-bar for the quintile values of the variable. For factor variables, it will create an error-bar for each level of the factor. It can also create side-by-side error-bar plots for two variables simultaneously by using the byvar option. 8.5.1 Using the liftplot function Requires the following packages: ggplot2 Usage: liftplot(data, var=NULL, byvar=NULL, ar=NULL, ci=c(0.90, 0.95, 0.975, 0.99, 0)) where: data is the name of the dataframe with the results of an uplift modeling analysis. var is the variable name for which the error-bars should be created. Must be in quotations. Default is NULL for a histogram. byvar is the variable that identifies second variable if side-by-side error-bar plots are desired. Must be in quotations. Default is NULL. ar is the aspect ratio for the plots. Default is NULL. ci is the type of error-var desired. Ignored if var is NULL. Must be one of the following if var is not NULL: 0 for error-bars to represent 1 standard deviation 0.90 or 0.95 or 0.975 or 0.99 for error-bars to represent the desired confidence level. Returns: A ggplot object 8.5.1.1 Examples Example 1: Histogram liftplot(visit.uplift$all) Example 2: Single variable lift plots # Standard deviation error bars liftplot(visit.uplift$all, var=&quot;recency&quot;, ci=0) # 99% CI error bars liftplot(visit.uplift$all, var=&quot;zip&quot;, ci=0.99) Example 3: Side-by-side, two variable lift plots # Standard deviation error bars liftplot(spend.uplift$all, var=&quot;recency&quot;, byvar=&quot;zip&quot;, ci=0) # 99% CI error bars liftplot(spend.uplift$all, var=&quot;zip&quot;, byvar=&quot;womens&quot;, ci=0.99) "],["standard-mnl.html", "Chapter 9 Standard MNL 9.1 Introduction 9.2 Data Preparation 9.3 Standard MNL using multinom()", " Chapter 9 Standard MNL Sources for this chapter: R for Marketing Research and Analytics, Second Edition (2019). Chris Chapman and Elea McDonnell Feit http://r-marketing.r-forge.r-project.org/index.html Data for this chapter: The bfast data is used from the MKT4320BGSU course package. Load the package and use the data() function to load the data. # Load the course package library(MKT4320BGSU) # Load the data data(bfast) 9.1 Introduction Base R is not good for standard multinomial logistic regression (MNL). The best package that I have found for standard MNL is nnet with its multinom function. Install that package install.packages(\"nnet\") and load it. library(nnet) In addition, I have created some user defined functions, which are all in the MKT4320BGSU package. stmnl produces Odds Ratio coefficients table, overall model significance, and McFadden’s Pseudo-\\(R^2\\) stmnl_cm1 produces a Classification Matrix stmnl_pp produces average predicted probability tables and plots 9.2 Data Preparation As with binary logistic regression, we often us a training and holdout sample when using MNL. For standard MNL, the process is the same. library(caret) set.seed(4320) inTrain &lt;- createDataPartition(y=bfast$bfast, p=.75, list=FALSE) train &lt;- bfast[inTrain,] test &lt;- bfast[-inTrain,] 9.3 Standard MNL using multinom() Standard MNL is performed using the multinom() function from the nnet package Usage: multinom(formula, data) formula is represented by dependent variables on the left side separated from the independent variables on the right side by a tilde(~), such as: dv ~ iv1 + iv2 data is the name of the (usually) training data As with other analyses, we save the result of the model to an object summary() provides standard coefficient estimates (i.e., not Odds Ratio estiamtes), but does not provide overall model fit values (i.e., overall model \\(p\\)-value or McFadden’s Psuedo \\(R^2\\)) or p-values for each independent variable library(nnet) model &lt;- multinom(bfast ~ gender + marital + lifestyle + age, data=train) # weights: 18 (10 variable) initial value 727.281335 iter 10 value 579.014122 final value 574.997631 converged summary(model) Call: multinom(formula = bfast ~ gender + marital + lifestyle + age, data = train) Coefficients: (Intercept) genderMale maritalUnmarried lifestyleInactive age Bar 0.8832457 -0.21298963 0.6126977 -0.7865772 -0.02532866 Oatmeal -4.4920408 -0.02262325 -0.3897362 0.3187473 0.07996475 Std. Errors: (Intercept) genderMale maritalUnmarried lifestyleInactive age Bar 0.3256994 0.2064320 0.2123832 0.2090460 0.006655803 Oatmeal 0.4596750 0.2094666 0.2366511 0.2156992 0.007755708 Residual Deviance: 1149.995 AIC: 1169.995 9.3.1 stmnl() User Defined Function To get overall model fit values, as well as an Odds Ratio estimate table with p-values, the stmnl() user defined function can be used Usage: stmnl(model) model is the name of the object with the saved model results NOTE: This function requires the broom package. If you do not have it installed on your machine, you will need to install it. stmnl(model) LR chi2 (8) = 288.1568; p &lt; 0.0001 McFadden&#39;s Pseudo R-square = 0.2004 y.level term estimate std.error statistic p.value Bar (Intercept) 2.4187 0.3257 2.7118 0.0067 Bar genderMale 0.8082 0.2064 -1.0318 0.3022 Bar maritalUnmarried 1.8454 0.2124 2.8849 0.0039 Bar lifestyleInactive 0.4554 0.2090 -3.7627 0.0002 Bar age 0.9750 0.0067 -3.8055 0.0001 Oatmeal (Intercept) 0.0112 0.4597 -9.7722 0.0000 Oatmeal genderMale 0.9776 0.2095 -0.1080 0.9140 Oatmeal maritalUnmarried 0.6772 0.2367 -1.6469 0.0996 Oatmeal lifestyleInactive 1.3754 0.2157 1.4777 0.1395 Oatmeal age 1.0832 0.0078 10.3104 0.0000 9.3.2 Classification Matrix To get a classification matrix, the stmnl_cm user-defined function should be used Usage: stmnl_cm(model, data) model is the name of the object with the saved model results data is name of the data to create the classification model for (i.e., training or holdout data) stmnl_cm(model, train) 0.5619 = Hit Ratio 0.3413 = PCC Level T.Cereal T.Bar T.Oatmeal Total 1 P.Cereal 124 85 46 255 2 P.Bar 52 68 7 127 3 P.Oatmeal 79 21 180 280 4 Total 255 174 233 662 stmnl_cm(model, test) 0.5826 = Hit Ratio 0.3416 = PCC Level T.Cereal T.Bar T.Oatmeal Total 1 P.Cereal 45 24 20 89 2 P.Bar 18 25 0 43 3 P.Oatmeal 21 8 57 86 4 Total 84 57 77 218 9.3.3 Average Predicted Probabilities Predicted probabilities can help interpret the effects of the independent variables on the choice dependent variable Use the stmnl_pp user-defined function for each IV to obtain these. Usage: stmnl_pp(model, focal, xlab) model is the name of the object with the saved model results focal is the name of the variable (in quotes) for which predicted probabilities are wanted xlab is optional, but can be provided for a better x-axis label for the plot (e.g., “Income Category”) NOTE 1: For continuous focal variables, the table produced uses three levels to calculate predicted probabilities: \\(-1 SD\\), \\(MEAN\\), \\(+1 SD\\) NOTE 2: This function requires the following packages: tidyr effects dplyr ggplot2 stmnl_pp(model, &quot;age&quot;, &quot;Age in Years&quot;) $table age bfast p.prob lower.CI upper.CI 1 31 Cereal 0.5158 0.5727 0.4586 2 31 Bar 0.4134 0.4718 0.3573 3 31 Oatmeal 0.0708 0.1047 0.0473 4 49 Cereal 0.4792 0.5274 0.4314 5 49 Bar 0.2434 0.2874 0.2043 6 49 Oatmeal 0.2773 0.3255 0.2338 7 67 Cereal 0.2657 0.3196 0.2180 8 67 Bar 0.0856 0.1199 0.0604 9 67 Oatmeal 0.6487 0.7035 0.5897 $plot stmnl_pp(model, &quot;gender&quot;, &quot;Gender&quot;) $table gender bfast p.prob lower.CI upper.CI 1 Female Cereal 0.4660 0.5276 0.4053 2 Female Bar 0.2634 0.3219 0.2122 3 Female Oatmeal 0.2706 0.3324 0.2166 4 Male Cereal 0.4939 0.5584 0.4296 5 Male Bar 0.2257 0.2848 0.1758 6 Male Oatmeal 0.2804 0.3473 0.2221 $plot "],["alt-specific-mnl.html", "Chapter 10 Alt-Specific MNL 10.1 Introduction 10.2 Alt-Spec MNL using User Defined Function", " Chapter 10 Alt-Specific MNL Data for this chapter: The train.yog and test.yog data are used from the MKT4320BGSU course package. Load the package and use the data() function to load the data. # Load the course package library(MKT4320BGSU) # Load the data data(train.yog) data(test.yog) 10.1 Introduction Base R is not good for alternative specific multinomial logistic regression (MNL). The best package that I have found for alternative specific MNL is mlogit with its mlogit function. Use install.packages(\"mlogit\") to install the package on your machine, then load it using the library function when needed. library(mlogit) However, even that is not very user friendly (in my opinion). Therefore, I have written a few user defined functions to help with getting the necessary results from an alternative specific MNL. * asmnl_est produces Odds Ratio coefficients table, overall model significance, McFadden’s Pseudo-\\(R^2\\), and classification matrices for both the training data and the test/holdout data * asmnl_me produces marginal effects tables for all IVs * asmnl_mp produces margin plots for case-specific IVs 10.2 Alt-Spec MNL using User Defined Function Alternative Specific MNL is performed using the asmnl_est user defined function Usage: asmnl_est(formula, data, id=\"\", alt=\"\", choice=\"\", testdata) formula is an object with a saved formula. The formula is represented by a DV on the left side separated from the IVs on the right side by a tilde(~). The IVs are further separated by having choice-specific variables on the left and the case-specific variables on the right, separated by a vertical line, |. For example: myform = choice ~ chvar1 + chvar2 | casvar1 + casvar2 data is the name of the training data id is the variable that identifies the case (in quotes) alt is the variable that identifies the choice (in quotes) choice is the variable that identifies if alt was selected or not testdata is the name of the test data The function will display the coefficients table, overall model significance, McFadden’s Pseudo-\\(R^2\\), and classification matrices for both the training data and the test/holdout data In addition, the results should be saved to an object to be used in other user defined functions NOTE 1: To work properly, all factor IVs should already be in dummy variable coding NOTE 2: This function also requires the broom package library(mlogit) # Saving formula to object myform &lt;- choice ~ feat + price | income asmod &lt;- asmnl_est(formula=myform, data=train.yog, id=&quot;id&quot;, alt=&quot;brand&quot;, choice=&quot;choice&quot;, testdata=test.yog) --------- Model Fit --------- Log-Likelihood: -1618.4208 McFadden R^2: 0.2397 Likelihood ratio test: chisq = 1020.5649 (p.value &lt; .0001) --------------------- OR Estimation Results --------------------- term estimate std.error statistic p.value (Intercept):Hiland 2.1355 0.5677 1.3365 0.1814 (Intercept):Weight 0.9740 0.2079 -0.1269 0.8990 (Intercept):Yoplait 0.0185 0.2680 -14.8845 0.0000 feat 1.5267 0.1491 2.8371 0.0046 price 0.6425 0.0296 -14.9691 0.0000 income:Hiland 0.8975 0.0149 -7.2464 0.0000 income:Weight 0.9886 0.0038 -3.0436 0.0023 income:Yoplait 1.0756 0.0040 18.1030 0.0000 --------------------------------------- Classification Matrix for Training Data --------------------------------------- 0.6207 = Hit Ratio 0.3299 = PCC T.Dannon T.Hiland T.Weight T.Yoplait Total P.Dannon 577 39 324 97 1037 P.Hiland 1 12 0 2 15 P.Weight 18 2 38 18 76 P.Yoplait 132 1 53 497 683 Total 728 54 415 614 1811 -------------------------------------- Classification Matrix for Holdout Data -------------------------------------- 0.6073 = Hit Ratio 0.3309 = PCC T.Dannon T.Hiland T.Weight T.Yoplait Total P.Dannon 199 14 104 38 355 P.Hiland 2 2 1 1 6 P.Weight 8 1 12 13 34 P.Yoplait 33 0 21 152 206 Total 242 17 138 204 601 10.2.1 Marginal Effects The asmnl_me user defined function will be used to get the marginal effects of the IVs Usage: asmnl_me(mod) mod is the object containing the result of the mlogit call using the asmnl_est user defined function asmnl_me(asmod) -------------------------------- Predicted Probabilities at Means -------------------------------- Dannon Hiland Weight Yoplait 0.4832 0.0048 0.2571 0.2549 ------------------------- Marginal effects for feat ------------------------- Dannon Hiland Weight Yoplait Dannon 0.10565 -0.00098 -0.05256 -0.05212 Hiland -0.00098 0.00201 -0.00052 -0.00052 Weight -0.05256 -0.00052 0.08080 -0.02773 Yoplait -0.05212 -0.00052 -0.02773 0.08036 -------------------------- Marginal effects for price -------------------------- Dannon Hiland Weight Yoplait Dannon -0.11049 0.00102 0.05496 0.05450 Hiland 0.00102 -0.00211 0.00054 0.00054 Weight 0.05496 0.00054 -0.08450 0.02899 Yoplait 0.05450 0.00054 0.02899 -0.08404 --------------------------- Marginal effects for income --------------------------- Dannon Hiland Weight Yoplait -0.00731 -0.00059 -0.00684 0.01473 10.2.2 Margin Plots The asmnl_mp user defined function will create margin plots for a case-specific IV Usage: almnl_mp(mod, focal=\"\", type=\"\") *modis the object containing the result of themlogitcall using theasmnl_estuser defined function *focalis the case-specific IV for which a margin plot is wanted (in quotes) *typeis the type of IV; must be either“C”for continuous or“D”` for dummy NOTE: This function requires the ggplot2 package asmnl_mp(asmod,&quot;income&quot;, &quot;C&quot;) "],["forecasting-i.html", "Chapter 11 Forecasting I 11.1 Introduction 11.2 tsplot User Defined Function 11.3 naivefc User Defined Function 11.4 smoothfc User Defined Function 11.5 linregfc User Defined Function 11.6 fccompare User Defined Function", " Chapter 11 Forecasting I Data for this chapter: The msales and qales data are used from the MKT4320BGSU course package. Load the package and use the data() function to load the data. # Load the course package library(MKT4320BGSU) # Load the data data(msales) data(qsales) 11.1 Introduction While Base R does have some time-series forecasting capabilities, there are several packages that make working with the data and running the analysis easier. For our class, we will be mainly using the fpp3 package inside of some user-defined functions. The user-defined functions are described briefly below, and then in detail in their own sections. 11.1.1 User-Defined Functions for Forecasting I naivefc analyzes the data using naive forecasting methods smoothfc analyzes the data using smoothing forecasting methods linregfc analyzes the data using regression-based forecasting methods tsplot produces a time series plot of the data fccompare compares models from saved results after running the methods functions 11.1.2 Packages You must have the following packages installed to use all of the user-defined functions. If you do not have them installed, you should do so now. fpp3 slider purrr dplyr ggplot2 ggfortify stringr cowplot # Load necessary packages library(fpp3) library(slider) library(purrr) library(ggplot2) library(dplyr) library(ggfortify) library(stringr) library(cowplot) 11.2 tsplot User Defined Function Usage: tsplot(data, tvar=\"\", obs=\"\", datetype=c(\"ym\", \"yq\", \"yw\"), h= ) data is the name of the dataframe with the time variable and measure variable tvar is the variable that identifies the time period (in quotes) obs is the variable that identifies the measure (in quotes) datetype can be one of three options: \"ym\" if the time period is year-month \"yq\" if the time period is year-quarter \"yw\" if the time period is year-week h is an integer indicating the number of holdout/forecast periods Output: A time series plot tsplot(msales, # Dataframe &quot;t&quot;, # Date variable &quot;sales&quot;, # Measure variable &quot;ym&quot;, # Date type 12) # Holdout periods tsplot(qsales, &quot;t&quot;, &quot;sales&quot;, &quot;yq&quot;, 8) 11.3 naivefc User Defined Function Usage: naivefc(data, tvar=\"\", obs=\"\", datetype=c(\"ym\", \"yq\", \"yw\"), h= ) data is the name of the dataframe with the time variable and measure variable tvar is the variable that identifies the time period (in quotes) obs is the variable that identifies the measure (in quotes) datetype can be one of three options: \"ym\" if the time period is year-month \"yq\" if the time period is year-quarter \"yw\" if the time period is year-week h is an integer indicating the number of holdout/forecast periods NOTE 1: The results of this function should be saved to an object. When doing so, the following objects are returned: $plot contains the naive methods plot $acc contains the accuracy measures $fcresplot contains a plot of the holdout period residuals $fcresid is a dataframe of the holdout period residuals (seldom used separately) Note 2: The model names are: Naive for the naive model Naive.Drift for the naive model with drift Seas.Naive for the seasonal naive model Seas.Naive.Drift for the seasonal naive model with drift naive &lt;- naivefc(msales, &quot;t&quot;, &quot;sales&quot;, &quot;ym&quot;, 12) naive$plot naive$acc Model RMSE MAE MAPE 1 Naive 323.496 263.917 0.945 2 Naive.Drift 253.103 185.868 0.665 3 Seas.Naive 133.710 127.417 0.459 4 Seas.Naive.Drift 45.769 41.417 0.149 naive$fcresplot 11.4 smoothfc User Defined Function Usage: smoothfc(data, tvar=\"\", obs=\"\", datetype=c(\"ym\", \"yq\", \"yw\"), h= ) data is the name of the dataframe with the time variable and measure variable tvar is the variable that identifies the time period (in quotes) obs is the variable that identifies the measure (in quotes) datetype can be one of three options: \"ym\" if the time period is year-month \"yq\" if the time period is year-quarter \"yw\" if the time period is year-week h is an integer indicating the number of holdout/forecast periods NOTE 1: The results of this function should be saved to an object. When doing so, the following objects are returned: $plot contains the smoothing methods plot $acc contains the accuracy measures $fcresplot contains a plot of the holdout period residuals $fcresid is a dataframe of the holdout period residuals (seldom used separately) Note 2: The model names are: Mov.Ave for the moving average model Exp.Smooth for the exponential smoothing model H-W.Add for the Holt-Winters Additive model H-W.Mult for Hold-Winters Multiplicative model smooth &lt;- smoothfc(msales, &quot;t&quot;, &quot;sales&quot;, &quot;ym&quot;, 12) smooth$plot smooth$acc Model RMSE MAE MAPE 1 Exp.Smooth 323.495 263.915 0.945 2 H-W.Add 54.469 46.754 0.168 3 H-W.Mult 43.857 40.626 0.146 4 Mov.Ave 225.685 191.245 0.686 smooth$fcresplot 11.5 linregfc User Defined Function Usage: linregfc(data, tvar=\"\", obs=\"\", datetype=c(\"ym\", \"yq\", \"yw\"), h= ) data is the name of the dataframe with the time variable and measure variable tvar is the variable that identifies the time period (in quotes) obs is the variable that identifies the measure (in quotes) datetype can be one of three options: \"ym\" if the time period is year-month \"yq\" if the time period is year-quarter \"yw\" if the time period is year-week h is an integer indicating the number of holdout/forecast periods NOTE 1: The results of this function should be saved to an object. When doing so, the following objects are returned: $plot contains the regression methods plot $acc contains the accuracy measures $fcresplot contains a plot of the holdout period residuals $fcresid is a dataframe of the holdout period residuals (seldom used separately) Note 2: The model names are: Lin.Reg.Trend for the linear regression with trend model Line.Reg.Seas.Trend for linear regression with trend and seasonality model linreg &lt;- linregfc(msales, &quot;t&quot;, &quot;sales&quot;, &quot;ym&quot;, 12) linreg$plot linreg$acc Model RMSE MAE MAPE 1 Lin.Reg.Seas.Trend 55.212 47.898 0.172 2 Lin.Reg.Trend 199.198 168.985 0.607 linreg$fcresplot 11.6 fccompare User Defined Function Usage: fccompare(results, models) results is a list of the stored methods results; create the list with the list function, such as:results &lt;- list(naive, smooth, linreg) models is a vector of the models you want to compare; create the vector with the c() function, such as:models &lt;- c(\"Naive\", \"Mov.Ave\", \"Lin.Reg.Trend\") NOTE 1: The function returns two items that will be directly displayed or can be saved to an object: $acc contains the accuracy measures $fcresplot contains a plot of the holdout period residuals results &lt;- list(naive, smooth, linreg) models &lt;- c(&quot;Naive&quot;, &quot;Mov.Ave&quot;, &quot;Lin.Reg.Trend&quot;) fccompare(results, models) $acc Model RMSE MAE MAPE 1 Naive 323.496 263.917 0.945 8 Mov.Ave 225.685 191.245 0.686 10 Lin.Reg.Trend 199.198 168.985 0.607 $fcresplot "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
