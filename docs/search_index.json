[["index.html", "R Tutorial for MKT 4320 About this tutorial", " R Tutorial for MKT 4320 Jeffrey Meyer 2022-01-19 About this tutorial This tutorial is a quick and basic R tutorial for MKT 4320. It is not designed to be comprehensive, but will provide you with the basics of R, RStudio, and how to complete the types of analyses covered in the course. At this time, the tutorial is not complete, but will be updated as we move through the topics in the course. Much of the content in this tutorial is adapted from a variety of sources. Where applicable, the source will be noted. "],["r-basics.html", "Chapter 1 R Basics 1.1 Introduction 1.2 R Language 1.3 Packages 1.4 Getting Help 1.5 Basic Object Types (and Other Important Stuff) 1.6 Data Frames 1.7 Data Transformations 1.8 Loading and Saving Data 1.9 User Defined Functions 1.10 Package dplyr 1.11 Package lubridate 1.12 RMarkdown", " Chapter 1 R Basics Sources for this chapter: R for Marketing Research ad Analytics, Second Edition (2019). Chris Chapman and Elea McDonnell Feit http://r-marketing.r-forge.r-project.org/index.html 1.1 Introduction 1.1.1 What is R? R is a programming language R is not a statistics program Much different than SPSS, MiniTab, Stata, etc. Does not use a point-and-click interface 1.1.2 Why R? Emerging techniques usually available in R quickly Default educational platform for statistics programs (and spreading to other disciplines) Large and diverse set of analytic tools Powerful plotting options Large community of helpful users R skills are in high demand And R is free 1.1.3 Why NOT R? Steep learning curve Requires programming 1.1.4 What is RStudio? RStudio IDE is an integrated development environment that makes working with R more user friendly Not required to use R, but provides a better interface and environment of writing code, editing code, and creating documents. Complete separate software And RStudio is free 1.1.5 Getting Started 1.1.5.1 Option 1: Install on your Machine Install R base from the Comprehensive R Archive Network (CRAN) https://cran.r-project.org/ Install RStudio https://www.rstudio.com/products/rstudio/download/#download 1.1.5.2 Option 2: Use BGSUs Virtual Computing Lab pilot See course website for link 1.1.5.3 Option 3: Use a computer in an on-campus computer lab All computer in on-campus computer labs should have R and RStudio installed 1.1.6 Navigating RStudio As you can see in Figure 1.1, RStudio is typically divided in 4 quadrants. Figure 1.1: RStudio Layout 1.1.6.1 Quadrant 1 The upper-left corner is the source pane. This pane is where the majority of your programming or coding will take place. When working in this pane, the code does not run unless you tell it to run. In addition, the code can be saved to prevent work from being lost. 1.1.6.2 Quadrant 2 The lower-left corner is the console pane. While it contains several tabs, generally the Console tab is the only one used. The console is where R actually evaluates the code. If you run code from the a source pane window, the code will automatically be put into the console pane and evaluated. You can also type code directly into the console pane and receive immediate results. Depending on the code, the results will appear directly in the console or in a tab Quadrant 4. The &gt; symbol shows that the console is ready for input. 1.1.6.3 Quadrant 3 The upper-right corner also contains several tabs, but the Environment and History tabs are the ones used most often. The Environment tab lists all data objects that have been defined in the current session. The History tab is an archive of all commands run in the current session. 1.1.6.4 Quadrant 4 The bottom-right corner also contains several tabs, all of which are used at different times. The Files tab lists all files in the current directory. The Plots tab shows visualizations created during the current session. The Packages tab shows all packages installed as well as which packages are currently loaded. The Help tab contains the help menu. The Viewer tab contains output from code if the code directs it to be displayed there. 1.2 R Language 1.2.1 Basics of R Commands R is case sensitive When using the console, use the keyboard  and  arrow keys to easily cycle through previous commands typed. When using the text editor (i.e., a script file) in the source pane, use the Ctrl+Enter keyboard shortcut to submit a line of code directly to the console. The entire line does not need to be highlighted; the cursor needs to be anywhere on the line to be submitted. When using the text editor/script file, the # symbol signifies a comment Everything after is ignored It can be on the same line: x &lt;- 100 # Assign 100 to x It can be on separate lines: # Assign 100 to x x &lt;- 100 1.2.2 Operators Mathematical and logical operators are used frequently. Table 1.1: R Operators Description Operator Mathematical addition \\(+\\) subtraction \\(-\\) multiplication \\(*\\) division \\(/\\) exponentiation ^ or \\(**\\) Logical less than &lt; less than or equal to &lt;= greater than &gt; greater than or equal to &gt;= exactly equal to == not equal to != Not x !x x OR y x|y x AND y x&amp;y test if X is TRUE isTRUE(x) 1.3 Packages Packages are collections of functions that have been written to expand the functionality of R. Packages are not automatically included, and if a command is given that is not part of a package installed and loaded, R will give an error message. Therefore, the package must first be installed, and then loaded. 1.3.1 Installing Packages Installing packages is performed with the install.packages(\"\")function, where the name of the package is inside the quotation marks Two packages that used quite often in this course are ggplot2 and dplyr install.packages(&quot;ggplot2&quot;) install.packages(&quot;dplyr&quot;) NOTE 1: Packages only need to be installed on your machine once NOTE 2: If using BGSUs Virtual Computing Lab, new packages cannot be installed, but the version in the virtual environment has most of the most common packages pre-installed 1.3.2 Loading Packages Once a package is installed, it has to be loaded with the library() function, where the name of the package is in the parentheses, in order to be used library(ggplot2) library(dplyr) NOTE 1: It is not uncommon to see a variety of messages when loading a package NOTE 2: Packages need to be loaded every time you start a new R session 1.4 Getting Help R has built in help to assist with understanding different functions To access the help, type ? FUNCTION in the console, and the help page for that function will show up in the lower-right pane under the help tab ? mean 1.5 Basic Object Types (and Other Important Stuff) Objects in R include variables, data sets, and functions The assignment operator &lt;- assigns a value to a named object x &lt;- 100 # Assign value 100 to object &#39;x&#39; x # Display object &#39;x&#39; [1] 100 NOTE: In RStudio console or script file, Alt+- will automatically paste the assignment operator As stated before, object names are case sensitive x &lt;- 100 # Assign value 100 to object &#39;x&#39; X # Display object &#39;X&#39; Error in eval(expr, envir, enclos): object &#39;X&#39; not found The print command can also be used to print objects print(x) [1] 100 1.5.1 Vectors Vectors can be created many ways and take many data types One method is to using the c() function, which concatenates individual items x.Num &lt;- c(1, 3.14, 5.49, 10, 20) x.Num [1] 1.00 3.14 5.49 10.00 20.00 x.Log &lt;- c(TRUE, FALSE, TRUE, TRUE, FALSE) x.Log [1] TRUE FALSE TRUE TRUE FALSE x.Char &lt;- c(&quot;fr&quot;, &quot;fr&quot;, &quot;jr&quot;, &quot;so&quot;, &quot;sr&quot;) x.Char [1] &quot;fr&quot; &quot;fr&quot; &quot;jr&quot; &quot;so&quot; &quot;sr&quot; The class of the vector can be checked with the class() function # Concatenate class functions and print together print(c(class(x.Num), class(x.Log), class(x.Char))) [1] &quot;numeric&quot; &quot;logical&quot; &quot;character&quot; Vectors can only hold a single class/type of value When multiple classes are included, the values are coerced to the most general type x.Mix &lt;- c(1, FALSE, 3.5, &quot;Hello!&quot;) x.Mix [1] &quot;1&quot; &quot;FALSE&quot; &quot;3.5&quot; &quot;Hello!&quot; class(x.Mix) [1] &quot;character&quot; The c() function can be used to add to existing vectors, or combine vectors Type coercion will be applied as needed x2 &lt;- c(x.Num, 25, 50) x.Num [1] 1.00 3.14 5.49 10.00 20.00 x2 [1] 1.00 3.14 5.49 10.00 20.00 25.00 50.00 x3 &lt;- c(x2, &quot;Hello&quot;) x3 [1] &quot;1&quot; &quot;3.14&quot; &quot;5.49&quot; &quot;10&quot; &quot;20&quot; &quot;25&quot; &quot;50&quot; &quot;Hello&quot; Math can be applied directly to vectors x.Num [1] 1.00 3.14 5.49 10.00 20.00 x.Num + 100 [1] 101.00 103.14 105.49 110.00 120.00 x.Num * pi [1] 3.141593 9.864601 17.247344 31.415927 62.831853 The length() function provides the length of a vector length(x.Num) [1] 5 length(x.Char) [1] 5 The str() function provide the structure of an object Class, Length, and Value str(x.Num) num [1:5] 1 3.14 5.49 10 20 str(x.Char) chr [1:5] &quot;fr&quot; &quot;fr&quot; &quot;jr&quot; &quot;so&quot; &quot;sr&quot; 1.5.2 Indexing Indexing is used to obtain particular elements of a data structure Vectors are indexed with square brackets, [] # Obtain the third element of the &#39;x.Num&#39; vector x.Num[3] [1] 5.49 Items can be excluded with negative indexing # Obtain all elements except the third element of the &#39;x.Num&#39; vector x.Num[-3] [1] 1.00 3.14 10.00 20.00 Indexing also works with logical operators # Obtain all elements in &#39;x.Num&#39; greater than 5 x.Num[x.Num &gt; 5] [1] 5.49 10.00 20.00 1.5.3 Sequencing Vectors can also be created using sequencing Integer sequencing is done with #:# coding x.Seq &lt;- 1:10 x.Seq [1] 1 2 3 4 5 6 7 8 9 10 Sequences can also be used in indexing # Obtain the second through fourth element of the &#39;x.Num&#39; vector x.Num[2:4] [1] 3.14 5.49 10.00 Complex sequencing can be done using the seq() function x.Seq2 &lt;- seq(from=0, to=100, by=20) x.Seq2 [1] 0 20 40 60 80 100 Note: the from=, to= and by= can be excluded x.Seq3 &lt;- seq(0,100,20) x.Seq3 [1] 0 20 40 60 80 100 1.5.4 Missing (and Other Interesting) Values In R, missing values are assigned a special constant, NA NA is not a character value, but a type of its own Any math performed on a value of NA becomes NA x.Scores &lt;- c(85, 93, NA, NA) mean(x.Scores) [1] NA Many commands contain a option, na.rm=TRUE, to ignore NA data when performing the function mean(x.Scores, na.rm=TRUE) [1] 89 NA values can also be removed before performing the function using the na.omit() function mean(na.omit(x.Scores)) [1] 89 R also has special types for infinity, Inf, and undefined numbers (i.e., not a number), NaN To see this in action, take the natural log, log(), of certain numbers log(-1) Warning in log(-1): NaNs produced [1] NaN log(0) [1] -Inf Notice that R provides a warning when the NaN is found 1.5.5 Factors Character data can be converted into nominal factors using the as.factors() function Each unique character value will be a level of the factor Behind the scenes, R stores the values as integers, with a separate list of labels When the data type is set as a factor, R knows how to handle it appropriately in the model The levels can be accessed with the levels() function x.Class &lt;- as.factor(x.Char) str(x.Class) Factor w/ 4 levels &quot;fr&quot;,&quot;jr&quot;,&quot;so&quot;,..: 1 1 2 3 4 levels(x.Class) [1] &quot;fr&quot; &quot;jr&quot; &quot;so&quot; &quot;sr&quot; 1.6 Data Frames Data frames are an object type that deserve special attention 1.6.1 Overview Most common way to handle data sets in R Provide data to statistical functions Think of it like a spreadsheet, or a rectangular object where: Columns are varying data types (i.e., variables) Rows are values in each column (i.e, observations) 1.6.2 Creating a data frame Can construct a data frame with the data.frame() function Takes as input a set of vectors of the same length x.df &lt;- data.frame(x.Num, x.Log, x.Char) x.df x.Num x.Log x.Char 1 1.00 TRUE fr 2 3.14 FALSE fr 3 5.49 TRUE jr 4 10.00 TRUE so 5 20.00 FALSE sr Note that the column names are inherited from the contributing vector Elements can be indexed using [ROW, COLUMN] notation # Obtain the first element of the third row of data frame &#39;x.df&#39; x.df[3,1] [1] 5.49 # Obtain the third element of the second row of data frame &#39;x.df&#39; x.df[2,3] [1] &quot;fr&quot; 1.6.2.1 Using vectors in-line The vectors can be created in line (i.e., not already created) If the vectors are of different length, the shorter vector will be repeated IF the longest vector is divisible by the vector If a single value is provided instead of a vector, it is repeated for all rows x2.df &lt;- data.frame(var1=seq(10,100,10), var2=c(&quot;Yes&quot;,&quot;No&quot;), var3=1:5, var4=100) x2.df var1 var2 var3 var4 1 10 Yes 1 100 2 20 No 2 100 3 30 Yes 3 100 4 40 No 4 100 5 50 Yes 5 100 6 60 No 1 100 7 70 Yes 2 100 8 80 No 3 100 9 90 Yes 4 100 10 100 No 5 100 1.6.3 Viewing a Data Frame There are a few ways to view a data frame Type the data frame name in the console x.df x.Num x.Log x.Char 1 1.00 TRUE fr 2 3.14 FALSE fr 3 5.49 TRUE jr 4 10.00 TRUE so 5 20.00 FALSE sr With data frames that have many variables, this is cumbersome With data frames with many rows, a max.print setting will kick in and not all rows will be shown To view only a few rows of data, the head(DF, n) function can be used, where DF is the name of the data frame, and n (optional) is the number of rows to view, with 10 as the default NOTE: The Salaries data frame from the car package is being used as an example head(Salaries,5) rank discipline yrs.since.phd yrs.service sex salary 1 Prof B 19 18 Male 139750 2 Prof B 20 16 Male 173200 3 AsstProf B 4 3 Male 79750 4 Prof B 45 39 Male 115000 5 Prof B 40 41 Male 141500 Use the function View() or click on the data frame name in the environment tab to see the data farme in the Source pane See Figure 1.2 Figure 1.2: Viewing a Data Frame in the Source Window Indexing and Sequencing Indices can be left blank, which selects all of that dimension x.df[2, ] # Obtain all of row 2 x.Num x.Log x.Char 2 3.14 FALSE fr x.df[ ,3] # Obtain all of column 3 [1] &quot;fr&quot; &quot;fr&quot; &quot;jr&quot; &quot;so&quot; &quot;sr&quot; As with vectors, indexing can be done with sequencing and negative indices to omit rows x.df[2:3, ] # Obtain rows 2 and 3 x.Num x.Log x.Char 2 3.14 FALSE fr 3 5.49 TRUE jr x.df[ ,-2] # Exclude column 2 x.Num x.Char 1 1.00 fr 2 3.14 fr 3 5.49 jr 4 10.00 so 5 20.00 sr Indexing a data frame returns an object, but the object type depends on the indexing Choosing \\(n\\) rows and and a single column yields a vector of length \\(n\\) Choosing multiple columns returns a new data frame Use the str() function to verify the new objects structure str(x.df[1, 1]) # 1 row and 1 column = vector of length 1 num 1 str(x.df[1:3, 2]) # 3 rows and 1 column = vector of length 3 logi [1:3] TRUE FALSE TRUE str(x.df[1, 1:2]) # 1 row and 2 columns = 1 x 2 data frame &#39;data.frame&#39;: 1 obs. of 2 variables: $ x.Num: num 1 $ x.Log: logi TRUE str(x.df[1:4, c(1, 3)]) #4 rows and 2 columns = 4 x 2 data frame &#39;data.frame&#39;: 4 obs. of 2 variables: $ x.Num : num 1 3.14 5.49 10 $ x.Char: chr &quot;fr&quot; &quot;fr&quot; &quot;jr&quot; &quot;so&quot; Data frames can also be indexed using column names after the $ character x.df$x.Char [1] &quot;fr&quot; &quot;fr&quot; &quot;jr&quot; &quot;so&quot; &quot;sr&quot; 1.7 Data Transformations Analysts and researchers often need to create new variables from existing ones or transform existing variables Data transformations can usually be accomplished in more than one way Using base R will be shown first After the dplyr package is introduced, a second way will be shown For the transformations shown below, either a new variable will be added to the data frame, or an existing variable will be changed However, it is not always required that the data frame be changed Sometimes, a transformation will be done on the fly and used only in an analysis, but the data frame remains the same 1.7.1 Creating New Variables Adding a new variable is done using code such as df$new &lt;- SOME FUNCTION, where: df is the name of the data frame new is the name for the new variable SOME FUNCTION is the data transformation to take place # Create new variable &#39;NumSq&#39; that is the square of current variable x.Num x.df$NumSq &lt;- x.df$x.Num^2 x.df x.Num x.Log x.Char NumSq 1 1.00 TRUE fr 1.0000 2 3.14 FALSE fr 9.8596 3 5.49 TRUE jr 30.1401 4 10.00 TRUE so 100.0000 5 20.00 FALSE sr 400.0000 1.7.2 Recoding (Create New) In base R, recoding is usually a multi-step process using indexing # Recode &#39;x.Num&#39; into three factors x.df$Grp &lt;- &quot;low&quot; # Create new variable and set all rows to one level x.df$Grp[x.df$x.Num&gt;=3 &amp; x.df$x.Num&lt;10] &lt;- &quot;med&quot; # Create medium level x.df$Grp[x.df$x.Num&gt;10] &lt;- &quot;high&quot; # Create high level x.df$Grp &lt;- as.factor(x.df$Grp) # Set new variable as factor str(x.df) # See structure of data frame with new variable &#39;data.frame&#39;: 5 obs. of 5 variables: $ x.Num : num 1 3.14 5.49 10 20 $ x.Log : logi TRUE FALSE TRUE TRUE FALSE $ x.Char: chr &quot;fr&quot; &quot;fr&quot; &quot;jr&quot; &quot;so&quot; ... $ NumSq : num 1 9.86 30.14 100 400 $ Grp : Factor w/ 3 levels &quot;high&quot;,&quot;low&quot;,&quot;med&quot;: 2 3 3 2 1 Notice the &amp; in the code above. It stands for and, which tells R that both conditions must be true 1.7.3 Recoding (Change Existing) Recoding to change an existing variable is done in a similar manner NOTE: Sometimes we have to first change the variable type, such as when the existing variable is a factor # Recode &#39;Grp&#39; into only two factors # Change type to &#39;character&#39; x.df$Grp &lt;- as.character(x.df$Grp) # Recode &#39;low&#39; and &#39;med&#39; to &#39;very low&#39; x.df$Grp[x.df$Grp==&quot;low&quot; | x.df$Grp==&quot;med&quot;] &lt;- &quot;very low&quot; # Change back to factor x.df$Grp &lt;- as.factor(x.df$Grp) str(x.df) &#39;data.frame&#39;: 5 obs. of 5 variables: $ x.Num : num 1 3.14 5.49 10 20 $ x.Log : logi TRUE FALSE TRUE TRUE FALSE $ x.Char: chr &quot;fr&quot; &quot;fr&quot; &quot;jr&quot; &quot;so&quot; ... $ NumSq : num 1 9.86 30.14 100 400 $ Grp : Factor w/ 2 levels &quot;high&quot;,&quot;very low&quot;: 2 2 2 2 1 Notice the | in the code above. It stands for or, which tells R that either condition can be true. 1.8 Loading and Saving Data In this class, the data will be provided to you as an .Rdata file, which are specific to R and the best way to store (and load) objects. If desired, .Rdata files can contain multiple objects. For example, an .Rdata file could contain two different data frames. 1.8.1 Setting Working Directory To know where your files are saved to, and to make it easier to load files, it is probably best to have a working directory where existing files are located and where new files will be saved. Use the getwd() function to see your current working directory getwd() [1] &quot;C:/Users/jdmeyer/Docs/RFiles&quot; Set the working directory in one of three ways: Use the setwd() function: setwd(\"C:/Users/jdmeyer/Doc/RFiles/RTutorial\") NOTE: Forward slashes (as shown above) are used in place of backward slashes for directory paths Use the menus in RStudio SessionSet Working DirectoryChoose Directory See Figure 1.3 Figure 1.3: Set Working Direcory using Menus Use the Files tab in the lower-right corner in RStudio See Figure 1.4 Figure 1.4: Set Working Direcory using Files Tab 1.8.2 Loading .Rdata Use the load(\"FILE LOCATION/NAME\") function to load and .Rdata file Suppose the data set used in Topic 1 (airlinesat.rdata) is in a subdirectory of the working directory called Data load(&quot;Data/airlinesat.rdata&quot;) See 1.5 for a visual example Figure 1.5: Loading Data 1.8.3 Saving .Rdata Use the save(OBJECT, file=\"SAVENAME\") function, where: OBJECT is one or more objects in the current environment separated by commas SAVENAME is the name of the file the objects will be saved to. save(x.df, file=&quot;xdf.rdata&quot;) 1.9 User Defined Functions Often, a series of commands is repeated over and over, or there is not an easy, built-in function in R to provide a needed result. In these case, R makes it relatively easy to create your own functions 1.9.1 Structure A function is constructed in the in the following manner: function.name &lt;- function(arglist) {body} where function.name is the name of the user defined function (arglist) contains the names of any inputs to the function, separated by commas {body} contains the code that operates on the inputs The function must be executed prior to using it in the current session; alternatively, the function can be saved as a .R script file and sourced using the source() function in R 1.9.2 Example Suppose a function is need to take the square root of a natural log transformation The new function will be named sqlog and will have one argument # Define the new function sqlog &lt;- function(x) { # Function has one argument, &#39;x&#39; sqrt(log(x)) # What is done with the argument, &#39;x&#39; } Now that the function is created and ran, it can be used. In this case, the output will be printed to the console. The function could have been written in a way that the result is stored as an object. sqlog(100) # Using the function on a single number [1] 2.145966 myvals &lt;- c(5, 10, 20, 40, 80, 160) # Creating a vector of values sqlog(myvals) # Using the function on a vector [1] 1.268636 1.517427 1.730818 1.920646 2.093329 2.252815 1.10 Package dplyr The dplyr package (pronounced DEE ply er) is a package that makes data manipulation much easier and more intuitive (for most). dplyr is built around the five main verbs shown below that make up a majority of data manipulation. However, there are other functions that dplyr uses to also help with data manipulation. select is used to subset columns filter is used to subset rows arrange is used to sort rows mutate is used to add new columns based on calculations (usually with other columns) summarise is use to perform summary calculations (e.g., mean, max, etc.) on data set In addition, dplyr uses the pipe, %&gt;%, to string together a series of functions. Think of functions strung together as upstream and downstream functions. The function to the left of %&gt;% is the upstream function, while the function to the right is the downstream function. By default, the downstream function assumes the value coming from the upstream function is the first argument in its function Therefore, the first argument can be omitted If the downstream function needs to use the value from from the upstream function assigned to a different argument, a . is simply put in the position of that argument 1.10.1 dplyr Examples First, be sure the dplyr package is loaded: library(dplyr) Well be using the airlinesat dataset from the airlinesat.rdata file for these examples. 1.10.1.1 select() function Usage: select(.data, ...), where ... is one or more unquoted expressions separated by commas airlinesat has 70 variables, but 46 of them are a series of expectation (e1 to e23) and satisfaction (s1 to s23)scales. First, we want to create a new data frame with those variables excluded. For simplicity, the num_range(\"prefix\", start:finish) selection can be used, and the ! takes the complement (i.e., all but these) airlinesat.small &lt;- # Create new data frame airlinesat %&gt;% # Use airlinesat as the starting data frame select(!num_range(&quot;e&quot;, 1:23)) %&gt;% # Select all but e1 to e23 select(!num_range(&quot;s&quot;, 1:23)) # Select all but s1 to s23 # NOTE: the two selects could have been concantendated as: # select(!c(num_range(&quot;e&quot;, 1:23), num_range(&quot;s&quot;, 1:23))) str(airlinesat.small) &#39;data.frame&#39;: 1065 obs. of 24 variables: $ age : num 30 55 56 43 44 40 39 41 33 51 ... $ country : Factor w/ 5 levels &quot;at&quot;,&quot;ch&quot;,&quot;de&quot;,..: 2 2 2 4 2 2 2 2 2 3 ... $ flight_class : Factor w/ 3 levels &quot;Business&quot;,&quot;Economy&quot;,..: 2 1 2 2 1 3 2 1 2 1 ... $ flight_latest : Factor w/ 6 levels &quot;within the last 12 months&quot;,..: 4 3 5 3 6 5 6 3 3 4 ... $ flight_purpose: Factor w/ 2 levels &quot;Business&quot;,&quot;Leisure&quot;: 2 1 1 2 1 2 1 1 2 1 ... $ flight_type : Factor w/ 2 levels &quot;Domestic&quot;,&quot;International&quot;: 1 2 1 1 2 2 1 2 1 2 ... $ gender : Factor w/ 2 levels &quot;female&quot;,&quot;male&quot;: 2 2 1 1 1 2 2 2 2 2 ... $ language : Factor w/ 3 levels &quot;English&quot;,&quot;French&quot;,..: 2 1 1 2 1 3 2 2 2 3 ... $ nflights : num 2 6 8 7 25 16 35 9 3 4 ... $ status : Factor w/ 3 levels &quot;Blue&quot;,&quot;Gold&quot;,..: 1 2 1 1 2 2 1 2 1 2 ... $ nps : num 6 10 8 8 6 7 8 7 8 8 ... $ sat1 : num 5 6 4 6 4 7 6 5 4 4 ... $ sat2 : num 2 6 2 6 3 2 3 3 4 4 ... $ sat3 : num 4 6 2 4 2 7 5 4 4 3 ... $ loy1 : num 3 6 3 6 3 2 2 4 4 3 ... $ loy2 : num 3 6 4 4 3 3 7 4 4 4 ... $ loy3 : num 3 6 7 5 2 2 7 4 2 3 ... $ loy4 : num 7 5 2 4 2 3 7 5 1 3 ... $ loy5 : num 3 6 4 5 2 2 6 5 2 4 ... $ com1 : num 1 6 7 6 3 7 7 4 3 1 ... $ com2 : num 1 6 7 6 3 6 7 4 3 7 ... $ com3 : num 7 6 7 6 2 3 7 5 3 7 ... $ overall_sat : num 2 6 2 4 2 4 4 4 4 3 ... $ reputation : num 3 6 4 6 5 3 3 4 2 4 ... Second, we want to create a new data frame with only demographic variables airlinesat.d &lt;- # Create new data frame airlinesat %&gt;% # Use airlinesat as the starting data frame select(age, country, gender) # Select only demographic variables str(airlinesat.d) &#39;data.frame&#39;: 1065 obs. of 3 variables: $ age : num 30 55 56 43 44 40 39 41 33 51 ... $ country: Factor w/ 5 levels &quot;at&quot;,&quot;ch&quot;,&quot;de&quot;,..: 2 2 2 4 2 2 2 2 2 3 ... $ gender : Factor w/ 2 levels &quot;female&quot;,&quot;male&quot;: 2 2 1 1 1 2 2 2 2 2 ... 1.10.1.2 filter() function Usage: filter(.data, ...), where ... is an expression that returns a logical value First, we want to select only those rows where the person is from the United States (i.e., country == \"us\") using the newly created airlinesat.d data frame airlinesat.dus &lt;- airlinesat.d %&gt;% filter(country == &quot;us&quot;) head(airlinesat.dus) age country gender 1 52 us male 2 68 us male 3 64 us female 4 47 us male 5 57 us male 6 43 us male Second, we want to select only those rows where the person is older than the mean age using the newly created airlinesat.d data frame airlinesat.dold &lt;- airlinesat.d %&gt;% filter(age &gt; mean(age, na.rm=TRUE)) head(airlinesat.dold) age country gender 1 55 ch male 2 56 ch female 3 51 de male 4 58 de female 5 53 de male 6 53 de male 1.10.1.3 arrange() function Usage: arrange(.data, ..., .by_group = FALSE) where ... are variable(s) or functions of variables Use desc(...) to sort in a descending order .by_group = TRUE will sort first by a grouping variable, if one exists; default is FALSE First, we want to see the first 10 rows in ascending order of age using the airlinesat.d data frame # NOTE: A new data frame does not need to be created. # The result of the data manipulation can be sent directly # to another function, like &#39;head()&#39; airlinesat.d %&gt;% arrange(age) %&gt;% head(10) age country gender 1 19 de male 2 19 de male 3 21 de male 4 21 de male 5 22 de female 6 22 de male 7 22 de male 8 22 de female 9 22 de male 10 23 de male Second, we want to see the first 10 rows of three variables (age, country, nflights) from the original airlinesat data frame, sorted first ascending by age and second descending by nflights airlinesat %&gt;% select(age, country, nflights) %&gt;% arrange(age, desc(nflights)) %&gt;% head(10) age country nflights 1 19 de 15 2 19 de 3 3 21 de 11 4 21 de 2 5 22 de 20 6 22 de 8 7 22 de 3 8 22 de 3 9 22 de 2 10 23 de 15 1.10.1.4 mutate() function Usage: mutate(.data, ...) where ... are name-value pairs. The name gives the name of the new column/variable. The value is some function or formula. First, we want to create a standard normal variable for age using the airlinesat.d data frame airlinesat.d %&gt;% mutate(age_snrm=(age-mean(age, na.rm=TRUE))/sd(age,na.rm=TRUE)) %&gt;% head(10) age country gender age_snrm 1 30 ch male -1.66357002 2 55 ch male 0.37315007 3 56 ch female 0.45461887 4 43 fr female -0.60447557 5 44 ch female -0.52300677 6 40 ch male -0.84888198 7 39 ch male -0.93035079 8 41 ch male -0.76741318 9 33 ch male -1.41916361 10 51 de male 0.04727486 Second, we want to use mutate with recode to create a new variable, continent based on variable country recode(.x, ...) where .x is the variable to modify and ... are the things to recode in old = \"new\" format separated by commas Use recode_factor(.x, ...) to recode factor variables airlinesat.d %&gt;% mutate(continent=recode_factor(country, at=&quot;Europe&quot;, ch=&quot;Europe&quot;, de=&quot;Europe&quot;, fr=&quot;Europe&quot;, us=&quot;North America&quot;)) %&gt;% head(10) age country gender continent 1 30 ch male Europe 2 55 ch male Europe 3 56 ch female Europe 4 43 fr female Europe 5 44 ch female Europe 6 40 ch male Europe 7 39 ch male Europe 8 41 ch male Europe 9 33 ch male Europe 10 51 de male Europe 1.10.1.5 summarise() function Usage: summarise(.data, ...) where ... are name-value pairs of summary functions (e.g., mean(), min(), sum(), n()) More than one summary function can be included First, we want to find the mean, standard deviation, and number of valid observations for the nflights variable airlinesat %&gt;% summarise(mean_flights=mean(nflights, na.rm=TRUE), sd_flights=mean(nflights, na.rm=TRUE), valid_n=sum(!is.na(nflights))) mean_flights sd_flights valid_n 1 13.41878 13.41878 1065 Second, we want to find the same information as above, but by continent group Use the group_by() function before summarise() # NOTE: The output will be of type &#39;tibble&#39; instead of &#39;data.frame&#39; # Tibbles are like data frames, but occasionally behave differently airlinesat %&gt;% mutate(continent=recode_factor(country, at=&quot;Europe&quot;, ch=&quot;Europe&quot;, de=&quot;Europe&quot;, fr=&quot;Europe&quot;, us=&quot;North America&quot;)) %&gt;% group_by(continent) %&gt;% summarise(mean_flights=mean(nflights, na.rm=TRUE), sd_flights=mean(nflights, na.rm=TRUE), valid_n=sum(!is.na(nflights))) # A tibble: 2 x 4 continent mean_flights sd_flights valid_n &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; 1 Europe 13.7 13.7 870 2 North America 12.2 12.2 195 1.11 Package lubridate The lubridate package was created to make working with dates and times a little bit easier. While the package has a great deal of funcationality, this tutorial will only focus on a some of the most common elements. Probably the most useful capability of lubridate is its ability to quickly parse out parts of a text date string, no matter the form of that string. Fast parsing is done through a series of functions that are based on the order of the parts of date/time in the text string. Use ymd() if the order is year, month, day, such as 20101215 or 16/7/1 Use mdy() if the order is month, day, year, such as January 25, 2016 or 5/29/1993 Use dmy() if the order is day, month, year, such as 171210 or 5 January 1990 The results will be the in the format YYYY-MM-DD and have a Date class library(lubridate) ymd(c(&quot;20101215&quot;, &quot;16/7/1&quot;)) [1] &quot;2010-12-15&quot; &quot;2016-07-01&quot; mdy(c(&quot;January 25, 2016&quot;, &quot;5/29/1993&quot;)) [1] &quot;2016-01-25&quot; &quot;1993-05-29&quot; dmy(c(&quot;171210&quot;, &quot;5 January 1990&quot;)) [1] &quot;2010-12-17&quot; &quot;1990-01-05&quot; If time is also included in the text string, that can also be parsed out, such as ymd_hms() where hms stands for hours, minutes, seconds Additionally, lubridate can easily pull out the specific components that are have class Date year(x) returns the year number month(x) returns the number of the month month(x, label=TRUE) returns the month name (abbreviated) day(x) (or mday(x)) returns the number of the day of the month wday(x) returns the number of the day in week, where Sunday = 1 wday(x, label=TRUE) returns the day of the week name (abbreviated) yday(x) returns the number of the day of the year # Use lubridate to create a date class object for my birthday (not really) mybday &lt;- mdy(&quot;March 15, 1973&quot;) year(mybday) [1] 1973 month(mybday) [1] 3 month(mybday, label=TRUE) [1] Mar 12 Levels: Jan &lt; Feb &lt; Mar &lt; Apr &lt; May &lt; Jun &lt; Jul &lt; Aug &lt; Sep &lt; ... &lt; Dec day(mybday) [1] 15 wday(mybday) [1] 5 wday(mybday, label=TRUE) [1] Thu Levels: Sun &lt; Mon &lt; Tue &lt; Wed &lt; Thu &lt; Fri &lt; Sat yday(mybday) [1] 74 1.12 RMarkdown RMarkdown allows users to create documents that combine code and text. Ultimately, they are used for reproducible research. That is, the R Markdown files allow other people to see exactly what was done, and if the data is available to all, other people can reproduce the research. In this class, RMarkdown will be used for the lab assignments. You will write your code in the RMarkdown file, and answer the assignment questions with the code your have written. While RMarkdown has a great deal of functionality, we will focus on a select few of those features. This cheatsheet may be beneficial. 1.12.1 YAML Header The top of every RMarkdown is a section called the YAML header, which is enclosed at the top and bottom with ---. For this class, the only think in the YAML header that you will need to change is the author: section. Figure 1.6: Change Author in YAML Header 1.12.2 Markdown Syntax When writing text in RMarkdown, there isnt a point and click menu to change fonts size or to add italics or bold text or to insert an equation. Instead, it requires the use of markdown syntax. The most commonly used are provided below: Plain text Plain text *Italic* Italic **Bold** Bold ***Bold and Italic*** Bold and Italic # Header 1 Header 1 ## Header 2 Header 2 ### Header 3 Header 3 #### Header 4 Header 4 * Unordered list item * Item 2 * Item 2a (indent 4 spaces) * Item 2b Unordered list item Item 2 Item 2a (indent 4 spaces) Item 2b 1. Ordered list item 2. Item 2 1. Item 2a (indent 4 spaces) 2. Item 2b Ordered list item Item 2 Item 2a (indent 4 spaces) Item 2b `verbatim code` vertabim code equation: $y=\\alpha+\\betax$ equation: \\(y=\\alpha+\\beta x\\) (See this file for symbols) 1.12.3 Code Chunks One of the greatest things about RMarkdown files is the ability to include code, and run the code, within the RMarkdown file. Putting code in the file is done with code chunks. 1.12.3.1 Inserting a Code Chunk Code chunks can be inserted by clicking on the Insert Chunk button in the document toolbar (see Figure 1.7) or by manually typing in the code chunk (see Figure 1.8) Figure 1.7: Inserting a Code Chunk from the Toolbar Figure 1.8: Inserting a Code Chunk Manually 1.12.3.2 Using Code Chunks RMarkdown doesnt pay attention to anything else going on in your R/RStudio session Any objects, data, packages, or user defined scripts must be in a code chunk in RMarkdown However, once they are loaded in a chunk, they do not need to be loaded again in subsequent chunks To run a code chunk, click on the green triangle ( If you run a chunk that does have the necessary object, data, etc., you will get an error message (see Figure 1.9) Figure 1.9: Chunk Error If you need to run previous chunks to load data or packages, click on the gray triangle with the green bar underneath () first, then click on the green triangle (see Figure 1.10) Figure 1.10: Run Previous Chunks, then Run Chunk Once the chunk runs correctly, the result will be shown under the chunk To clear the result, click on the x in the upper right hand corner of the results 1.12.3.3 Knitting the Results At any time, you can Knit the RMarkdown file to an HTML document or a PDF document. While working through the document, HTML is usually quicker. When the document is completed, a PDF is more professional looking (and for this course, required to turn in the lab assignment). To Knit the file, click on the down arrow next to Knit in the document toolbar, and select how you would like to product the document (see Figure 1.11) By default, a document knitted to HTML will be viewable in the Viewer window in the lower right hand side of RStudio. For documents knitted to PDF, RStudio generally opens up a new window with the knitted PDF, from which the file can be saved to a local directory Figure 1.11: Knit a Document "],["examining-and-summarizing-data.html", "Chapter 2 Examining and Summarizing Data 2.1 Introduction 2.2 Visualizations 2.3 Tables and Statistics", " Chapter 2 Examining and Summarizing Data Sources for this chapter: ggplot2: https://ggplot2.tidyverse.org/ 2.1 Introduction Examining and summarizing data involves visualizations (e.g., graphs and charts) and tables. For visualization, the most popular package in R is th ggplot2 package. For this part of the tutorial, the airlinesat.rdata data file is used, which contains the airlinesat dataframe. You should load this data now:load(\"airlinesat.rdata\") 2.2 Visualizations 2.2.1 Package ggplot2 2.2.1.1 Introduction First, make sure the ggplot2 library is loaded: library(ggplot2) ggplot2 is based on the basic idea that for a graph, we need three things: Data: ggplot2 is designed to work with data frames Coordinate system: what are the x and y variables Geoms: how is the data being represented (e.g., points, lines, etc.) AND that the plot can be enhance by adding more layers, using + When ggplot is used in the console or from a script, the plot appears in the Viewer tab of the lower-right corner 2.2.1.2 Usage A plot starts with the ggplot() function, which requires two arguments: Source of the data, which can be piped in (i.e., %&gt;%) The mapping of the data components This argument is an aesthetic function, aes(), which maps the variable(s) to the coordinate system If the ggplot() function alone is used, the output is simply the coordinate system, but with nothing plotted Because a geom hasnt been requested ggplot(airlinesat, # Use data frame &#39;airlinesat&#39; aes(x=country, y=nflights)) # Map &#39;country&#39; on x and &#39;nflights&#39; on y Figure 2.1: Call to ggplot() without a geom Other parts of the plot are adding in layers, using + A good analogy is building a house: The call to ggplot() is the foundation, but the structure is built one layer at a time Example: Request a column chart for a discrete x and a continuous y ggplot(airlinesat, # Use data frame &#39;airlinesat&#39; aes(x=country, y=nflights)) + # Map &#39;country&#39; on x and &#39;nflights&#39; on y geom_col() # Ask for column chart as the geom Figure 2.2: ggplot() + geom_col() NOTE: Each geom has a default statistic to plot In this case, it is summing the nflights variable by country We can use dplyr and ggplot2 together to get a different value, such as the mean # Use airlinesat data airlinesat %&gt;% # Group data by &#39;country&#39; group_by(country) %&gt;% # Create summary statistic summarise(mean_nflights=mean(nflights, na.rm=TRUE)) %&gt;% # Pass this results to ggplot and start the plot ggplot(aes(x=country, y=mean_nflights)) + # Note dataset was `piped` # Request column geom geom_col() Figure 2.3: Using dplyr before ggplot to get mean values Using ggplot() can get much more advanced. As the tutorial progresses, many examples of additional layers to a ggplot() will be shown. 2.2.2 Bar and Column Charts In ggplot, bar charts, geom_bar(), are used for plotting a single discrete variable, while column charts, geom_col(), are used for plotting a discrete variable on the x axis and a continuous variable on the y axis. 2.2.2.1 Bar Charts The standard bar chart provides a count of observations of each category of discrete variable x airlinesat %&gt;% ggplot(aes(x=gender)) + geom_bar() Figure 2.4: Standard bar chart To get percentages of each category, we need to summarize the data and calculate the proportion for each category airlinesat %&gt;% group_by(gender) %&gt;% # Group data by gender summarise(n=n()) %&gt;% # Create variable with count of each gender mutate(prop=n/sum(n)) %&gt;% # Create variable with proportion by gender ggplot(aes(x=gender, # Variable for the x-axis y=prop)) + # Use &#39;prop&#39; instead of default counts for y-axis geom_bar(stat=&quot;identity&quot;) # Use the value of y as-is Figure 2.5: Bar chart with proportions To make the chart pretty, we change the color of each bar we can add layers for axis labels, use the scales package to have the y-axis show percent, add labels for the bars etc. airlinesat %&gt;% group_by(gender) %&gt;% # Group data by gender summarise(n=n()) %&gt;% # Create variable with count of each gender mutate(prop=n/sum(n)) %&gt;% # Create variable with proportion by gender ggplot(aes(x=gender, # Variable for the x-axis y=prop, # Use &#39;prop&#39; instead of default counts for y-axis fill=gender)) + # Use different color for each bar geom_bar(show.legend=FALSE, # Hide legend stat=&quot;identity&quot;, ) + # Use the value of y as-is scale_y_continuous(labels=scales::label_percent()) + # y-axis labels % labs(x=&quot;Gender&quot;, y=&quot;Percent&quot;) + # Label x- and y-axes geom_text(aes(label=sprintf(&quot;%.1f%%&quot;, prop*100)), # Format label number vjust=.95, # Vertically adjust the labels fontface=&quot;bold&quot;, # Bold typeface color=&quot;white&quot;) # Text color Figure 2.6: Prettier bar chart 2.2.2.1.1 Bar Chart Variations 2.2.2.1.1.1 Stacked Bar Chart Used to show one discrete variable by another discrete variable, such as data you would see in a cross-tab The x= variable specifies the axis, while the fill= variable stacks the bars by the other variable As with other bar charts, the default is to count observations, so some manipulation is needed to get 100% stacked bar charts airlinesat %&gt;% group_by(gender, flight_type) %&gt;% # Group data by two discrete variables summarise(n=n()) %&gt;% # Count observations for each combination mutate(prop=n/sum(n)) %&gt;% # Calculate prop WITHIN first grouping variable ggplot(aes(x=gender, y=prop, fill=flight_type)) + geom_bar(position=&quot;fill&quot;, # Stack the bars stat=&quot;identity&quot;) + # Use the value of y as-is scale_y_continuous(labels=scales::label_percent()) + # y-axis labels % labs(x=&quot;Gender&quot;, y=&quot;Percent&quot;, # Label x- and y-axes fill=&quot;Flight Type&quot;) + # Label legend geom_text(aes(label=sprintf(&quot;%.1f%%&quot;, prop*100)), # Format data label position=position_stack(vjust=.95), # Adjust the labels fontface=&quot;bold&quot;, # Bold typeface color=&quot;white&quot;) # Text color Figure 2.7: Stacked bar chart 2.2.2.1.1.2 Side-by-Side Bar Chart Also used to shows one discrete variable by another discrete variable Again, default is to count observations, so some manipulation required to get percentages Percentages can be within a group (like in 100% stacked, see Figure 2.8) or percent of overall total (see Figure 2.9) # NOTE: The code for this chart is nearly identical to the previous figure # ONLY the changes have been commented on below airlinesat %&gt;% group_by(gender, flight_type) %&gt;% summarise(n=n()) %&gt;% mutate(prop=n/sum(n)) %&gt;% ggplot(aes(x=gender, y=prop, fill=flight_type)) + # NOTE: Use position=&quot;dodge&quot; to make bars side-by-side geom_bar(position=&quot;dodge&quot;, stat=&quot;identity&quot;) + scale_y_continuous(labels=scales::label_percent()) + labs(x=&quot;Gender&quot;, y=&quot;Percent&quot;, fill=&quot;Flight Type&quot;) + # NOTE: Use position=position_dodge(width=1) to position labels # in center of each bar horizontally; use vjust=.95 to # position labels at the top of each bar geom_text(aes(label=sprintf(&quot;%.1f%%&quot;, prop*100)), position=position_dodge(width=1), vjust=.95, fontface=&quot;bold&quot;, color=&quot;white&quot;) Figure 2.8: Side-by-side bar chart (% within group) # NOTE: The code for this chart is nearly identical to the previous figure # ONLY the changes have been commented on below airlinesat %&gt;% group_by(gender, flight_type) %&gt;% # NOTE: Use .groups=&quot;drop&quot; to remove the grouping structure after # summarising the data summarise(n=n(), .groups=&quot;drop&quot;) %&gt;% mutate(prop=n/sum(n)) %&gt;% ggplot(aes(x=gender, y=prop, fill=flight_type)) + geom_bar(position=&quot;dodge&quot;, stat=&quot;identity&quot;) + scale_y_continuous(labels=scales::label_percent()) + labs(x=&quot;Gender&quot;, y=&quot;Percent&quot;, fill=&quot;Flight Type&quot;) + geom_text(aes(label=sprintf(&quot;%.1f%%&quot;, prop*100)), position=position_dodge(width=1), vjust=.95, fontface=&quot;bold&quot;, color=&quot;white&quot;) Figure 2.9: Side-by-side bar chart (% of total) 2.2.2.2 Column Charts The standard column chart provides a sum of continuous variable y of each category of disrete variable x airlinesat %&gt;% ggplot(aes(x=flight_type, y=nflights)) + geom_col() Figure 2.10: Standard column chart To get a different summary statistic, such as mean, we can summarize the data and calculate the summary statistic for each category (and make the graph prettier) airlinesat %&gt;% group_by(flight_type) %&gt;% summarise(mean=mean(nflights)) %&gt;% ggplot(aes(x=flight_type, y=mean, fill=flight_type)) + geom_col(show.legend=FALSE) + labs(x=&quot;Flight Type&quot;, y=&quot;Mean Number of Flights&quot;) + geom_text(aes(label=sprintf(&quot;%.2f&quot;, mean)), # Format label number vjust=.95, # Vertically adjust the labels fontface=&quot;bold&quot;, # Bold typeface color=&quot;white&quot;) # Text color Figure 2.11: Column chart showing means 2.2.2.2.1 Side-by-Side Column Chart A side by side column chart can be used to show two discrete variables on the x-axis airlinesat %&gt;% group_by(flight_type, flight_purpose) %&gt;% summarise(mean=mean(nflights), .groups=&quot;drop&quot;) %&gt;% ggplot(aes(x=flight_type, y=mean, fill=flight_purpose)) + geom_col(position=&quot;dodge&quot;) + labs(x=&quot;Flight Type&quot;, y=&quot;Mean Number of Flights&quot;, fill=&quot;Flight Purpose&quot;) + geom_text(aes(label=sprintf(&quot;%.2f&quot;, mean)), position=position_dodge(width=1), vjust=.95, fontface=&quot;bold&quot;, color=&quot;white&quot;) Figure 2.12: Side-by-side column chart 2.2.3 Histogram In ggplot, histograms are produced with the geom_histogram() geom, which produces a histogram of a single continuous variable. By default, the y-axis is a count of observations in each bin of the x variable A bin is a range of values of the continuous x variable By default, ggplot will produce a histogram with 30 bins, and a message is produced to that effect unless the bins are changed manually airlinesat %&gt;% ggplot(aes(x=age)) + geom_histogram() `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Figure 2.13: Standard histogram 2.2.3.1 Changing Bins Histograms can look quite different based on the bins used. Bins can be changed in two ways: (1) number of bins; and (2) bin width Changing the number of bins is done with the bins= option For example: geom_histogram(bins=20) Changing the bin width is done with the binwidth= option For example; geom_histogram(binwidth=5) Use the interactive histograms (Figure 2.14 and Figure 2.15 to see how the histograms change Figure 2.14: Interactive histogram for number of bins Figure 2.15: Interactive histogram for bin width 2.2.3.2 Improving the Look You may find the default histogram a little blah or tough to read. Just as the look of bar and column charts could be changed, so can the look of histograms airlinesat %&gt;% ggplot(aes(x=age)) + geom_histogram(color=&quot;black&quot;, # Adds red border around each bar fill=&quot;tan&quot;) + # Makes each bar blue labs(x=&quot;Age&quot;, y=&quot;Frequency&quot;) Figure 2.16: Prettier histogram 2.2.3.3 Other Options Instead of the default count of observations, a density histogram can be created, where the sum of the area of the bars adds up to 1 Often, a normal curve is added look of bar and column charts could be changed, so can the look of histograms airlinesat %&gt;% ggplot(aes(x=age)) + geom_histogram(aes(y=..density..), # Request density instead of count color=&quot;black&quot;, # Adds red border around each bar fill=&quot;tan&quot;) + # Makes each bar blue stat_function(fun=function(x) # Adds normal curve ovarlay dnorm(x, mean=mean(airlinesat$age, na.rm=TRUE), # Mean of normal dist sd=sd(airlinesat$age, na.rm=TRUE))) + # StdDev of normal dist labs(x=&quot;Age&quot;, y=&quot;Density&quot;) Figure 2.17: Density histogram with normal curve 2.2.4 Box Plot Box Plots are drawn with the geom_boxplot() geom, which by default creates a box plot for a continuous y variable, but for each level of a discrete x variable. In addition, the standard box plot does not contain whiskers. To get a box plot for only the continuous y variable, use x=\"\" as the discrete x variable To add whiskers, include a stat_boxplot(geom=\"errorbar\") layer airlinesat %&gt;% ggplot(aes(x=&quot;&quot;, y=age)) + geom_boxplot() + stat_boxplot(geom=&quot;errorbar&quot;) + # Add whiskers to box plot labs(x=&quot;&quot;, # Remove x axis label y=&quot;Age&quot;) # Make y axis label nicer Figure 2.18: Single box plot with whiskers To make comparisons across a discrete x variable, replaces the x=\"\" from before with x=VARIABLE airlinesat %&gt;% ggplot(aes(x=flight_purpose, y=age)) + geom_boxplot() + stat_boxplot(geom=&quot;errorbar&quot;) + # Add whiskers to box plot labs(x=&quot;Flight Purpose&quot;, y=&quot;Age&quot;) Figure 2.19: Multiple box plot 2.2.5 Scatterplot Scatterplots are drawn with the geom_point() geom and are used to show the relationship between two continuous variables Notice the warning given due to missing values (these warnings will be suppressed in other scatterplots below) airlinesat %&gt;% ggplot(aes(x=age, y=s10)) + # s10 is satisfaction with condition of airplane geom_point() Warning: Removed 40 rows containing missing values (geom_point). Figure 2.20: Standard scatterplot 2.2.5.1 Trendline Scatterplots become more helpful when we add a trend line. The most common trend line is a simple regression line, although others can be used. Use geom_smooth(method=\"lm\", se=FALSE) to add a linear trend line airlinesat %&gt;% ggplot(aes(x=age, y=s10)) + # s10 is satisfaction with condition of airplane geom_point() + geom_smooth(method=&quot;lm&quot;, se=FALSE) + # Add trendline labs(x=&quot;Age&quot;, y=&quot;Satisfaction with Aircraft Condition&quot;) Figure 2.21: Scatterplot with trendline 2.2.5.2 Other Options The color, https://ggplot2.tidyverse.org/articles/ggplot2-specs.html#sec:shape-spec, and size of the points can be changed In addition, they can vary by levels of a discrete variable If a trend line is requested, separate trend lines will be provided for each level of the discrete variable airlinesat %&gt;% ggplot(aes(x=age, y=s10, color=flight_type)) + geom_point(shape=17) + geom_smooth(method=&quot;lm&quot;, se=FALSE) + # Add trendline labs(x=&quot;Age&quot;, y=&quot;Satisfaction with Aircraft Condition&quot;, color=&quot;Flight Type&quot;) Figure 2.22: Scatterplot with different colors for discrete variable 2.3 Tables and Statistics 2.3.1 Frequency Table The freq() command from the package questionr produces nice one-way frequency tables (i.e., a frequency table for a single discrete variable) library(questionr) freq(airlinesat$language, # Provide discrete variable cum=TRUE, # Add cumulative percent column total=TRUE) # Add total row at bottom n % val% %cum val%cum English 233 21.9 21.9 21.9 21.9 French 10 0.9 0.9 22.8 22.8 German 822 77.2 77.2 100.0 100.0 Total 1065 100.0 100.0 100.0 100.0 Table 2.1: One-way frequency table Use package htmlTable() to produce a nicer looking table for output in the viewer (vs. the console) library(htmlTable) freq(airlinesat$flight_type, cum=TRUE, total=TRUE) %&gt;% # Pass result to htmlTable htmlTable() n % val% %cum val%cum Domestic 558 52.4 52.4 52.4 52.4 International 507 47.6 47.6 100 100 Total 1065 100 100 100 100 Table 2.2: One-way frequency table using htmlTable 2.3.2 Crosstabs 2.3.2.1 Base R Base R does not do a great job of easily creating cross-tabs and testing for independent of the two variables Using base R, a multistep process is required Create the two-way frequency table using the table(rowvar, colvar) function and assign it to a separate object Display the two-way freq table by just using the table name Use the function proportions(tablename, margin) on the newly created object to get column, row, or total percentages proportions(tablename) gives total percentages proportions(tablename, 1) gives row percentages proportions(tablename, 2) gives column percentages Use the function chisq.test(tablename) on the newly created object to run the test of independence # Create two way table crosstab &lt;- table(airlinesat$flight_purpose, # row Variable airlinesat$gender) # Column variable crosstab # Display 2-way freq table female male Business 76 449 Leisure 204 336 proportions(crosstab, 2) # Display column percentages female male Business 0.2714286 0.5719745 Leisure 0.7285714 0.4280255 chisq.test(crosstab) # Run test of independence Pearson&#39;s Chi-squared test with Yates&#39; continuity correction data: crosstab X-squared = 73.386, df = 1, p-value &lt; 2.2e-16 Table 2.3: Cross-tabs using Base R The look of the tables can be improved with the htmlTable package htmlTable(crosstab) female male Business 76 449 Leisure 204 336 htmlTable(round(proportions(crosstab,2)*100, 2)) female male Business 27.14 57.2 Leisure 72.86 42.8 Table 2.4: Cross-tabs using htmlTable 2.3.2.2 Alternative Packages The following packages are not availabe through the BGSU Virtual Computing lab, but can be installed if using R/RStudio on your own machine. These packages produce nicely formatted crosstabs. 2.3.2.2.1 Package sjPlot Use the function tab_xtab(var.row=, var.col=, show.col.prc=TRUE) to get a standard crosstab with column percentages library(sjPlot) tab_xtab(var.row=airlinesat$flight_purpose, var.col=airlinesat$gender, show.col.prc=TRUE) flight_purpose gender Total female male Business 7627.1 % 44957.2 % 52549.3 % Leisure 20472.9 % 33642.8 % 54050.7 % Total 280100 % 785100 % 1065100 % 2=73.386  df=1  =0.265  p=0.000 Table 2.5: Cross-tab using sjPlot 2.3.2.2.2 Package gmodels FunctionCrossTable(rowvar, colvar, OPTIONS) has many options similar to SPSS library(gmodels) CrossTable(airlinesat$flight_purpose, airlinesat$gender, prop.r=FALSE, # Exclude row percentages prop.t=FALSE, # Exclude total percentages, prop.chisq=FALSE, # Exclude cell contribution to chi-sq digits=2, # 2 digits after decimal point chisq=TRUE, # Request test of independence format=&quot;SPSS&quot;) # Request SPSS formatting Cell Contents |-------------------------| | Count | | Column Percent | |-------------------------| Total Observations in Table: 1065 | airlinesat$gender airlinesat$flight_purpose | female | male | Row Total | --------------------------|-----------|-----------|-----------| Business | 76 | 449 | 525 | | 27.14% | 57.20% | | --------------------------|-----------|-----------|-----------| Leisure | 204 | 336 | 540 | | 72.86% | 42.80% | | --------------------------|-----------|-----------|-----------| Column Total | 280 | 785 | 1065 | | 26.29% | 73.71% | | --------------------------|-----------|-----------|-----------| Statistics for All Table Factors Pearson&#39;s Chi-squared test ------------------------------------------------------------ Chi^2 = 74.58406 d.f. = 1 p = 5.811064e-18 Pearson&#39;s Chi-squared test with Yates&#39; continuity correction ------------------------------------------------------------ Chi^2 = 73.38648 d.f. = 1 p = 1.065938e-17 Minimum expected frequency: 138.0282 Table 2.6: Cross-tab using gmodels 2.3.3 Measures of Centrality and Dispersion 2.3.3.1 Base R Any individual summary statistic can be easily calculated using Base R with functions such as: mean(x) for mean sd(x) for standard deviation quantile(x, .percentile) for percentiles (e.g., .50 would be median) For summary statistics except for standard deviation, the summary(object) function can be used, where object can be a single variable or an entire data frame # Summary for a single variable summary(airlinesat$nflights) Min. 1st Qu. Median Mean 3rd Qu. Max. 1.00 4.00 8.00 13.42 16.00 457.00 Table 2.7: Summary statistics in R Base, one variable # Subset of airlinesat summary(airlinesat[,c(&quot;age&quot;, &quot;nflights&quot;, &quot;s10&quot;)]) age nflights s10 Min. : 19.00 Min. : 1.00 Min. : 1.00 1st Qu.: 42.00 1st Qu.: 4.00 1st Qu.: 50.00 Median : 50.00 Median : 8.00 Median : 61.00 Mean : 50.42 Mean : 13.42 Mean : 64.54 3rd Qu.: 58.00 3rd Qu.: 16.00 3rd Qu.: 83.00 Max. :101.00 Max. :457.00 Max. :100.00 NA&#39;s :40 Table 2.8: Summary statistics in R Base, multiple variables Summary statistics for a continuous variable by different levels of a discrete variable can also be done in Base R using the tapply(continuous variable, discrete variable, function) function tapply(airlinesat$nflights, # Continous variable to apply the function to airlinesat$flight_purpose, # Discrete, grouping variable summary) # R function to apply by group $Business Min. 1st Qu. Median Mean 3rd Qu. Max. 1.00 6.00 12.00 18.65 25.00 120.00 $Leisure Min. 1st Qu. Median Mean 3rd Qu. Max. 1.000 3.000 4.000 8.337 8.000 457.000 Table 2.9: Summary statistics in R Base, one variable, grouped 2.3.3.2 Package dplyr The dplyr package can also be used to manually create tables of summary statistics One continuous variable airlinesat %&gt;% summarise(mean=mean(age), sd=sd(age), q1=quantile(age, .25), median=quantile(age,.50), q3=quantile(age, .75)) mean sd q1 median q3 1 50.41972 12.27464 42 50 58 Table 2.10: Summary statistics using dplyr, one variable Multiple continuous variables airlinesat %&gt;% select(age, nflights, s10) %&gt;% summary() age nflights s10 Min. : 19.00 Min. : 1.00 Min. : 1.00 1st Qu.: 42.00 1st Qu.: 4.00 1st Qu.: 50.00 Median : 50.00 Median : 8.00 Median : 61.00 Mean : 50.42 Mean : 13.42 Mean : 64.54 3rd Qu.: 58.00 3rd Qu.: 16.00 3rd Qu.: 83.00 Max. :101.00 Max. :457.00 Max. :100.00 NA&#39;s :40 Table 2.11: Summary statistics using dplyr, multiple variables One continuous variable by a discrete/grouping variable airlinesat %&gt;% group_by(flight_purpose) %&gt;% summarise(mean=mean(age), sd=sd(age), q1=quantile(age, .25), median=quantile(age,.50), q3=quantile(age, .75)) # A tibble: 2 x 6 flight_purpose mean sd q1 median q3 &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 Business 48.5 9.91 41 49 55 2 Leisure 52.3 14.0 43 53 63 Table 2.12: Summary statistics using dplyr, one variable, grouped 2.3.3.3 Package vtable Package vtable produces very nice looking tables of summary statistics, but it isnt available in BGSUs Virtual Computer Lab. Use function sumtable(data, vars=\"varname\") to produce the table One continuous variable library(vtable) sumtable(airlinesat, vars=&quot;nflights&quot;) Variable N Mean Std. Dev. Min Pctl. 25 Pctl. 75 Max nflights 1065 13.419 20.226 1 4 16 457 Table 2.13: Summary statistics using vtable, one variable Multiple continuous variables sumtable(airlinesat, vars=c(&quot;nflights&quot;,&quot;age&quot;,&quot;s10&quot;), # Use `c()` for multiple variables add.median=TRUE) # Request median Table 2.14: Summary Statistics Variable N Mean Std. Dev. Min Pctl. 25 Pctl. 50 Pctl. 75 Max nflights 1065 13.419 20.226 1 4 8 16 457 age 1065 50.42 12.275 19 42 50 58 101 s10 1025 64.539 21.408 1 50 61 83 100 Table 2.14: Summary statistics using vtable, multiple variable One or more continuous variables by a discrete/grouping variable sumtable(airlinesat, vars=c(&quot;nflights&quot;,&quot;age&quot;,&quot;s10&quot;), add.median=TRUE, group=&quot;flight_purpose&quot;) Variable N Mean SD Median N Mean SD Median flight_purpose Business Leisure nflights 525 18.646 17.665 12 540 8.337 21.254 4 age 525 48.497 9.911 49 540 52.289 13.958 53 s10 511 61.955 21.14 60 514 67.107 21.384 65 Table 2.15: Summary statistics using vtable, multiple variables, grouped 2.3.4 Correlation Correlation provides a measure of the strength of association between two continuous variables. 2.3.4.1 Base R Base R can easily provide the correlation and a test of the correlation using the cor.test(variable1, variable2) function By default, it includes only observations that are non-missing in both variables cor.test(airlinesat$age, airlinesat$nflights) Pearson&#39;s product-moment correlation data: airlinesat$age and airlinesat$nflights t = -3.7998, df = 1063, p-value = 0.000153 alternative hypothesis: true correlation is not equal to 0 95 percent confidence interval: -0.17461941 -0.05608231 sample estimates: cor -0.115763 Table 2.16: Correlation with test in Base R Base R can also easily provide a correlation matrix of variables using the cor(data) function By default, correlation will only be calculated for those pairs of variables that have no missing values Use option use=\"pairwise.complete.obs\" to exclude observations that are non-missing in both variables However, Base R cannot produce a correlation matrix with p-values # First create data frame with only variables wanted mycorr &lt;- airlinesat[,c(&quot;age&quot;, &quot;nflights&quot;, &quot;s10&quot;)] # Use function `round` to limit to 3 digits after decimal point round(cor(mycorr, use=&quot;pairwise.complete.obs&quot;), 3) age nflights s10 age 1.000 -0.116 0.167 nflights -0.116 1.000 -0.121 s10 0.167 -0.121 1.000 Table 2.17: Correlation matrix in Base R 2.3.4.2 Package Hmisc The function rcorr() from the package Hmisc, which is available in the BGSU Virtual Computing Lab, can be used to create correlation matrices also The rcorr() function requires a matrix, so the data frame of variables must be coerced into a matrix first By default, rcorr() produces three separate matrices: correlation, number of observations, and p-values Separate tables can be requested rcorr(as.matrix(dataframe))]]\"r\"]] provides the correlation matrix rcorr(as.matrix(dataframe))]]\"P\"]] provides the matrix of p-values Separate tables can used with htmlTable() for nicer output library(Hmisc) rcorr(as.matrix(mycorr)) # NOTE: &#39;mycorr&#39; created in previous code age nflights s10 age 1.00 -0.12 0.17 nflights -0.12 1.00 -0.12 s10 0.17 -0.12 1.00 n age nflights s10 age 1065 1065 1025 nflights 1065 1065 1025 s10 1025 1025 1025 P age nflights s10 age 2e-04 0e+00 nflights 2e-04 1e-04 s10 0e+00 1e-04 Table 2.18: Correlation matrix using Hmisc # Use &#39;round()&#39; function to limit digits in output htmlTable(round(rcorr(as.matrix(mycorr))[[&quot;r&quot;]],4)) htmlTable(round(rcorr(as.matrix(mycorr))[[&quot;P&quot;]],5)) age nflights s10 age 1 -0.1158 0.1671 nflights -0.1158 1 -0.1206 s10 0.1671 -0.1206 1 age nflights s10 age 0.00015 0 nflights 0.00015 0.00011 s10 0 0.00011 Table 2.19: Separate correlation matrix output using Hmisc 2.3.4.3 Package sjPlot The function tab_corr() from the sjPlot package produces very nice correlation matrices sjPlot is not available in BGSUs Virtual Computing Lab library(sjPlot) tab_corr(mycorr, # Data frame of variables to use; created earlier na.deletion = &quot;pairwise&quot;, # Delete obs if either variable is missing corr.method = &quot;pearson&quot;, # Choose Pearson correlation coefficient show.p = TRUE, # Show asterisks for significant correlations digits = 3, # Show three decimal points triangle = &quot;lower&quot;, # Show only lower triangle fade.ns=FALSE) # Do not fade insignficant correlations) age nflights s10 age nflights -0.116*** s10 0.167*** -0.121*** Computed correlation used pearson-method with pairwise-deletion. Table 2.20: Correlation matrix output using sjPlot 2.3.4.4 Package GGally The ggpairs() function from package GGally can produce a combination scatterplot and correlation matrix library(GGally) ggpairs(mycorr, # Data frame created earlier lower=list(continuous=wrap(&quot;smooth&quot;, # Adds fit lines... method=&quot;lm&quot;, # Using linear regression... se=FALSE, # Without CI bands color=&quot;blue&quot;)), # Color dots diag=list(continuous=&quot;blankDiag&quot;)) # Sets diagonals to be blank Figure 2.23: Combination scatterplot/correlation matrix using GGally "],["linear-regression.html", "Chapter 3 Linear Regression 3.1 Introduction 3.2 The lm() Function 3.3 Prediction 3.4 Margin Plots", " Chapter 3 Linear Regression Sources for this chapter: R for Marketing Research ad Analytics, Second Edition (2019). Chris Chapman and Elea McDonnell Feit http://r-marketing.r-forge.r-project.org/index.html ggplot2: https://ggplot2.tidyverse.org/ Data for this chapter: Once again, the airlinesat.rdata is used. Load it now. # You may need to change the directory load(&quot;Data/airlinesat.rdata&quot;) 3.1 Introduction Base R is typically sufficient for performing most regression tasks. Some additional packages may be used for prettier tables or extracting results to make useful plots. 3.2 The lm() Function Basic linear regression is performed using the lm() function. Usage: lm(formula, data) In R, a formula is represented by dependent variables on the left side separated from the independent variables on the right side by a tilde(~), such as: dv ~ iv1 + iv2 For interactions between independent variables, use either * or : * will include the interaction term AND each main effect : will include ONLY the iteraction term Examples: y ~ x1 + x2*x3 is the same as: \\(y=x_1+x_2+x_3+(x_2\\times x_3)\\) y ~ x1 + x2:x3 is the same as: \\(y=x_1+(x_2\\times x_3)\\) y ~ x1 + x2 + x2:x3 is the same as: \\(y=x_1+x_2+(x_2\\times x_3)\\) If lm() is run by itself, R only outputs the coefficients lm(nps ~ age + nflights, airlinesat) Call: lm(formula = nps ~ age + nflights, data = airlinesat) Coefficients: (Intercept) age nflights 6.786100 0.016985 -0.009112 Table 3.1: Coefficients from lm() call However, if the results of the lm() call are assigned to an object, the summary() function can be used to get much more detailed output model1 &lt;- lm(nps ~ age + nflights, airlinesat) summary(model1) Call: lm(formula = nps ~ age + nflights, data = airlinesat) Residuals: Min 1Q Median 3Q Max -6.988 -1.316 0.440 1.725 7.682 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 6.786100 0.310554 21.852 &lt; 2e-16 *** age 0.016985 0.005815 2.921 0.00357 ** nflights -0.009112 0.003529 -2.582 0.00995 ** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 2.313 on 1062 degrees of freedom Multiple R-squared: 0.01591, Adjusted R-squared: 0.01406 F-statistic: 8.587 on 2 and 1062 DF, p-value: 0.0001997 Table 3.2: Summary results from lm() call For nicer looking results, the package jtools can be used NOTE: jtools is no available in BGSUs Virtual Computing Lab library(jtools) summ(model1, # Saved object from before digits=4, # How many digits to display in each column model.info = FALSE) # Suppress extraneous information F(2,1062) 8.5875 R 0.0159 Adj. R 0.0141 Est. S.E. t val. p (Intercept) 6.7861 0.3106 21.8516 0.0000 age 0.0170 0.0058 2.9208 0.0036 nflights -0.0091 0.0035 -2.5822 0.0100 Standard errors: OLS Table 3.3: Summary results from lm() using jtools package To get standardized beta coefficients, use the lm_beta user defined function. source(&quot;lm_beta.R&quot;) # Download lm_beta.R and put in working directory lm_beta(model1, # Saved object with results digits=4) # Number of digits to diplsy Std.Beta (Intercept) 0.0000 age 0.0895 nflights -0.0791 Table 3.4: Standardized Beta Coefficients 3.3 Prediction The function predict.lm() can be used to predict the DV based on values of the IVs. This function is used in the margin plots covered in the next two sections. To use this function, we must pass a data frame of values to the function, where the data frame contains ALL of the IVs and the value for each IV that we want. Suppose we wanted to predict, with a confidence interval, the nps of someone that is 45 years old and had 25 flights on the airline, and also someone that is 25 years old and had 45 flights on the airline. First, we create the data frame of values (see 1.6.2.1): values &lt;- data.frame(age=c(45, 25), nflights=c(25, 45)) # Create data frame values # Verify values age nflights 1 45 25 2 25 45 Second the data frame is passed to the predict.lm() function with confidence intervals requested: predict.lm(model1, # The model we are using to predict values, # The data frame of values to predict with interval=&quot;confidence&quot;) # Request confidence interval fit lwr upr 1 7.322601 7.153951 7.491252 2 6.800657 6.431058 7.170255 3.4 Margin Plots In R, margin plots are a multistep process: Create a data frame of IV values to use in the prediction. For the variable of interest, this is usually a sequence of values from about the minimum to about the maximum For other variables in the model: Continuous variables are usually evaluated an the sample mean Factor variables are usually evaluated at each level of the factor Use the predict.lm() function to use the model results to predict the linear fit of the simulated observations in the new data frame Use ggplot to create the margin plot # Want to predict &#39;nps&#39; for different levels of &#39;age&#39; # when &#39;nflights&#39; is at the mean # First, create a data frame of values to predict, using the &#39;crossing&#39; # function from the &#39;tidyr&#39; package library(tidyr) # Load tidyr # NOTE: variable names must be EXACTLY the same as in original model pred_iv &lt;- crossing(age=seq(15, 105, 10), # Different values of &#39;age&#39; nflights=mean(airlinesat$nflights, # mean &#39;nflights&#39; na.rm=TRUE)) # remove missing values # Use the model results to predict &#39;nps&#39; for values in &#39;pred_iv&#39; data frame # Predicted values and confidence intervals get appended to data frame # New variables are called: # &#39;pred$fit&#39; = linear prediction from model # &#39;pred$lwr&#39; = lower confidence interval for prediction # &#39;pred$upr&#39; = upper confidcent interval for prediction pred_iv$pred &lt;- as.data.frame( predict.lm(model1, pred_iv, interval=&quot;confidence&quot;)) # &#39;pred_iv&#39; now contains all necessary information for margin plot pred_iv %&gt;% ggplot(aes(x=age, # Age on x-axis y=pred$fit)) + # &#39;nps&#39; prediction on y-axis geom_line(size=1) + # Draw predicted line geom_ribbon(aes(ymin=pred$lwr, # Draws the confidence interval bands ymax=pred$upr), alpha=0.2) + # Sets transparency level labs(x=&quot;Age&quot;, y=&quot;Linear Prediciton&quot;) Figure 3.1: Single margin plot 3.4.1 Separate Margin Plots If creating separate plots for each continuous IV, it is best to have the prediction (y) variable have the same scale Doing so might take some trial and error after looking at graphs once Use the function plot_grid() from the cowplot package to make the plots appear in the same figure Save each plot as an object, then pass the objects to plot_grid() library(cowplot) # Ask for min and max of the 95% confidence bands to adjust y-axis min(pred_iv$pred$lwr) [1] 6.491185 max(pred_iv$pred$upr) [1] 9.085342 # Save previous plot (for &#39;age&#39;) as plot 1 plot1 &lt;- pred_iv %&gt;% ggplot(aes(x=age, # Age on x-axis y=pred$fit)) + # &#39;nps&#39; prediction on y-axis geom_line(size=1) + # Draw predicted line geom_ribbon(aes(ymin=pred$lwr, # Draws the confidence interval bands ymax=pred$upr), alpha=0.2) + # Sets transparency level labs(x=&quot;Age&quot;, y=&quot;Linear Prediciton&quot;) + scale_y_continuous(limits=c(5.25,9.25)) # Set scale limits for y-axis # Create second plot for &#39;nflights&#39; and save as plot 2 pred_iv &lt;- crossing(nflights=seq(0, 150, 15), age=mean(airlinesat$age, na.rm=TRUE)) pred_iv$pred &lt;- as.data.frame( predict.lm(model1, pred_iv, interval=&quot;confidence&quot;)) min(pred_iv$pred$lwr) [1] 5.319659 max(pred_iv$pred$upr) [1] 7.809707 plot2 &lt;- pred_iv %&gt;% ggplot(aes(x=nflights, y=pred$fit)) + geom_line(size=1) + geom_ribbon(aes(ymin=pred$lwr,ymax=pred$upr),alpha=0.2) + labs(x=&quot;Number of Flights&quot;, y=&quot;Linear Prediciton&quot;) + scale_y_continuous(limits=c(5.25,9.25)) # Set scale limits for y-axis plot_grid(plot1,plot2) Figure 3.2: Separate margin plots 3.4.2 Continuous IV at Levels of Factor IV Margin plots when one of the variables is a factor variable are done in much the same way, but require an aes(color=factor) to produce different lines for each level of the factor model2 &lt;- lm(nps ~ age*flight_purpose, airlinesat) summary(model2) Call: lm(formula = nps ~ age * flight_purpose, data = airlinesat) Residuals: Min 1Q Median 3Q Max -6.9197 -1.0779 0.3226 1.8153 4.1003 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 5.51007 0.50217 10.973 &lt; 2e-16 *** age 0.03563 0.01015 3.512 0.000463 *** flight_purposeLeisure 1.98261 0.63238 3.135 0.001765 ** age:flight_purposeLeisure -0.02986 0.01238 -2.411 0.016072 * --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 2.302 on 1061 degrees of freedom Multiple R-squared: 0.0262, Adjusted R-squared: 0.02345 F-statistic: 9.516 on 3 and 1061 DF, p-value: 3.322e-06 Table 3.5: Summary results of model with interaction pred_iv &lt;- crossing(age=seq(15, 105, 10), # Different values of &#39;age&#39; flight_purpose=c(&quot;Leisure&quot;, &quot;Business&quot;)) # factor levels pred_iv$pred &lt;- as.data.frame( predict.lm(model2, pred_iv, interval=&quot;confidence&quot;)) pred_iv %&gt;% # Use &#39;color&#39; aesthetic for separate lines for &#39;flight purpose&#39; ggplot(aes(x=age, y=pred$fit, color=as.factor(flight_purpose))) + geom_line(size=1) + # Use &#39;fill&#39; aesthetic for separate colors for the CI bands geom_ribbon(aes(ymin=pred$lwr, ymax=pred$upr, fill=as.factor(flight_purpose)), alpha=0.2) + labs(x=&quot;Age&quot;, y=&quot;Linear Prediciton&quot;, fill=&quot;Flight Purpose&quot;, color=&quot;Flight Purpose&quot;) Figure 3.3: Margin plot with factor variable "],["logistic-regression-binary.html", "Chapter 4 Logistic Regression (Binary) 4.1 Introduction 4.2 The glm() Function 4.3 Logistic Regression using glm() 4.4 Estimate with Training Sample Only 4.5 Classification Matrix 4.6 ROC Curve 4.7 Gain/Lift Charts and Tables 4.8 Sensitivity/Specificity Plot", " Chapter 4 Logistic Regression (Binary) Sources for this chapter: R for Marketing Research ad Analytics, Second Edition (2019). Chris Chapman and Elea McDonnell Feit http://r-marketing.r-forge.r-project.org/index.html ggplot2: https://ggplot2.tidyverse.org/ Data for this chapter: The directmktg.rdata is used. Load it now. # You may need to change the directory load(&quot;Data/directmktg.rdata&quot;) 4.1 Introduction Base R is typically sufficient for performing the basics of logisitic regression, but to get some of the outputs required, I have created some user defined functions. You should download these functions and save them in your working directory. or_table.R produces Odds Ratio Coefficients logreg_cm.R produces the Classification Matrix logreg_roc.R produces the ROC Curves gainlift.R produces Gain/Lift tables and charts logreg_cut.R produces the Sensitivity/Specificity Plot Once saved in your working directory, it is good practice to source them. source(&quot;or_table.R&quot;) source(&quot;logreg_cm.R&quot;) source(&quot;logreg_roc.R&quot;) source(&quot;gainlift.R&quot;) source(&quot;logreg_cut.R&quot;) 4.2 The glm() Function glm stands for Generalized Linear Model, and this function can be used with a variety of dependent variables by specifying different family=\"FAMILY\" options *lm(dv ~ iv1 + iv2, data) is the same as `glm(dv ~ iv1 + iv2, data, family=gaussian) Usage: glm(formula, data, family) 4.3 Logistic Regression using glm() Binary logistic regression is performed using the glm() function when the family=\"binomial\" is specified. Usage: glm(formula, data, family=\"binonmial\") family=\"binomial\" tells R to use logistic regression on a binary dependent variable If glm(formula, data, family=\"binomial\") is run by itself, R only outputs the **Logit formulation* coefficients (and some other measures) glm(buy ~ age + gender, directmktg, family=&quot;binomial&quot;) Call: glm(formula = buy ~ age + gender, family = &quot;binomial&quot;, data = directmktg) Coefficients: (Intercept) age genderFemale -8.02069 0.18954 -0.09468 Degrees of Freedom: 399 Total (i.e. Null); 397 Residual Null Deviance: 521.6 Residual Deviance: 336.1 AIC: 342.1 Table 4.1: Logit Coefficients from glm() call However, if the results of the glm() call are assigned to an object, the Base R summary() function can be used to get much more detailed output, but requires manual calculation of McFaddens Pseudo-\\(R^2\\) prelim &lt;- glm(buy ~ age + gender, directmktg, family=&quot;binomial&quot;) summary(prelim) Call: glm(formula = buy ~ age + gender, family = &quot;binomial&quot;, data = directmktg) Deviance Residuals: Min 1Q Median 3Q Max -2.4952 -0.6679 -0.2844 0.5748 2.4684 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -8.02069 0.78700 -10.191 &lt;2e-16 *** age 0.18954 0.01926 9.842 &lt;2e-16 *** genderFemale -0.09468 0.27354 -0.346 0.729 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 521.57 on 399 degrees of freedom Residual deviance: 336.14 on 397 degrees of freedom AIC: 342.14 Number of Fisher Scoring iterations: 5 # Manually calculate McFadden&#39;s Pseudo R-sq Mrsq &lt;- 1-prelim$deviance/prelim$null.deviance cat(&quot;McFadden&#39;s Pseudo-Rsquared = &quot;, Mrsq) McFadden&#39;s Pseudo-Rsquared = 0.3555239 Table 4.2: Summary results from glm() call For nicer looking results, the package jtools can be used NOTE: jtools is not available in BGSUs Virtual Computing Lab library(jtools) summ(prelim, # Saved object from before digits=4, # How many digits to display in each column model.info = FALSE) # Suppress extraneous information (2) 185.4317 Pseudo-R (Cragg-Uhler) 0.5092 Pseudo-R (McFadden) 0.3555 AIC 342.1413 BIC 354.1157 Est. S.E. z val. p (Intercept) -8.0207 0.7870 -10.1915 0.0000 age 0.1895 0.0193 9.8422 0.0000 genderFemale -0.0947 0.2735 -0.3461 0.7293 Standard errors: MLE Table 4.3: Summary results from glm() using jtools package To get the Odds Ratio coefficients, use the user defined function or_table.R Usage: or_table(MODEL, DIGITS, CONF) MODEL is the name of the object with results of the glm() call DIGITS is the number of digits to round the values to in the table CONF is the confidence interval level (e.g., 95 = 95%) flextable( # Wrapping it with &#39;flextable&#39; for nicer output or_table(prelim, # Saved logistic regression model from above 4, # Number of digits to round output to 95)) # Level of confidence .tabwid table{ border-spacing:0px !important; border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 1.275em; margin-bottom: 1.275em; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-5543a43e{}.cl-553d190c{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-553d190d{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-553d190e{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-553d66fa{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-553d66fb{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-553d66fc{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-553d66fd{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-553d66fe{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-553d66ff{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} ParameterOR Estp2.5%97.5%(Intercept)0.00030.00000.00010.0015age1.20870.00001.16391.2552genderFemale0.90970.72930.53221.5550 Table 4.4: Odds Ratio Coefficients 4.4 Estimate with Training Sample Only Generally, it is good practice to use a training sample and a testing/holdout sample to see how well the model performs out of sample. To do this, the data must be split into two groups: train and test 4.4.1 Creating train and test Samples While this can be done in a number of ways, the package caret has a very useful function that attempts to balance the percent of positive cases in both samples, while still creating random samples After running this procedure, two new data frames will be created One containing the training data, train One containing the testing/holdout data, test # Use &#39;caret&#39; package to create training and test/holdout samples # This will create two separate dataframes: train and test library(caret) # Load the &#39;caret package&#39; # Start by setting a random number seed so that the same samples # will be created each time set.seed(4320) # Create a dataframe of row numbers that should be in the &#39;train&#39; sample inTrain &lt;- createDataPartition(y=directmktg$buy, # Outcome variable p=.75, # Percent of sample to be in &#39;train&#39; list=FALSE) # Put result in matrix # Select only rows from data that are in &#39;inTrain&#39;; assign to &#39;train&#39; train &lt;- directmktg[inTrain,] # Select only rows from data that not in &#39;inTrain&#39;; assign to &#39;test&#39; test &lt;- directmktg[-inTrain,] 4.4.2 Run Model with only Training Sample Once completed, run the model on the training sample only model &lt;- glm(buy ~ age + gender, train, family=&quot;binomial&quot;) summ(model, # &#39;jtools&#39; results; use &#39;summary&#39; for Base R 4, model.info=FALSE) (2) 130.57 Pseudo-R (Cragg-Uhler) 0.48 Pseudo-R (McFadden) 0.33 AIC 268.37 BIC 279.49 Est. S.E. z val. p (Intercept) -7.71 0.87 -8.81 0.00 age 0.18 0.02 8.52 0.00 genderFemale -0.01 0.31 -0.04 0.97 Standard errors: MLE; Continuous predictors are mean-centered and scaled by 1 s.d. flextable(or_table(model)) .tabwid table{ border-spacing:0px !important; border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 1.275em; margin-bottom: 1.275em; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-380b1856{}.cl-380529fa{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-380550ec{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-380550ed{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-380577f2{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-380577f3{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-380577f4{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-380577f5{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-380577f6{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-380577f7{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} ParameterOR Estp2.5%97.5%(Intercept)0.00040.0000.00010.0025age1.19960.0001.15051.2509genderFemale0.98730.9670.53991.8056 Table 4.5: Logistic Regression Results for Training Sample 4.5 Classification Matrix To get the Classification Matrix, use the user defined function logreg_cm.R Usage: logreg_cm(MOD, DATA, \"POS\", CUTOFF=) MOD is the name of the object with results of the glm() call DATA is the data set for which the Classification Matrix should be produced (i.e., original, training, or testing) \"POS\" is the level of the factor variable that is the SUCCESS level CUTOFF= is the cutoff threshold; default is 0.5 This function requires the package caret, which should already be loaded from the splitting of the data # Classification Matrix for training sample logreg_cm(model, # Name of the results object train, # Use training sample &quot;Yes&quot;) # Level of &#39;buy&#39; that represents success/true Confusion Matrix and Statistics Reference Prediction No Yes No 179 37 Yes 14 71 Accuracy : 0.8306 95% CI : (0.7833, 0.8712) No Information Rate : 0.6412 P-Value [Acc &gt; NIR] : 3.179e-13 Kappa : 0.6136 Mcnemar&#39;s Test P-Value : 0.002066 Sensitivity : 0.6574 Specificity : 0.9275 Pos Pred Value : 0.8353 Neg Pred Value : 0.8287 Prevalence : 0.3588 Detection Rate : 0.2359 Detection Prevalence : 0.2824 Balanced Accuracy : 0.7924 &#39;Positive&#39; Class : Yes PCC = 53.99% Table 4.6: Classification Matrix for Training Sample 4.6 ROC Curve To get the ROC curve, use the user defined function logreg_roc.R Usage: logreg_roc(MOD, DATA) MOD is the name of the object with results of the glm() call DATA is the data set for which the ROC should be produced (i.e., original, training, or testing) This function requires the package pROC, which needs to be loaded # Load &#39;pROC&#39; package library(pROC) # ROC Curve for the training sample logreg_roc(model, # Name of the results object train) # Use training sample Figure 4.1: ROC Curve for Training Sample 4.7 Gain/Lift Charts and Tables To get the Gain/Lift charts and tables , use the user defined function gainlift.R Usage: OBJ.NAME &lt;- gainlift(MOD, TRAIN, TEST, \"POS\") OBJ.NAME is the name of the object to assign the results to MOD is the name of the object with results of the glm() call TRAIN is the name of the data frame containing the training sample TEST is the name of the data frame containing the test/holdout sample \"POS\" is the level of the factor variable that is the SUCCESS level This function requires the ggplot2, dplyr, and tidyr packages, which need to be loaded first This user defined function returns a list of four objects To use, assign the result to an object name, and then call one of the four objects returned from the function # Load necessary packages (if not already loaded) library(ggplot2) library(dplyr) library(tidyr) # Call the function and assign to object named &#39;glresults&#39; glresults &lt;- gainlift(model, # Name of the glm results object train, # Name of the training data frame test, # Name of the testing data frame &quot;Yes&quot;) # Level that represents success/true OBJ.NAME$gaintable returns the Gain table glresults$gaintable # A tibble: 20 x 3 `% Sample` Holdout Training &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 0.05 0.114 0.130 2 0.1 0.229 0.269 3 0.15 0.371 0.370 4 0.2 0.457 0.5 5 0.25 0.6 0.602 6 0.3 0.714 0.667 7 0.35 0.8 0.704 8 0.4 0.8 0.731 9 0.45 0.829 0.769 10 0.5 0.886 0.815 11 0.55 0.914 0.861 12 0.6 0.943 0.870 13 0.65 0.971 0.889 14 0.7 1 0.944 15 0.75 1 0.954 16 0.8 1 0.972 17 0.85 1 0.991 18 0.9 1 1 19 0.95 1 1 20 1 1 1 Table 4.7: Gain Table OBJ.NAME$gainplot returns the Gain plot glresults$gainplot Figure 4.2: Gain Plot OBJ.NAME$lifttable returns the Lift table glresults$lifttable # A tibble: 20 x 3 `% Sample` Holdout Training &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 0.05 2.83 2.60 2 0.1 2.51 2.69 3 0.15 2.63 2.48 4 0.2 2.38 2.51 5 0.25 2.48 2.42 6 0.3 2.44 2.23 7 0.35 2.33 2.02 8 0.4 2.03 1.83 9 0.45 1.86 1.71 10 0.5 1.79 1.64 11 0.55 1.68 1.57 12 0.6 1.58 1.46 13 0.65 1.50 1.37 14 0.7 1.43 1.35 15 0.75 1.34 1.28 16 0.8 1.25 1.22 17 0.85 1.18 1.17 18 0.9 1.11 1.11 19 0.95 1.05 1.06 20 1 1 1 Table 4.8: Lift Table OBJ.NAME$liftplot returns the Lift plot glresults$liftplot Figure 4.3: Lift Plot 4.8 Sensitivity/Specificity Plot To get the Sensitivity/Specificity plot, use the user defined function logreg_cut.R Usage: logreg_cut.r(MOD, DATA, \"POS\") MOD is the name of the object with results of the glm() call DATA is the data set for which the plot should be produced (i.e., original, training, or testing) \"POS\" is the level of the factor variable that is the SUCCESS level This function requires the ggplot2 package, which needs to be loaded first # Load necessary packages library(ggplot2) # Sensitivity/Specificity Plot for Training Sample logreg_cut(model, # Name of the results object train, # Use training sample &quot;Yes&quot;) # Level of &#39;buy&#39; that represents success/true Figure 4.4: Sensitivity/Specificity Plot for Training Sample "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
